{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/spanstatus.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/spanstatus.ts"],"sourcesContent":["import type { Span } from '../types-hoist/span';\nimport type { SpanStatus } from '../types-hoist/spanStatus';\n\nexport const SPAN_STATUS_UNSET = 0;\nexport const SPAN_STATUS_OK = 1;\nexport const SPAN_STATUS_ERROR = 2;\n\n/**\n * Converts a HTTP status code into a sentry status with a message.\n *\n * @param httpStatus The HTTP response status code.\n * @returns The span status or internal_error.\n */\n// https://develop.sentry.dev/sdk/event-payloads/span/\nexport function getSpanStatusFromHttpCode(httpStatus: number): SpanStatus {\n  if (httpStatus < 400 && httpStatus >= 100) {\n    return { code: SPAN_STATUS_OK };\n  }\n\n  if (httpStatus >= 400 && httpStatus < 500) {\n    switch (httpStatus) {\n      case 401:\n        return { code: SPAN_STATUS_ERROR, message: 'unauthenticated' };\n      case 403:\n        return { code: SPAN_STATUS_ERROR, message: 'permission_denied' };\n      case 404:\n        return { code: SPAN_STATUS_ERROR, message: 'not_found' };\n      case 409:\n        return { code: SPAN_STATUS_ERROR, message: 'already_exists' };\n      case 413:\n        return { code: SPAN_STATUS_ERROR, message: 'failed_precondition' };\n      case 429:\n        return { code: SPAN_STATUS_ERROR, message: 'resource_exhausted' };\n      case 499:\n        return { code: SPAN_STATUS_ERROR, message: 'cancelled' };\n      default:\n        return { code: SPAN_STATUS_ERROR, message: 'invalid_argument' };\n    }\n  }\n\n  if (httpStatus >= 500 && httpStatus < 600) {\n    switch (httpStatus) {\n      case 501:\n        return { code: SPAN_STATUS_ERROR, message: 'unimplemented' };\n      case 503:\n        return { code: SPAN_STATUS_ERROR, message: 'unavailable' };\n      case 504:\n        return { code: SPAN_STATUS_ERROR, message: 'deadline_exceeded' };\n      default:\n        return { code: SPAN_STATUS_ERROR, message: 'internal_error' };\n    }\n  }\n\n  return { code: SPAN_STATUS_ERROR, message: 'internal_error' };\n}\n\n/**\n * Sets the Http status attributes on the current span based on the http code.\n * Additionally, the span's status is updated, depending on the http code.\n */\nexport function setHttpStatus(span: Span, httpStatus: number): void {\n  span.setAttribute('http.response.status_code', httpStatus);\n\n  const spanStatus = getSpanStatusFromHttpCode(httpStatus);\n  if (spanStatus.message !== 'unknown_error') {\n    span.setStatus(spanStatus);\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAGO,MAAM,iBAAA,GAAoB;AAC1B,MAAM,cAAA,GAAiB;AACvB,MAAM,iBAAA,GAAoB;AAEjC;;;;;CAKA,GACA,sDAAA;AACO,SAAS,yBAAyB,CAAC,UAAU,EAAsB;IACxE,IAAI,UAAA,GAAa,OAAO,UAAA,IAAc,GAAG,EAAE;QACzC,OAAO;YAAE,IAAI,EAAE;QAAA,CAAgB;IACjC;IAEA,IAAI,UAAA,IAAc,OAAO,UAAA,GAAa,GAAG,EAAE;QACzC,OAAQ,UAAU;YAChB,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,iBAAA;gBAAA,CAAmB;YAChE,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,mBAAA;gBAAA,CAAqB;YAClE,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,WAAA;gBAAA,CAAa;YAC1D,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,gBAAA;gBAAA,CAAkB;YAC/D,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,qBAAA;gBAAA,CAAuB;YACpE,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,oBAAA;gBAAA,CAAsB;YACnE,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,WAAA;gBAAA,CAAa;YAC1D;gBACE,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,kBAAA;gBAAA,CAAoB;QACvE;IACE;IAEA,IAAI,UAAA,IAAc,OAAO,UAAA,GAAa,GAAG,EAAE;QACzC,OAAQ,UAAU;YAChB,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,eAAA;gBAAA,CAAiB;YAC9D,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,aAAA;gBAAA,CAAe;YAC5D,KAAK,GAAG;gBACN,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,mBAAA;gBAAA,CAAqB;YAClE;gBACE,OAAO;oBAAE,IAAI,EAAE,iBAAiB;oBAAE,OAAO,EAAE,gBAAA;gBAAA,CAAkB;QACrE;IACE;IAEA,OAAO;QAAE,IAAI,EAAE,iBAAiB;QAAE,OAAO,EAAE,gBAAA;IAAA,CAAkB;AAC/D;AAEA;;;CAGA,GACO,SAAS,aAAa,CAAC,IAAI,EAAQ,UAAU,EAAgB;IAClE,IAAI,CAAC,YAAY,CAAC,2BAA2B,EAAE,UAAU,CAAC;IAE1D,MAAM,UAAA,GAAa,yBAAyB,CAAC,UAAU,CAAC;IACxD,IAAI,UAAU,CAAC,OAAA,KAAY,eAAe,EAAE;QAC1C,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC;IAC5B;AACF"}},
    {"offset": {"line": 120, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/utils.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/utils.ts"],"sourcesContent":["import type { Scope } from '../scope';\nimport type { Span } from '../types-hoist/span';\nimport { addNonEnumerableProperty } from '../utils/object';\nimport { GLOBAL_OBJ } from '../utils/worldwide';\n\nconst SCOPE_ON_START_SPAN_FIELD = '_sentryScope';\nconst ISOLATION_SCOPE_ON_START_SPAN_FIELD = '_sentryIsolationScope';\n\ntype ScopeWeakRef = { deref(): Scope | undefined } | Scope;\n\ntype SpanWithScopes = Span & {\n  [SCOPE_ON_START_SPAN_FIELD]?: Scope;\n  [ISOLATION_SCOPE_ON_START_SPAN_FIELD]?: ScopeWeakRef;\n};\n\n/** Wrap a scope with a WeakRef if available, falling back to a direct scope. */\nfunction wrapScopeWithWeakRef(scope: Scope): ScopeWeakRef {\n  try {\n    // @ts-expect-error - WeakRef is not available in all environments\n    const WeakRefClass = GLOBAL_OBJ.WeakRef;\n    if (typeof WeakRefClass === 'function') {\n      return new WeakRefClass(scope);\n    }\n  } catch {\n    // WeakRef not available or failed to create\n    // We'll fall back to a direct scope\n  }\n\n  return scope;\n}\n\n/** Try to unwrap a scope from a potential WeakRef wrapper. */\nfunction unwrapScopeFromWeakRef(scopeRef: ScopeWeakRef | undefined): Scope | undefined {\n  if (!scopeRef) {\n    return undefined;\n  }\n\n  if (typeof scopeRef === 'object' && 'deref' in scopeRef && typeof scopeRef.deref === 'function') {\n    try {\n      return scopeRef.deref();\n    } catch {\n      return undefined;\n    }\n  }\n\n  // Fallback to a direct scope\n  return scopeRef as Scope;\n}\n\n/** Store the scope & isolation scope for a span, which can the be used when it is finished. */\nexport function setCapturedScopesOnSpan(span: Span | undefined, scope: Scope, isolationScope: Scope): void {\n  if (span) {\n    addNonEnumerableProperty(span, ISOLATION_SCOPE_ON_START_SPAN_FIELD, wrapScopeWithWeakRef(isolationScope));\n    // We don't wrap the scope with a WeakRef here because webkit aggressively garbage collects\n    // and scopes are not held in memory for long periods of time.\n    addNonEnumerableProperty(span, SCOPE_ON_START_SPAN_FIELD, scope);\n  }\n}\n\n/**\n * Grabs the scope and isolation scope off a span that were active when the span was started.\n * If WeakRef was used and scopes have been garbage collected, returns undefined for those scopes.\n */\nexport function getCapturedScopesOnSpan(span: Span): { scope?: Scope; isolationScope?: Scope } {\n  const spanWithScopes = span as SpanWithScopes;\n\n  return {\n    scope: spanWithScopes[SCOPE_ON_START_SPAN_FIELD],\n    isolationScope: unwrapScopeFromWeakRef(spanWithScopes[ISOLATION_SCOPE_ON_START_SPAN_FIELD]),\n  };\n}\n"],"names":[],"mappings":";;;;;;;;;;AAKA,MAAM,yBAAA,GAA4B,cAAc;AAChD,MAAM,mCAAA,GAAsC,uBAAuB;AASnE,8EAAA,GACA,SAAS,oBAAoB,CAAC,KAAK,EAAuB;IACxD,IAAI;QACN,kEAAA;QACI,MAAM,YAAA,GAAe,wPAAU,CAAC,OAAO;QACvC,IAAI,OAAO,YAAA,KAAiB,UAAU,EAAE;YACtC,OAAO,IAAI,YAAY,CAAC,KAAK,CAAC;QAChC;IACF,EAAE,OAAM;IACV,4CAAA;IACA,oCAAA;IACE;IAEA,OAAO,KAAK;AACd;AAEA,4DAAA,GACA,SAAS,sBAAsB,CAAC,QAAQ,EAA+C;IACrF,IAAI,CAAC,QAAQ,EAAE;QACb,OAAO,SAAS;IAClB;IAEA,IAAI,OAAO,QAAA,KAAa,YAAY,OAAA,IAAW,QAAA,IAAY,OAAO,QAAQ,CAAC,KAAA,KAAU,UAAU,EAAE;QAC/F,IAAI;YACF,OAAO,QAAQ,CAAC,KAAK,EAAE;QACzB,EAAE,OAAM;YACN,OAAO,SAAS;QAClB;IACF;IAEF,6BAAA;IACE,OAAO,QAAA;AACT;AAEA,6FAAA,GACO,SAAS,uBAAuB,CAAC,IAAI,EAAoB,KAAK,EAAS,cAAc,EAAe;IACzG,IAAI,IAAI,EAAE;YACR,mQAAwB,EAAC,IAAI,EAAE,mCAAmC,EAAE,oBAAoB,CAAC,cAAc,CAAC,CAAC;QAC7G,2FAAA;QACA,8DAAA;YACI,mQAAwB,EAAC,IAAI,EAAE,yBAAyB,EAAE,KAAK,CAAC;IAClE;AACF;AAEA;;;CAGA,GACO,SAAS,uBAAuB,CAAC,IAAI,EAAmD;IAC7F,MAAM,cAAA,GAAiB,IAAA;IAEvB,OAAO;QACL,KAAK,EAAE,cAAc,CAAC,yBAAyB,CAAC;QAChD,cAAc,EAAE,sBAAsB,CAAC,cAAc,CAAC,mCAAmC,CAAC,CAAC;IAC/F,CAAG;AACH"}},
    {"offset": {"line": 183, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/dynamicSamplingContext.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/dynamicSamplingContext.ts"],"sourcesContent":["import type { Client } from '../client';\nimport { DEFAULT_ENVIRONMENT } from '../constants';\nimport { getClient } from '../currentScopes';\nimport type { Scope } from '../scope';\nimport {\n  SEMANTIC_ATTRIBUTE_SENTRY_PREVIOUS_TRACE_SAMPLE_RATE,\n  SEMANTIC_ATTRIBUTE_SENTRY_SAMPLE_RATE,\n  SEMANTIC_ATTRIBUTE_SENTRY_SOURCE,\n} from '../semanticAttributes';\nimport type { DynamicSamplingContext } from '../types-hoist/envelope';\nimport type { Span } from '../types-hoist/span';\nimport { baggageHeaderToDynamicSamplingContext, dynamicSamplingContextToSentryBaggageHeader } from '../utils/baggage';\nimport { extractOrgIdFromClient } from '../utils/dsn';\nimport { hasSpansEnabled } from '../utils/hasSpansEnabled';\nimport { addNonEnumerableProperty } from '../utils/object';\nimport { getRootSpan, spanIsSampled, spanToJSON } from '../utils/spanUtils';\nimport { getCapturedScopesOnSpan } from './utils';\n\n/**\n * If you change this value, also update the terser plugin config to\n * avoid minification of the object property!\n */\nconst FROZEN_DSC_FIELD = '_frozenDsc';\n\ntype SpanWithMaybeDsc = Span & {\n  [FROZEN_DSC_FIELD]?: Partial<DynamicSamplingContext> | undefined;\n};\n\n/**\n * Freeze the given DSC on the given span.\n */\nexport function freezeDscOnSpan(span: Span, dsc: Partial<DynamicSamplingContext>): void {\n  const spanWithMaybeDsc = span as SpanWithMaybeDsc;\n  addNonEnumerableProperty(spanWithMaybeDsc, FROZEN_DSC_FIELD, dsc);\n}\n\n/**\n * Creates a dynamic sampling context from a client.\n *\n * Dispatches the `createDsc` lifecycle hook as a side effect.\n */\nexport function getDynamicSamplingContextFromClient(trace_id: string, client: Client): DynamicSamplingContext {\n  const options = client.getOptions();\n\n  const { publicKey: public_key } = client.getDsn() || {};\n\n  // Instead of conditionally adding non-undefined values, we add them and then remove them if needed\n  // otherwise, the order of baggage entries changes, which \"breaks\" a bunch of tests etc.\n  const dsc: DynamicSamplingContext = {\n    environment: options.environment || DEFAULT_ENVIRONMENT,\n    release: options.release,\n    public_key,\n    trace_id,\n    org_id: extractOrgIdFromClient(client),\n  };\n\n  client.emit('createDsc', dsc);\n\n  return dsc;\n}\n\n/**\n * Get the dynamic sampling context for the currently active scopes.\n */\nexport function getDynamicSamplingContextFromScope(client: Client, scope: Scope): Partial<DynamicSamplingContext> {\n  const propagationContext = scope.getPropagationContext();\n  return propagationContext.dsc || getDynamicSamplingContextFromClient(propagationContext.traceId, client);\n}\n\n/**\n * Creates a dynamic sampling context from a span (and client and scope)\n *\n * @param span the span from which a few values like the root span name and sample rate are extracted.\n *\n * @returns a dynamic sampling context\n */\nexport function getDynamicSamplingContextFromSpan(span: Span): Readonly<Partial<DynamicSamplingContext>> {\n  const client = getClient();\n  if (!client) {\n    return {};\n  }\n\n  const rootSpan = getRootSpan(span);\n  const rootSpanJson = spanToJSON(rootSpan);\n  const rootSpanAttributes = rootSpanJson.data;\n  const traceState = rootSpan.spanContext().traceState;\n\n  // The span sample rate that was locally applied to the root span should also always be applied to the DSC, even if the DSC is frozen.\n  // This is so that the downstream traces/services can use parentSampleRate in their `tracesSampler` to make consistent sampling decisions across the entire trace.\n  const rootSpanSampleRate =\n    traceState?.get('sentry.sample_rate') ??\n    rootSpanAttributes[SEMANTIC_ATTRIBUTE_SENTRY_SAMPLE_RATE] ??\n    rootSpanAttributes[SEMANTIC_ATTRIBUTE_SENTRY_PREVIOUS_TRACE_SAMPLE_RATE];\n\n  function applyLocalSampleRateToDsc(dsc: Partial<DynamicSamplingContext>): Partial<DynamicSamplingContext> {\n    if (typeof rootSpanSampleRate === 'number' || typeof rootSpanSampleRate === 'string') {\n      dsc.sample_rate = `${rootSpanSampleRate}`;\n    }\n    return dsc;\n  }\n\n  // For core implementation, we freeze the DSC onto the span as a non-enumerable property\n  const frozenDsc = (rootSpan as SpanWithMaybeDsc)[FROZEN_DSC_FIELD];\n  if (frozenDsc) {\n    return applyLocalSampleRateToDsc(frozenDsc);\n  }\n\n  // For OpenTelemetry, we freeze the DSC on the trace state\n  const traceStateDsc = traceState?.get('sentry.dsc');\n\n  // If the span has a DSC, we want it to take precedence\n  const dscOnTraceState = traceStateDsc && baggageHeaderToDynamicSamplingContext(traceStateDsc);\n\n  if (dscOnTraceState) {\n    return applyLocalSampleRateToDsc(dscOnTraceState);\n  }\n\n  // Else, we generate it from the span\n  const dsc = getDynamicSamplingContextFromClient(span.spanContext().traceId, client);\n\n  // We don't want to have a transaction name in the DSC if the source is \"url\" because URLs might contain PII\n  const source = rootSpanAttributes[SEMANTIC_ATTRIBUTE_SENTRY_SOURCE];\n\n  // after JSON conversion, txn.name becomes jsonSpan.description\n  const name = rootSpanJson.description;\n  if (source !== 'url' && name) {\n    dsc.transaction = name;\n  }\n\n  // How can we even land here with hasSpansEnabled() returning false?\n  // Otel creates a Non-recording span in Tracing Without Performance mode when handling incoming requests\n  // So we end up with an active span that is not sampled (neither positively nor negatively)\n  if (hasSpansEnabled()) {\n    dsc.sampled = String(spanIsSampled(rootSpan));\n    dsc.sample_rand =\n      // In OTEL we store the sample rand on the trace state because we cannot access scopes for NonRecordingSpans\n      // The Sentry OTEL SpanSampler takes care of writing the sample rand on the root span\n      traceState?.get('sentry.sample_rand') ??\n      // On all other platforms we can actually get the scopes from a root span (we use this as a fallback)\n      getCapturedScopesOnSpan(rootSpan).scope?.getPropagationContext().sampleRand.toString();\n  }\n\n  applyLocalSampleRateToDsc(dsc);\n\n  client.emit('createDsc', dsc, rootSpan);\n\n  return dsc;\n}\n\n/**\n * Convert a Span to a baggage header.\n */\nexport function spanToBaggageHeader(span: Span): string | undefined {\n  const dsc = getDynamicSamplingContextFromSpan(span);\n  return dynamicSamplingContextToSentryBaggageHeader(dsc);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkBA;;;CAGA,GACA,MAAM,gBAAA,GAAmB,YAAY;AAMrC;;CAEA,GACO,SAAS,eAAe,CAAC,IAAI,EAAQ,GAAG,EAAyC;IACtF,MAAM,gBAAA,GAAmB,IAAA;QACzB,mQAAwB,EAAC,gBAAgB,EAAE,gBAAgB,EAAE,GAAG,CAAC;AACnE;AAEA;;;;CAIA,GACO,SAAS,mCAAmC,CAAC,QAAQ,EAAU,MAAM,EAAkC;IAC5G,MAAM,OAAA,GAAU,MAAM,CAAC,UAAU,EAAE;IAEnC,MAAM,EAAE,SAAS,EAAE,UAAA,EAAW,GAAI,MAAM,CAAC,MAAM,EAAC,IAAK,CAAA,CAAE;IAEzD,mGAAA;IACA,wFAAA;IACE,MAAM,GAAG,GAA2B;QAClC,WAAW,EAAE,OAAO,CAAC,WAAA,IAAe,wPAAmB;QACvD,OAAO,EAAE,OAAO,CAAC,OAAO;QACxB,UAAU;QACV,QAAQ;QACR,MAAM,MAAE,8PAAsB,EAAC,MAAM,CAAC;IAC1C,CAAG;IAED,MAAM,CAAC,IAAI,CAAC,WAAW,EAAE,GAAG,CAAC;IAE7B,OAAO,GAAG;AACZ;AAEA;;CAEA,GACO,SAAS,kCAAkC,CAAC,MAAM,EAAU,KAAK,EAA0C;IAChH,MAAM,kBAAA,GAAqB,KAAK,CAAC,qBAAqB,EAAE;IACxD,OAAO,kBAAkB,CAAC,GAAA,IAAO,mCAAmC,CAAC,kBAAkB,CAAC,OAAO,EAAE,MAAM,CAAC;AAC1G;AAEA;;;;;;CAMA,GACO,SAAS,iCAAiC,CAAC,IAAI,EAAmD;IACvG,MAAM,MAAA,OAAS,kPAAS,EAAE;IAC1B,IAAI,CAAC,MAAM,EAAE;QACX,OAAO,CAAA,CAAE;IACX;IAEA,MAAM,QAAA,OAAW,yPAAW,EAAC,IAAI,CAAC;IAClC,MAAM,YAAA,OAAe,wPAAU,EAAC,QAAQ,CAAC;IACzC,MAAM,kBAAA,GAAqB,YAAY,CAAC,IAAI;IAC5C,MAAM,aAAa,QAAQ,CAAC,WAAW,EAAE,CAAC,UAAU;IAEtD,sIAAA;IACA,kKAAA;IACE,MAAM,kBAAA,GACJ,UAAU,EAAE,GAAG,CAAC,oBAAoB,CAAA,IACpC,kBAAkB,CAAC,mRAAqC,CAAA,IACxD,kBAAkB,CAAC,kSAAoD,CAAC;IAE1E,SAAS,yBAAyB,CAAC,GAAG,EAAoE;QACxG,IAAI,OAAO,kBAAA,KAAuB,QAAA,IAAY,OAAO,kBAAA,KAAuB,QAAQ,EAAE;YACpF,GAAG,CAAC,WAAA,GAAc,CAAC,EAAA,kBAAA,CAAA,CAAA;QACA;QACA,OAAA,GAAA;IACA;IAEA,wFAAA;IACA,MAAA,SAAA,GAAA,QAAA,CAAA,gBAAA,CAAA;IACA,IAAA,SAAA,EAAA;QACA,OAAA,yBAAA,CAAA,SAAA,CAAA;IACA;IAEA,0DAAA;IACA,MAAA,aAAA,GAAA,UAAA,EAAA,GAAA,CAAA,YAAA,CAAA;IAEA,uDAAA;IACA,MAAA,eAAA,GAAA,aAAA,QAAA,iRAAA,EAAA,aAAA,CAAA;IAEA,IAAA,eAAA,EAAA;QACA,OAAA,yBAAA,CAAA,eAAA,CAAA;IACA;IAEA,qCAAA;IACA,MAAA,GAAA,GAAA,mCAAA,CAAA,IAAA,CAAA,WAAA,EAAA,CAAA,OAAA,EAAA,MAAA,CAAA;IAEA,4GAAA;IACA,MAAA,MAAA,GAAA,kBAAA,CAAA,8QAAA,CAAA;IAEA,+DAAA;IACA,MAAA,IAAA,GAAA,YAAA,CAAA,WAAA;IACA,IAAA,MAAA,KAAA,KAAA,IAAA,IAAA,EAAA;QACA,GAAA,CAAA,WAAA,GAAA,IAAA;IACA;IAEA,oEAAA;IACA,wGAAA;IACA,2FAAA;IACA,QAAA,mQAAA,EAAA,GAAA;QACA,GAAA,CAAA,OAAA,GAAA,MAAA,KAAA,2PAAA,EAAA,QAAA,CAAA,CAAA;QACA,GAAA,CAAA,WAAA,GACA,4GAAA;QACA,qFAAA;QACA,UAAA,EAAA,GAAA,CAAA,oBAAA,CAAA,IACA,qGAAA;YACA,mQAAA,EAAA,QAAA,CAAA,CAAA,KAAA,EAAA,qBAAA,EAAA,CAAA,UAAA,CAAA,QAAA,EAAA;IACA;IAEA,yBAAA,CAAA,GAAA,CAAA;IAEA,MAAA,CAAA,IAAA,CAAA,WAAA,EAAA,GAAA,EAAA,QAAA,CAAA;IAEA,OAAA,GAAA;AACA;AAEA;;CAEA,GACA,SAAA,mBAAA,CAAA,IAAA,EAAA;IACA,MAAA,GAAA,GAAA,iCAAA,CAAA,IAAA,CAAA;IACA,WAAA,uRAAA,EAAA,GAAA,CAAA;AACA"}},
    {"offset": {"line": 319, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/measurement.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/measurement.ts"],"sourcesContent":["import { DEBUG_BUILD } from '../debug-build';\nimport {\n  SEMANTIC_ATTRIBUTE_SENTRY_MEASUREMENT_UNIT,\n  SEMANTIC_ATTRIBUTE_SENTRY_MEASUREMENT_VALUE,\n} from '../semanticAttributes';\nimport type { Measurements, MeasurementUnit } from '../types-hoist/measurement';\nimport type { TimedEvent } from '../types-hoist/timedEvent';\nimport { debug } from '../utils/debug-logger';\nimport { getActiveSpan, getRootSpan } from '../utils/spanUtils';\n\n/**\n * Adds a measurement to the active transaction on the current global scope. You can optionally pass in a different span\n * as the 4th parameter.\n */\nexport function setMeasurement(name: string, value: number, unit: MeasurementUnit, activeSpan = getActiveSpan()): void {\n  const rootSpan = activeSpan && getRootSpan(activeSpan);\n\n  if (rootSpan) {\n    DEBUG_BUILD && debug.log(`[Measurement] Setting measurement on root span: ${name} = ${value} ${unit}`);\n    rootSpan.addEvent(name, {\n      [SEMANTIC_ATTRIBUTE_SENTRY_MEASUREMENT_VALUE]: value,\n      [SEMANTIC_ATTRIBUTE_SENTRY_MEASUREMENT_UNIT]: unit as string,\n    });\n  }\n}\n\n/**\n * Convert timed events to measurements.\n */\nexport function timedEventsToMeasurements(events: TimedEvent[]): Measurements | undefined {\n  if (!events || events.length === 0) {\n    return undefined;\n  }\n\n  const measurements: Measurements = {};\n  events.forEach(event => {\n    const attributes = event.attributes || {};\n    const unit = attributes[SEMANTIC_ATTRIBUTE_SENTRY_MEASUREMENT_UNIT] as MeasurementUnit | undefined;\n    const value = attributes[SEMANTIC_ATTRIBUTE_SENTRY_MEASUREMENT_VALUE] as number | undefined;\n\n    if (typeof unit === 'string' && typeof value === 'number') {\n      measurements[event.name] = { value, unit };\n    }\n  });\n\n  return measurements;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAUA;;;CAGA,GACO,SAAS,cAAc,CAAC,IAAI,EAAU,KAAK,EAAU,IAAI,EAAmB,iBAAa,2PAAa,GAAE,EAAQ;IACrH,MAAM,WAAW,UAAA,QAAc,yPAAW,EAAC,UAAU,CAAC;IAEtD,IAAI,QAAQ,EAAE;QACZ,qPAAA,IAAe,yPAAK,CAAC,GAAG,CAAC,CAAC,gDAAgD,EAAE,IAAI,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,CAAA,CAAA;QACA,QAAA,CAAA,QAAA,CAAA,IAAA,EAAA;YACA,CAAA,yRAAA,CAAA,EAAA,KAAA;YACA,CAAA,wRAAA,CAAA,EAAA,IAAA;QACA,CAAA,CAAA;IACA;AACA;AAEA;;CAEA,GACA,SAAA,yBAAA,CAAA,MAAA,EAAA;IACA,IAAA,CAAA,MAAA,IAAA,MAAA,CAAA,MAAA,KAAA,CAAA,EAAA;QACA,OAAA,SAAA;IACA;IAEA,MAAA,YAAA,GAAA,CAAA,CAAA;IACA,MAAA,CAAA,OAAA,EAAA,KAAA,IAAA;QACA,MAAA,UAAA,GAAA,KAAA,CAAA,UAAA,IAAA,CAAA,CAAA;QACA,MAAA,IAAA,GAAA,UAAA,CAAA,wRAAA,CAAA;QACA,MAAA,KAAA,GAAA,UAAA,CAAA,yRAAA,CAAA;QAEA,IAAA,OAAA,IAAA,KAAA,QAAA,IAAA,OAAA,KAAA,KAAA,QAAA,EAAA;YACA,YAAA,CAAA,KAAA,CAAA,IAAA,CAAA,GAAA;gBAAA,KAAA;gBAAA,IAAA;YAAA,CAAA;QACA;IACA,CAAA,CAAA;IAEA,OAAA,YAAA;AACA"}},
    {"offset": {"line": 372, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/logSpans.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/logSpans.ts"],"sourcesContent":["import { DEBUG_BUILD } from '../debug-build';\nimport type { Span } from '../types-hoist/span';\nimport { debug } from '../utils/debug-logger';\nimport { getRootSpan, spanIsSampled, spanToJSON } from '../utils/spanUtils';\n\n/**\n * Print a log message for a started span.\n */\nexport function logSpanStart(span: Span): void {\n  if (!DEBUG_BUILD) return;\n\n  const { description = '< unknown name >', op = '< unknown op >', parent_span_id: parentSpanId } = spanToJSON(span);\n  const { spanId } = span.spanContext();\n\n  const sampled = spanIsSampled(span);\n  const rootSpan = getRootSpan(span);\n  const isRootSpan = rootSpan === span;\n\n  const header = `[Tracing] Starting ${sampled ? 'sampled' : 'unsampled'} ${isRootSpan ? 'root ' : ''}span`;\n\n  const infoParts: string[] = [`op: ${op}`, `name: ${description}`, `ID: ${spanId}`];\n\n  if (parentSpanId) {\n    infoParts.push(`parent ID: ${parentSpanId}`);\n  }\n\n  if (!isRootSpan) {\n    const { op, description } = spanToJSON(rootSpan);\n    infoParts.push(`root ID: ${rootSpan.spanContext().spanId}`);\n    if (op) {\n      infoParts.push(`root op: ${op}`);\n    }\n    if (description) {\n      infoParts.push(`root description: ${description}`);\n    }\n  }\n\n  debug.log(`${header}\n  ${infoParts.join('\\n  ')}`);\n}\n\n/**\n * Print a log message for an ended span.\n */\nexport function logSpanEnd(span: Span): void {\n  if (!DEBUG_BUILD) return;\n\n  const { description = '< unknown name >', op = '< unknown op >' } = spanToJSON(span);\n  const { spanId } = span.spanContext();\n  const rootSpan = getRootSpan(span);\n  const isRootSpan = rootSpan === span;\n\n  const msg = `[Tracing] Finishing \"${op}\" ${isRootSpan ? 'root ' : ''}span \"${description}\" with ID ${spanId}`;\n  debug.log(msg);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAKA;;CAEA,GACO,SAAS,YAAY,CAAC,IAAI,EAAc;IAC7C,IAAI,CAAC,qPAAW,EAAE;IAElB,MAAM,EAAE,WAAA,GAAc,kBAAkB,EAAE,KAAK,gBAAgB,EAAE,cAAc,EAAE,YAAA,EAAa,OAAI,wPAAU,EAAC,IAAI,CAAC;IAClH,MAAM,EAAE,MAAA,EAAO,GAAI,IAAI,CAAC,WAAW,EAAE;IAErC,MAAM,OAAA,OAAU,2PAAa,EAAC,IAAI,CAAC;IACnC,MAAM,QAAA,OAAW,yPAAW,EAAC,IAAI,CAAC;IAClC,MAAM,UAAA,GAAa,QAAA,KAAa,IAAI;IAEpC,MAAM,SAAS,CAAC,mBAAmB,EAAE,OAAA,GAAU,SAAA,GAAY,WAAW,CAAC,CAAC,EAAE,UAAA,GAAa,UAAU,EAAE,CAAC,IAAI,CAAC;IAEzG,MAAM,SAAS,GAAa;QAAC,CAAC,IAAI,EAAE,EAAE,CAAC,CAAA;QAAA,CAAA,MAAA,EAAA,WAAA,CAAA,CAAA;QAAA,CAAA,IAAA,EAAA,MAAA,CAAA,CAAA;KAAA;IAEA,IAAA,YAAA,EAAA;QACA,SAAA,CAAA,IAAA,CAAA,CAAA,WAAA,EAAA,YAAA,CAAA,CAAA,CAAA;IACA;IAEA,IAAA,CAAA,UAAA,EAAA;QACA,MAAA,EAAA,EAAA,EAAA,WAAA,EAAA,OAAA,wPAAA,EAAA,QAAA,CAAA;QACA,SAAA,CAAA,IAAA,CAAA,CAAA,SAAA,EAAA,QAAA,CAAA,WAAA,EAAA,CAAA,MAAA,CAAA,CAAA,CAAA;QACA,IAAA,EAAA,EAAA;YACA,SAAA,CAAA,IAAA,CAAA,CAAA,SAAA,EAAA,EAAA,CAAA,CAAA,CAAA;QACA;QACA,IAAA,WAAA,EAAA;YACA,SAAA,CAAA,IAAA,CAAA,CAAA,kBAAA,EAAA,WAAA,CAAA,CAAA,CAAA;QACA;IACA;IAEA,yPAAA,CAAA,GAAA,CAAA,CAAA,EAAA,MAAA,CAAA;EACA,EAAA,SAAA,CAAA,IAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA;AACA;AAEA;;CAEA,GACA,SAAA,UAAA,CAAA,IAAA,EAAA;IACA,IAAA,CAAA,qPAAA,EAAA;IAEA,MAAA,EAAA,WAAA,GAAA,kBAAA,EAAA,EAAA,GAAA,gBAAA,EAAA,OAAA,wPAAA,EAAA,IAAA,CAAA;IACA,MAAA,EAAA,MAAA,EAAA,GAAA,IAAA,CAAA,WAAA,EAAA;IACA,MAAA,QAAA,OAAA,yPAAA,EAAA,IAAA,CAAA;IACA,MAAA,UAAA,GAAA,QAAA,KAAA,IAAA;IAEA,MAAA,GAAA,GAAA,CAAA,qBAAA,EAAA,EAAA,CAAA,EAAA,EAAA,UAAA,GAAA,OAAA,GAAA,EAAA,CAAA,MAAA,EAAA,WAAA,CAAA,UAAA,EAAA,MAAA,CAAA,CAAA;IACA,yPAAA,CAAA,GAAA,CAAA,GAAA,CAAA;AACA"}},
    {"offset": {"line": 432, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/sampling.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/sampling.ts"],"sourcesContent":["import { DEBUG_BUILD } from '../debug-build';\nimport type { CoreOptions } from '../types-hoist/options';\nimport type { SamplingContext } from '../types-hoist/samplingcontext';\nimport { debug } from '../utils/debug-logger';\nimport { hasSpansEnabled } from '../utils/hasSpansEnabled';\nimport { parseSampleRate } from '../utils/parseSampleRate';\n\n/**\n * Makes a sampling decision for the given options.\n *\n * Called every time a root span is created. Only root spans which emerge with a `sampled` value of `true` will be\n * sent to Sentry.\n */\nexport function sampleSpan(\n  options: Pick<CoreOptions, 'tracesSampleRate' | 'tracesSampler'>,\n  samplingContext: SamplingContext,\n  sampleRand: number,\n): [sampled: boolean, sampleRate?: number, localSampleRateWasApplied?: boolean] {\n  // nothing to do if span recording is not enabled\n  if (!hasSpansEnabled(options)) {\n    return [false];\n  }\n\n  let localSampleRateWasApplied = undefined;\n\n  // we would have bailed already if neither `tracesSampler` nor `tracesSampleRate` were defined, so one of these should\n  // work; prefer the hook if so\n  let sampleRate;\n  if (typeof options.tracesSampler === 'function') {\n    sampleRate = options.tracesSampler({\n      ...samplingContext,\n      inheritOrSampleWith: fallbackSampleRate => {\n        // If we have an incoming parent sample rate, we'll just use that one.\n        // The sampling decision will be inherited because of the sample_rand that was generated when the trace reached the incoming boundaries of the SDK.\n        if (typeof samplingContext.parentSampleRate === 'number') {\n          return samplingContext.parentSampleRate;\n        }\n\n        // Fallback if parent sample rate is not on the incoming trace (e.g. if there is no baggage)\n        // This is to provide backwards compatibility if there are incoming traces from older SDKs that don't send a parent sample rate or a sample rand. In these cases we just want to force either a sampling decision on the downstream traces via the sample rate.\n        if (typeof samplingContext.parentSampled === 'boolean') {\n          return Number(samplingContext.parentSampled);\n        }\n\n        return fallbackSampleRate;\n      },\n    });\n    localSampleRateWasApplied = true;\n  } else if (samplingContext.parentSampled !== undefined) {\n    sampleRate = samplingContext.parentSampled;\n  } else if (typeof options.tracesSampleRate !== 'undefined') {\n    sampleRate = options.tracesSampleRate;\n    localSampleRateWasApplied = true;\n  }\n\n  // Since this is coming from the user (or from a function provided by the user), who knows what we might get.\n  // (The only valid values are booleans or numbers between 0 and 1.)\n  const parsedSampleRate = parseSampleRate(sampleRate);\n\n  if (parsedSampleRate === undefined) {\n    DEBUG_BUILD &&\n      debug.warn(\n        `[Tracing] Discarding root span because of invalid sample rate. Sample rate must be a boolean or a number between 0 and 1. Got ${JSON.stringify(\n          sampleRate,\n        )} of type ${JSON.stringify(typeof sampleRate)}.`,\n      );\n    return [false];\n  }\n\n  // if the function returned 0 (or false), or if `tracesSampleRate` is 0, it's a sign the transaction should be dropped\n  if (!parsedSampleRate) {\n    DEBUG_BUILD &&\n      debug.log(\n        `[Tracing] Discarding transaction because ${\n          typeof options.tracesSampler === 'function'\n            ? 'tracesSampler returned 0 or false'\n            : 'a negative sampling decision was inherited or tracesSampleRate is set to 0'\n        }`,\n      );\n    return [false, parsedSampleRate, localSampleRateWasApplied];\n  }\n\n  // We always compare the sample rand for the current execution context against the chosen sample rate.\n  // Read more: https://develop.sentry.dev/sdk/telemetry/traces/#propagated-random-value\n  const shouldSample = sampleRand < parsedSampleRate;\n\n  // if we're not going to keep it, we're done\n  if (!shouldSample) {\n    DEBUG_BUILD &&\n      debug.log(\n        `[Tracing] Discarding transaction because it's not included in the random sample (sampling rate = ${Number(\n          sampleRate,\n        )})`,\n      );\n  }\n\n  return [shouldSample, parsedSampleRate, localSampleRateWasApplied];\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAOA;;;;;CAKA,GACO,SAAS,UAAU,CACxB,OAAO,EACP,eAAe,EACf,UAAU;IAEZ,iDAAA;IACE,IAAI,KAAC,mQAAe,EAAC,OAAO,CAAC,EAAE;QAC7B,OAAO;YAAC,KAAK;SAAC;IAChB;IAEA,IAAI,yBAAA,GAA4B,SAAS;IAE3C,sHAAA;IACA,8BAAA;IACE,IAAI,UAAU;IACd,IAAI,OAAO,OAAO,CAAC,aAAA,KAAkB,UAAU,EAAE;QAC/C,UAAA,GAAa,OAAO,CAAC,aAAa,CAAC;YACjC,GAAG,eAAe;YAClB,mBAAmB,GAAE,kBAAA,IAAsB;gBACjD,sEAAA;gBACA,mJAAA;gBACQ,IAAI,OAAO,eAAe,CAAC,gBAAA,KAAqB,QAAQ,EAAE;oBACxD,OAAO,eAAe,CAAC,gBAAgB;gBACzC;gBAER,4FAAA;gBACA,+PAAA;gBACQ,IAAI,OAAO,eAAe,CAAC,aAAA,KAAkB,SAAS,EAAE;oBACtD,OAAO,MAAM,CAAC,eAAe,CAAC,aAAa,CAAC;gBAC9C;gBAEA,OAAO,kBAAkB;YAC3B,CAAC;QACP,CAAK,CAAC;QACF,yBAAA,GAA4B,IAAI;IAClC,CAAA,MAAO,IAAI,eAAe,CAAC,aAAA,KAAkB,SAAS,EAAE;QACtD,UAAA,GAAa,eAAe,CAAC,aAAa;IAC5C,CAAA,MAAO,IAAI,OAAO,OAAO,CAAC,gBAAA,KAAqB,WAAW,EAAE;QAC1D,UAAA,GAAa,OAAO,CAAC,gBAAgB;QACrC,yBAAA,GAA4B,IAAI;IAClC;IAEF,6GAAA;IACA,mEAAA;IACE,MAAM,gBAAA,OAAmB,mQAAe,EAAC,UAAU,CAAC;IAEpD,IAAI,gBAAA,KAAqB,SAAS,EAAE;QAClC,qPAAA,IACE,yPAAK,CAAC,IAAI,CACR,CAAC,8HAA8H,EAAE,IAAI,CAAC,SAAS,CAC7I,UAAU,EACV,SAAS,EAAE,IAAI,CAAC,SAAS,CAAC,OAAO,UAAU,CAAC,CAAC,CAAC,CAAC;QAErD,OAAO;YAAC,KAAK;SAAC;IAChB;IAEF,sHAAA;IACE,IAAI,CAAC,gBAAgB,EAAE;QACrB,qPAAA,IACE,yPAAK,CAAC,GAAG,CACP,CAAC,yCAAyC,EACxC,OAAO,OAAO,CAAC,aAAA,KAAkB,aAC7B,sCACA,8EACL;QAEA,OAAA;YAAA,KAAA;YAAA,gBAAA;YAAA,yBAAA;SAAA;IACA;IAEA,sGAAA;IACA,sFAAA;IACA,MAAA,YAAA,GAAA,UAAA,GAAA,gBAAA;IAEA,4CAAA;IACA,IAAA,CAAA,YAAA,EAAA;QACA,qPAAA,IACA,yPAAA,CAAA,GAAA,CACA,CAAA,iGAAA,EAAA,MAAA,CACA,UAAA,EACA,CAAA,CAAA;IAEA;IAEA,OAAA;QAAA,YAAA;QAAA,gBAAA;QAAA,yBAAA;KAAA;AACA"}},
    {"offset": {"line": 521, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/sentryNonRecordingSpan.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/sentryNonRecordingSpan.ts"],"sourcesContent":["import type {\n  SentrySpanArguments,\n  Span,\n  SpanAttributes,\n  SpanAttributeValue,\n  SpanContextData,\n  SpanTimeInput,\n} from '../types-hoist/span';\nimport type { SpanStatus } from '../types-hoist/spanStatus';\nimport { generateSpanId, generateTraceId } from '../utils/propagationContext';\nimport { TRACE_FLAG_NONE } from '../utils/spanUtils';\n\n/**\n * A Sentry Span that is non-recording, meaning it will not be sent to Sentry.\n */\nexport class SentryNonRecordingSpan implements Span {\n  private _traceId: string;\n  private _spanId: string;\n\n  public constructor(spanContext: SentrySpanArguments = {}) {\n    this._traceId = spanContext.traceId || generateTraceId();\n    this._spanId = spanContext.spanId || generateSpanId();\n  }\n\n  /** @inheritdoc */\n  public spanContext(): SpanContextData {\n    return {\n      spanId: this._spanId,\n      traceId: this._traceId,\n      traceFlags: TRACE_FLAG_NONE,\n    };\n  }\n\n  /** @inheritdoc */\n  public end(_timestamp?: SpanTimeInput): void {}\n\n  /** @inheritdoc */\n  public setAttribute(_key: string, _value: SpanAttributeValue | undefined): this {\n    return this;\n  }\n\n  /** @inheritdoc */\n  public setAttributes(_values: SpanAttributes): this {\n    return this;\n  }\n\n  /** @inheritdoc */\n  public setStatus(_status: SpanStatus): this {\n    return this;\n  }\n\n  /** @inheritdoc */\n  public updateName(_name: string): this {\n    return this;\n  }\n\n  /** @inheritdoc */\n  public isRecording(): boolean {\n    return false;\n  }\n\n  /** @inheritdoc */\n  public addEvent(\n    _name: string,\n    _attributesOrStartTime?: SpanAttributes | SpanTimeInput,\n    _startTime?: SpanTimeInput,\n  ): this {\n    return this;\n  }\n\n  /** @inheritDoc */\n  public addLink(_link: unknown): this {\n    return this;\n  }\n\n  /** @inheritDoc */\n  public addLinks(_links: unknown[]): this {\n    return this;\n  }\n\n  /**\n   * This should generally not be used,\n   * but we need it for being compliant with the OTEL Span interface.\n   *\n   * @hidden\n   * @internal\n   */\n  public recordException(_exception: unknown, _time?: number | undefined): void {\n    // noop\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAYA;;CAEA,GACO,MAAM,wBAAuC;IAI3C,WAAW,CAAC,WAAW,GAAwB,CAAA,CAAE,CAAE;QACxD,IAAI,CAAC,QAAA,GAAW,WAAW,CAAC,OAAA,QAAW,sQAAe,EAAE;QACxD,IAAI,CAAC,OAAA,GAAU,WAAW,CAAC,MAAA,QAAU,qQAAc,EAAE;IACvD;IAEF,gBAAA,GACS,WAAW,GAAoB;QACpC,OAAO;YACL,MAAM,EAAE,IAAI,CAAC,OAAO;YACpB,OAAO,EAAE,IAAI,CAAC,QAAQ;YACtB,UAAU,EAAE,6PAAe;QACjC,CAAK;IACH;IAEF,gBAAA,GACS,GAAG,CAAC,UAAU,EAAwB,CAAC;IAEhD,gBAAA,GACS,YAAY,CAAC,IAAI,EAAU,MAAM,EAAwC;QAC9E,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,aAAa,CAAC,OAAO,EAAwB;QAClD,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,SAAS,CAAC,OAAO,EAAoB;QAC1C,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,UAAU,CAAC,KAAK,EAAgB;QACrC,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,WAAW,GAAY;QAC5B,OAAO,KAAK;IACd;IAEF,gBAAA,GACS,QAAQ,CACb,KAAK,EACL,sBAAsB,EACtB,UAAU,EACJ;QACN,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,OAAO,CAAC,KAAK,EAAiB;QACnC,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,QAAQ,CAAC,MAAM,EAAmB;QACvC,OAAO,IAAI;IACb;IAEF;;;;;;GAMA,GACS,eAAe,CAAC,UAAU,EAAW,KAAK,EAA6B;IAChF,OAAA;IACE;AACF"}},
    {"offset": {"line": 584, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/sentrySpan.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/sentrySpan.ts"],"sourcesContent":["import { getClient, getCurrentScope } from '../currentScopes';\nimport { DEBUG_BUILD } from '../debug-build';\nimport { createSpanEnvelope } from '../envelope';\nimport {\n  SEMANTIC_ATTRIBUTE_EXCLUSIVE_TIME,\n  SEMANTIC_ATTRIBUTE_PROFILE_ID,\n  SEMANTIC_ATTRIBUTE_SENTRY_CUSTOM_SPAN_NAME,\n  SEMANTIC_ATTRIBUTE_SENTRY_OP,\n  SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN,\n  SEMANTIC_ATTRIBUTE_SENTRY_SOURCE,\n} from '../semanticAttributes';\nimport type { SpanEnvelope } from '../types-hoist/envelope';\nimport type { TransactionEvent } from '../types-hoist/event';\nimport type { SpanLink } from '../types-hoist/link';\nimport type {\n  SentrySpanArguments,\n  Span,\n  SpanAttributes,\n  SpanAttributeValue,\n  SpanContextData,\n  SpanJSON,\n  SpanOrigin,\n  SpanTimeInput,\n} from '../types-hoist/span';\nimport type { SpanStatus } from '../types-hoist/spanStatus';\nimport type { TimedEvent } from '../types-hoist/timedEvent';\nimport { debug } from '../utils/debug-logger';\nimport { generateSpanId, generateTraceId } from '../utils/propagationContext';\nimport {\n  convertSpanLinksForEnvelope,\n  getRootSpan,\n  getSpanDescendants,\n  getStatusMessage,\n  spanTimeInputToSeconds,\n  spanToJSON,\n  spanToTransactionTraceContext,\n  TRACE_FLAG_NONE,\n  TRACE_FLAG_SAMPLED,\n} from '../utils/spanUtils';\nimport { timestampInSeconds } from '../utils/time';\nimport { getDynamicSamplingContextFromSpan } from './dynamicSamplingContext';\nimport { logSpanEnd } from './logSpans';\nimport { timedEventsToMeasurements } from './measurement';\nimport { getCapturedScopesOnSpan } from './utils';\n\nconst MAX_SPAN_COUNT = 1000;\n\n/**\n * Span contains all data about a span\n */\nexport class SentrySpan implements Span {\n  protected _traceId: string;\n  protected _spanId: string;\n  protected _parentSpanId?: string | undefined;\n  protected _sampled: boolean | undefined;\n  protected _name?: string | undefined;\n  protected _attributes: SpanAttributes;\n  protected _links?: SpanLink[];\n  /** Epoch timestamp in seconds when the span started. */\n  protected _startTime: number;\n  /** Epoch timestamp in seconds when the span ended. */\n  protected _endTime?: number | undefined;\n  /** Internal keeper of the status */\n  protected _status?: SpanStatus;\n  /** The timed events added to this span. */\n  protected _events: TimedEvent[];\n\n  /** if true, treat span as a standalone span (not part of a transaction) */\n  private _isStandaloneSpan?: boolean;\n\n  /**\n   * You should never call the constructor manually, always use `Sentry.startSpan()`\n   * or other span methods.\n   * @internal\n   * @hideconstructor\n   * @hidden\n   */\n  public constructor(spanContext: SentrySpanArguments = {}) {\n    this._traceId = spanContext.traceId || generateTraceId();\n    this._spanId = spanContext.spanId || generateSpanId();\n    this._startTime = spanContext.startTimestamp || timestampInSeconds();\n    this._links = spanContext.links;\n\n    this._attributes = {};\n    this.setAttributes({\n      [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: 'manual',\n      [SEMANTIC_ATTRIBUTE_SENTRY_OP]: spanContext.op,\n      ...spanContext.attributes,\n    });\n\n    this._name = spanContext.name;\n\n    if (spanContext.parentSpanId) {\n      this._parentSpanId = spanContext.parentSpanId;\n    }\n    // We want to include booleans as well here\n    if ('sampled' in spanContext) {\n      this._sampled = spanContext.sampled;\n    }\n    if (spanContext.endTimestamp) {\n      this._endTime = spanContext.endTimestamp;\n    }\n\n    this._events = [];\n\n    this._isStandaloneSpan = spanContext.isStandalone;\n\n    // If the span is already ended, ensure we finalize the span immediately\n    if (this._endTime) {\n      this._onSpanEnded();\n    }\n  }\n\n  /** @inheritDoc */\n  public addLink(link: SpanLink): this {\n    if (this._links) {\n      this._links.push(link);\n    } else {\n      this._links = [link];\n    }\n    return this;\n  }\n\n  /** @inheritDoc */\n  public addLinks(links: SpanLink[]): this {\n    if (this._links) {\n      this._links.push(...links);\n    } else {\n      this._links = links;\n    }\n    return this;\n  }\n\n  /**\n   * This should generally not be used,\n   * but it is needed for being compliant with the OTEL Span interface.\n   *\n   * @hidden\n   * @internal\n   */\n  public recordException(_exception: unknown, _time?: number | undefined): void {\n    // noop\n  }\n\n  /** @inheritdoc */\n  public spanContext(): SpanContextData {\n    const { _spanId: spanId, _traceId: traceId, _sampled: sampled } = this;\n    return {\n      spanId,\n      traceId,\n      traceFlags: sampled ? TRACE_FLAG_SAMPLED : TRACE_FLAG_NONE,\n    };\n  }\n\n  /** @inheritdoc */\n  public setAttribute(key: string, value: SpanAttributeValue | undefined): this {\n    if (value === undefined) {\n      // eslint-disable-next-line @typescript-eslint/no-dynamic-delete\n      delete this._attributes[key];\n    } else {\n      this._attributes[key] = value;\n    }\n\n    return this;\n  }\n\n  /** @inheritdoc */\n  public setAttributes(attributes: SpanAttributes): this {\n    Object.keys(attributes).forEach(key => this.setAttribute(key, attributes[key]));\n    return this;\n  }\n\n  /**\n   * This should generally not be used,\n   * but we need it for browser tracing where we want to adjust the start time afterwards.\n   * USE THIS WITH CAUTION!\n   *\n   * @hidden\n   * @internal\n   */\n  public updateStartTime(timeInput: SpanTimeInput): void {\n    this._startTime = spanTimeInputToSeconds(timeInput);\n  }\n\n  /**\n   * @inheritDoc\n   */\n  public setStatus(value: SpanStatus): this {\n    this._status = value;\n    return this;\n  }\n\n  /**\n   * @inheritDoc\n   */\n  public updateName(name: string): this {\n    this._name = name;\n    this.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_SOURCE, 'custom');\n    return this;\n  }\n\n  /** @inheritdoc */\n  public end(endTimestamp?: SpanTimeInput): void {\n    // If already ended, skip\n    if (this._endTime) {\n      return;\n    }\n\n    this._endTime = spanTimeInputToSeconds(endTimestamp);\n    logSpanEnd(this);\n\n    this._onSpanEnded();\n  }\n\n  /**\n   * Get JSON representation of this span.\n   *\n   * @hidden\n   * @internal This method is purely for internal purposes and should not be used outside\n   * of SDK code. If you need to get a JSON representation of a span,\n   * use `spanToJSON(span)` instead.\n   */\n  public getSpanJSON(): SpanJSON {\n    return {\n      data: this._attributes,\n      description: this._name,\n      op: this._attributes[SEMANTIC_ATTRIBUTE_SENTRY_OP],\n      parent_span_id: this._parentSpanId,\n      span_id: this._spanId,\n      start_timestamp: this._startTime,\n      status: getStatusMessage(this._status),\n      timestamp: this._endTime,\n      trace_id: this._traceId,\n      origin: this._attributes[SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN] as SpanOrigin | undefined,\n      profile_id: this._attributes[SEMANTIC_ATTRIBUTE_PROFILE_ID] as string | undefined,\n      exclusive_time: this._attributes[SEMANTIC_ATTRIBUTE_EXCLUSIVE_TIME] as number | undefined,\n      measurements: timedEventsToMeasurements(this._events),\n      is_segment: (this._isStandaloneSpan && getRootSpan(this) === this) || undefined,\n      segment_id: this._isStandaloneSpan ? getRootSpan(this).spanContext().spanId : undefined,\n      links: convertSpanLinksForEnvelope(this._links),\n    };\n  }\n\n  /** @inheritdoc */\n  public isRecording(): boolean {\n    return !this._endTime && !!this._sampled;\n  }\n\n  /**\n   * @inheritdoc\n   */\n  public addEvent(\n    name: string,\n    attributesOrStartTime?: SpanAttributes | SpanTimeInput,\n    startTime?: SpanTimeInput,\n  ): this {\n    DEBUG_BUILD && debug.log('[Tracing] Adding an event to span:', name);\n\n    const time = isSpanTimeInput(attributesOrStartTime) ? attributesOrStartTime : startTime || timestampInSeconds();\n    const attributes = isSpanTimeInput(attributesOrStartTime) ? {} : attributesOrStartTime || {};\n\n    const event: TimedEvent = {\n      name,\n      time: spanTimeInputToSeconds(time),\n      attributes,\n    };\n\n    this._events.push(event);\n\n    return this;\n  }\n\n  /**\n   * This method should generally not be used,\n   * but for now we need a way to publicly check if the `_isStandaloneSpan` flag is set.\n   * USE THIS WITH CAUTION!\n   * @internal\n   * @hidden\n   * @experimental\n   */\n  public isStandaloneSpan(): boolean {\n    return !!this._isStandaloneSpan;\n  }\n\n  /** Emit `spanEnd` when the span is ended. */\n  private _onSpanEnded(): void {\n    const client = getClient();\n    if (client) {\n      client.emit('spanEnd', this);\n    }\n\n    // A segment span is basically the root span of a local span tree.\n    // So for now, this is either what we previously refer to as the root span,\n    // or a standalone span.\n    const isSegmentSpan = this._isStandaloneSpan || this === getRootSpan(this);\n\n    if (!isSegmentSpan) {\n      return;\n    }\n\n    // if this is a standalone span, we send it immediately\n    if (this._isStandaloneSpan) {\n      if (this._sampled) {\n        sendSpanEnvelope(createSpanEnvelope([this], client));\n      } else {\n        DEBUG_BUILD &&\n          debug.log('[Tracing] Discarding standalone span because its trace was not chosen to be sampled.');\n        if (client) {\n          client.recordDroppedEvent('sample_rate', 'span');\n        }\n      }\n      return;\n    }\n\n    const transactionEvent = this._convertSpanToTransaction();\n    if (transactionEvent) {\n      const scope = getCapturedScopesOnSpan(this).scope || getCurrentScope();\n      scope.captureEvent(transactionEvent);\n    }\n  }\n\n  /**\n   * Finish the transaction & prepare the event to send to Sentry.\n   */\n  private _convertSpanToTransaction(): TransactionEvent | undefined {\n    // We can only convert finished spans\n    if (!isFullFinishedSpan(spanToJSON(this))) {\n      return undefined;\n    }\n\n    if (!this._name) {\n      DEBUG_BUILD && debug.warn('Transaction has no name, falling back to `<unlabeled transaction>`.');\n      this._name = '<unlabeled transaction>';\n    }\n\n    const { scope: capturedSpanScope, isolationScope: capturedSpanIsolationScope } = getCapturedScopesOnSpan(this);\n\n    const normalizedRequest = capturedSpanScope?.getScopeData().sdkProcessingMetadata?.normalizedRequest;\n\n    if (this._sampled !== true) {\n      return undefined;\n    }\n\n    // The transaction span itself as well as any potential standalone spans should be filtered out\n    const finishedSpans = getSpanDescendants(this).filter(span => span !== this && !isStandaloneSpan(span));\n\n    const spans = finishedSpans.map(span => spanToJSON(span)).filter(isFullFinishedSpan);\n\n    const source = this._attributes[SEMANTIC_ATTRIBUTE_SENTRY_SOURCE];\n\n    // remove internal root span attributes we don't need to send.\n    /* eslint-disable @typescript-eslint/no-dynamic-delete */\n    delete this._attributes[SEMANTIC_ATTRIBUTE_SENTRY_CUSTOM_SPAN_NAME];\n    spans.forEach(span => {\n      delete span.data[SEMANTIC_ATTRIBUTE_SENTRY_CUSTOM_SPAN_NAME];\n    });\n    // eslint-enabled-next-line @typescript-eslint/no-dynamic-delete\n\n    const transaction: TransactionEvent = {\n      contexts: {\n        trace: spanToTransactionTraceContext(this),\n      },\n      spans:\n        // spans.sort() mutates the array, but `spans` is already a copy so we can safely do this here\n        // we do not use spans anymore after this point\n        spans.length > MAX_SPAN_COUNT\n          ? spans.sort((a, b) => a.start_timestamp - b.start_timestamp).slice(0, MAX_SPAN_COUNT)\n          : spans,\n      start_timestamp: this._startTime,\n      timestamp: this._endTime,\n      transaction: this._name,\n      type: 'transaction',\n      sdkProcessingMetadata: {\n        capturedSpanScope,\n        capturedSpanIsolationScope,\n        dynamicSamplingContext: getDynamicSamplingContextFromSpan(this),\n      },\n      request: normalizedRequest,\n      ...(source && {\n        transaction_info: {\n          source,\n        },\n      }),\n    };\n\n    const measurements = timedEventsToMeasurements(this._events);\n    const hasMeasurements = measurements && Object.keys(measurements).length;\n\n    if (hasMeasurements) {\n      DEBUG_BUILD &&\n        debug.log(\n          '[Measurements] Adding measurements to transaction event',\n          JSON.stringify(measurements, undefined, 2),\n        );\n      transaction.measurements = measurements;\n    }\n\n    return transaction;\n  }\n}\n\nfunction isSpanTimeInput(value: undefined | SpanAttributes | SpanTimeInput): value is SpanTimeInput {\n  return (value && typeof value === 'number') || value instanceof Date || Array.isArray(value);\n}\n\n// We want to filter out any incomplete SpanJSON objects\nfunction isFullFinishedSpan(input: Partial<SpanJSON>): input is SpanJSON {\n  return !!input.start_timestamp && !!input.timestamp && !!input.span_id && !!input.trace_id;\n}\n\n/** `SentrySpan`s can be sent as a standalone span rather than belonging to a transaction */\nfunction isStandaloneSpan(span: Span): boolean {\n  return span instanceof SentrySpan && span.isStandaloneSpan();\n}\n\n/**\n * Sends a `SpanEnvelope`.\n *\n * Note: If the envelope's spans are dropped, e.g. via `beforeSendSpan`,\n * the envelope will not be sent either.\n */\nfunction sendSpanEnvelope(envelope: SpanEnvelope): void {\n  const client = getClient();\n  if (!client) {\n    return;\n  }\n\n  const spanItems = envelope[1];\n  if (!spanItems || spanItems.length === 0) {\n    client.recordDroppedEvent('before_send', 'span');\n    return;\n  }\n\n  // sendEnvelope should not throw\n  // eslint-disable-next-line @typescript-eslint/no-floating-promises\n  client.sendEnvelope(envelope);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CA,MAAM,cAAA,GAAiB,IAAI;AAE3B;;CAEA,GACO,MAAM,YAA2B;IAQxC,sDAAA,GAEA,oDAAA,GAEA,kCAAA,GAEA,yCAAA,GAGA,yEAAA,GAGA;;;;;;GAMA,GACS,WAAW,CAAC,WAAW,GAAwB,CAAA,CAAE,CAAE;QACxD,IAAI,CAAC,QAAA,GAAW,WAAW,CAAC,OAAA,QAAW,sQAAe,EAAE;QACxD,IAAI,CAAC,OAAA,GAAU,WAAW,CAAC,MAAA,QAAU,qQAAc,EAAE;QACrD,IAAI,CAAC,UAAA,GAAa,WAAW,CAAC,cAAA,QAAkB,2PAAkB,EAAE;QACpE,IAAI,CAAC,MAAA,GAAS,WAAW,CAAC,KAAK;QAE/B,IAAI,CAAC,WAAA,GAAc,CAAA,CAAE;QACrB,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,8QAAgC,CAAA,EAAG,QAAQ;YAC5C,CAAC,0QAA4B,CAAA,EAAG,WAAW,CAAC,EAAE;YAC9C,GAAG,WAAW,CAAC,UAAU;QAC/B,CAAK,CAAC;QAEF,IAAI,CAAC,KAAA,GAAQ,WAAW,CAAC,IAAI;QAE7B,IAAI,WAAW,CAAC,YAAY,EAAE;YAC5B,IAAI,CAAC,aAAA,GAAgB,WAAW,CAAC,YAAY;QAC/C;QACJ,2CAAA;QACI,IAAI,SAAA,IAAa,WAAW,EAAE;YAC5B,IAAI,CAAC,QAAA,GAAW,WAAW,CAAC,OAAO;QACrC;QACA,IAAI,WAAW,CAAC,YAAY,EAAE;YAC5B,IAAI,CAAC,QAAA,GAAW,WAAW,CAAC,YAAY;QAC1C;QAEA,IAAI,CAAC,OAAA,GAAU,EAAE;QAEjB,IAAI,CAAC,iBAAA,GAAoB,WAAW,CAAC,YAAY;QAErD,wEAAA;QACI,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,IAAI,CAAC,YAAY,EAAE;QACrB;IACF;IAEF,gBAAA,GACS,OAAO,CAAC,IAAI,EAAkB;QACnC,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC;QACxB,OAAO;YACL,IAAI,CAAC,MAAA,GAAS;gBAAC,IAAI;aAAC;QACtB;QACA,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,QAAQ,CAAC,KAAK,EAAoB;QACvC,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC;QAC5B,OAAO;YACL,IAAI,CAAC,MAAA,GAAS,KAAK;QACrB;QACA,OAAO,IAAI;IACb;IAEF;;;;;;GAMA,GACS,eAAe,CAAC,UAAU,EAAW,KAAK,EAA6B;IAChF,OAAA;IACE;IAEF,gBAAA,GACS,WAAW,GAAoB;QACpC,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,QAAQ,EAAE,OAAA,EAAQ,GAAI,IAAI;QACtE,OAAO;YACL,MAAM;YACN,OAAO;YACP,UAAU,EAAE,OAAA,GAAU,gQAAA,GAAqB,6PAAe;QAChE,CAAK;IACH;IAEF,gBAAA,GACS,YAAY,CAAC,GAAG,EAAU,KAAK,EAAwC;QAC5E,IAAI,KAAA,KAAU,SAAS,EAAE;YAC7B,gEAAA;YACM,OAAO,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC;QAC9B,OAAO;YACL,IAAI,CAAC,WAAW,CAAC,GAAG,CAAA,GAAI,KAAK;QAC/B;QAEA,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,aAAa,CAAC,UAAU,EAAwB;QACrD,MAAM,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,OAAO,EAAC,GAAA,GAAO,IAAI,CAAC,YAAY,CAAC,GAAG,EAAE,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC;QAC/E,OAAO,IAAI;IACb;IAEF;;;;;;;GAOA,GACS,eAAe,CAAC,SAAS,EAAuB;QACrD,IAAI,CAAC,UAAA,OAAa,oQAAsB,EAAC,SAAS,CAAC;IACrD;IAEF;;GAEA,GACS,SAAS,CAAC,KAAK,EAAoB;QACxC,IAAI,CAAC,OAAA,GAAU,KAAK;QACpB,OAAO,IAAI;IACb;IAEF;;GAEA,GACS,UAAU,CAAC,IAAI,EAAgB;QACpC,IAAI,CAAC,KAAA,GAAQ,IAAI;QACjB,IAAI,CAAC,YAAY,CAAC,8QAAgC,EAAE,QAAQ,CAAC;QAC7D,OAAO,IAAI;IACb;IAEF,gBAAA,GACS,GAAG,CAAC,YAAY,EAAwB;QACjD,yBAAA;QACI,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB;QACF;QAEA,IAAI,CAAC,QAAA,OAAW,oQAAsB,EAAC,YAAY,CAAC;YACpD,yPAAU,EAAC,IAAI,CAAC;QAEhB,IAAI,CAAC,YAAY,EAAE;IACrB;IAEF;;;;;;;GAOA,GACS,WAAW,GAAa;QAC7B,OAAO;YACL,IAAI,EAAE,IAAI,CAAC,WAAW;YACtB,WAAW,EAAE,IAAI,CAAC,KAAK;YACvB,EAAE,EAAE,IAAI,CAAC,WAAW,CAAC,0QAA4B,CAAC;YAClD,cAAc,EAAE,IAAI,CAAC,aAAa;YAClC,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,eAAe,EAAE,IAAI,CAAC,UAAU;YAChC,MAAM,MAAE,8PAAgB,EAAC,IAAI,CAAC,OAAO,CAAC;YACtC,SAAS,EAAE,IAAI,CAAC,QAAQ;YACxB,QAAQ,EAAE,IAAI,CAAC,QAAQ;YACvB,MAAM,EAAE,IAAI,CAAC,WAAW,CAAC,8QAAgC,CAAA;YACzD,UAAU,EAAE,IAAI,CAAC,WAAW,CAAC,2QAA6B,CAAA;YAC1D,cAAc,EAAE,IAAI,CAAC,WAAW,CAAC,+QAAiC,CAAA;YAClE,YAAY,MAAE,2QAAyB,EAAC,IAAI,CAAC,OAAO,CAAC;YACrD,UAAU,EAAE,AAAC,IAAI,CAAC,iBAAA,QAAqB,yPAAW,EAAC,IAAI,CAAA,KAAM,IAAI,IAAK,SAAS;YAC/E,UAAU,EAAE,IAAI,CAAC,iBAAA,OAAoB,yPAAW,EAAC,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,MAAA,GAAS,SAAS;YACvF,KAAK,MAAE,yQAA2B,EAAC,IAAI,CAAC,MAAM,CAAC;QACrD,CAAK;IACH;IAEF,gBAAA,GACS,WAAW,GAAY;QAC5B,OAAO,CAAC,IAAI,CAAC,QAAA,IAAY,CAAC,CAAC,IAAI,CAAC,QAAQ;IAC1C;IAEF;;GAEA,GACS,QAAQ,CACb,IAAI,EACJ,qBAAqB,EACrB,SAAS,EACH;QACN,qPAAA,IAAe,yPAAK,CAAC,GAAG,CAAC,oCAAoC,EAAE,IAAI,CAAC;QAEpE,MAAM,IAAA,GAAO,eAAe,CAAC,qBAAqB,CAAA,GAAI,qBAAA,GAAwB,SAAA,QAAa,2PAAkB,EAAE;QAC/G,MAAM,UAAA,GAAa,eAAe,CAAC,qBAAqB,CAAA,GAAI,CAAA,CAAC,GAAI,qBAAA,IAAyB,CAAA,CAAE;QAE5F,MAAM,KAAK,GAAe;YACxB,IAAI;YACJ,IAAI,MAAE,oQAAsB,EAAC,IAAI,CAAC;YAClC,UAAU;QAChB,CAAK;QAED,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC;QAExB,OAAO,IAAI;IACb;IAEF;;;;;;;GAOA,GACS,gBAAgB,GAAY;QACjC,OAAO,CAAC,CAAC,IAAI,CAAC,iBAAiB;IACjC;IAEF,2CAAA,GACU,YAAY,GAAS;QAC3B,MAAM,MAAA,OAAS,kPAAS,EAAE;QAC1B,IAAI,MAAM,EAAE;YACV,MAAM,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC;QAC9B;QAEJ,kEAAA;QACA,2EAAA;QACA,wBAAA;QACI,MAAM,aAAA,GAAgB,IAAI,CAAC,iBAAA,IAAqB,IAAA,SAAS,yPAAW,EAAC,IAAI,CAAC;QAE1E,IAAI,CAAC,aAAa,EAAE;YAClB;QACF;QAEJ,uDAAA;QACI,IAAI,IAAI,CAAC,iBAAiB,EAAE;YAC1B,IAAI,IAAI,CAAC,QAAQ,EAAE;gBACjB,gBAAgB,KAAC,sPAAkB,EAAC;oBAAC,IAAI;iBAAC,EAAE,MAAM,CAAC,CAAC;YACtD,OAAO;gBACL,qPAAA,IACE,yPAAK,CAAC,GAAG,CAAC,sFAAsF,CAAC;gBACnG,IAAI,MAAM,EAAE;oBACV,MAAM,CAAC,kBAAkB,CAAC,aAAa,EAAE,MAAM,CAAC;gBAClD;YACF;YACA;QACF;QAEA,MAAM,gBAAA,GAAmB,IAAI,CAAC,yBAAyB,EAAE;QACzD,IAAI,gBAAgB,EAAE;YACpB,MAAM,KAAA,OAAQ,mQAAuB,EAAC,IAAI,CAAC,CAAC,KAAA,QAAS,wPAAe,EAAE;YACtE,KAAK,CAAC,YAAY,CAAC,gBAAgB,CAAC;QACtC;IACF;IAEF;;GAEA,GACU,yBAAyB,GAAiC;QACpE,qCAAA;QACI,IAAI,CAAC,kBAAkB,KAAC,wPAAU,EAAC,IAAI,CAAC,CAAC,EAAE;YACzC,OAAO,SAAS;QAClB;QAEA,IAAI,CAAC,IAAI,CAAC,KAAK,EAAE;YACf,qPAAA,IAAe,yPAAK,CAAC,IAAI,CAAC,qEAAqE,CAAC;YAChG,IAAI,CAAC,KAAA,GAAQ,yBAAyB;QACxC;QAEA,MAAM,EAAE,KAAK,EAAE,iBAAiB,EAAE,cAAc,EAAE,0BAAA,EAA2B,OAAI,mQAAuB,EAAC,IAAI,CAAC;QAE9G,MAAM,iBAAA,GAAoB,iBAAiB,EAAE,YAAY,EAAE,CAAC,qBAAqB,EAAE,iBAAiB;QAEpG,IAAI,IAAI,CAAC,QAAA,KAAa,IAAI,EAAE;YAC1B,OAAO,SAAS;QAClB;QAEJ,+FAAA;QACI,MAAM,oBAAgB,gQAAkB,EAAC,IAAI,CAAC,CAAC,MAAM,EAAC,OAAQ,IAAA,KAAS,IAAA,IAAQ,CAAC,gBAAgB,CAAC,IAAI,CAAC,CAAC;QAEvG,MAAM,KAAA,GAAQ,aAAa,CAAC,GAAG,EAAC,IAAA,OAAQ,wPAAU,EAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,kBAAkB,CAAC;QAEpF,MAAM,SAAS,IAAI,CAAC,WAAW,CAAC,8QAAgC,CAAC;QAErE,8DAAA;QACA,uDAAA,GACI,OAAO,IAAI,CAAC,WAAW,CAAC,wRAA0C,CAAC;QACnE,KAAK,CAAC,OAAO,EAAC,QAAQ;YACpB,OAAO,IAAI,CAAC,IAAI,CAAC,wRAA0C,CAAC;QAC9D,CAAC,CAAC;QACN,gEAAA;QAEI,MAAM,WAAW,GAAqB;YACpC,QAAQ,EAAE;gBACR,KAAK,MAAE,2QAA6B,EAAC,IAAI,CAAC;YAClD,CAAO;YACD,KAAK,EACX,8FAAA;YACA,+CAAA;YACQ,KAAK,CAAC,MAAA,GAAS,iBACX,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,GAAK,CAAC,CAAC,eAAA,GAAkB,CAAC,CAAC,eAAe,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,cAAc,IACnF,KAAK;YACX,eAAe,EAAE,IAAI,CAAC,UAAU;YAChC,SAAS,EAAE,IAAI,CAAC,QAAQ;YACxB,WAAW,EAAE,IAAI,CAAC,KAAK;YACvB,IAAI,EAAE,aAAa;YACnB,qBAAqB,EAAE;gBACrB,iBAAiB;gBACjB,0BAA0B;gBAC1B,sBAAsB,MAAE,8RAAiC,EAAC,IAAI,CAAC;YACvE,CAAO;YACD,OAAO,EAAE,iBAAiB;YAC1B,GAAI,MAAA,IAAU;gBACZ,gBAAgB,EAAE;oBAChB,MAAM;gBAChB,CAAS;YACT,CAAO,CAAC;QACR,CAAK;QAED,MAAM,mBAAe,2QAAyB,EAAC,IAAI,CAAC,OAAO,CAAC;QAC5D,MAAM,eAAA,GAAkB,YAAA,IAAgB,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,MAAM;QAExE,IAAI,eAAe,EAAE;YACnB,qPAAA,IACE,yPAAK,CAAC,GAAG,CACP,yDAAyD,EACzD,IAAI,CAAC,SAAS,CAAC,YAAY,EAAE,SAAS,EAAE,CAAC,CAAC;YAE9C,WAAW,CAAC,YAAA,GAAe,YAAY;QACzC;QAEA,OAAO,WAAW;IACpB;AACF;AAEA,SAAS,eAAe,CAAC,KAAK,EAAsE;IAClG,OAAO,AAAC,KAAA,IAAS,OAAO,KAAA,KAAU,QAAQ,IAAK,KAAA,YAAiB,QAAQ,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC;AAC9F;AAEA,wDAAA;AACA,SAAS,kBAAkB,CAAC,KAAK,EAAwC;IACvE,OAAO,CAAC,CAAC,KAAK,CAAC,eAAA,IAAmB,CAAC,CAAC,KAAK,CAAC,SAAA,IAAa,CAAC,CAAC,KAAK,CAAC,OAAA,IAAW,CAAC,CAAC,KAAK,CAAC,QAAQ;AAC5F;AAEA,0FAAA,GACA,SAAS,gBAAgB,CAAC,IAAI,EAAiB;IAC7C,OAAO,gBAAgB,UAAA,IAAc,IAAI,CAAC,gBAAgB,EAAE;AAC9D;AAEA;;;;;CAKA,GACA,SAAS,gBAAgB,CAAC,QAAQ,EAAsB;IACtD,MAAM,MAAA,OAAS,kPAAS,EAAE;IAC1B,IAAI,CAAC,MAAM,EAAE;QACX;IACF;IAEA,MAAM,SAAA,GAAY,QAAQ,CAAC,CAAC,CAAC;IAC7B,IAAI,CAAC,SAAA,IAAa,SAAS,CAAC,MAAA,KAAW,CAAC,EAAE;QACxC,MAAM,CAAC,kBAAkB,CAAC,aAAa,EAAE,MAAM,CAAC;QAChD;IACF;IAEF,gCAAA;IACA,mEAAA;IACE,MAAM,CAAC,YAAY,CAAC,QAAQ,CAAC;AAC/B"}},
    {"offset": {"line": 910, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/trace.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/trace.ts"],"sourcesContent":["/* eslint-disable max-lines */\n\nimport { getAsyncContextStrategy } from '../asyncContext';\nimport type { AsyncContextStrategy } from '../asyncContext/types';\nimport { getMainCarrier } from '../carrier';\nimport { getClient, getCurrentScope, getIsolationScope, withScope } from '../currentScopes';\nimport { DEBUG_BUILD } from '../debug-build';\nimport type { Scope } from '../scope';\nimport { SEMANTIC_ATTRIBUTE_SENTRY_SAMPLE_RATE, SEMANTIC_ATTRIBUTE_SENTRY_SOURCE } from '../semanticAttributes';\nimport type { DynamicSamplingContext } from '../types-hoist/envelope';\nimport type { ClientOptions } from '../types-hoist/options';\nimport type { SentrySpanArguments, Span, SpanTimeInput } from '../types-hoist/span';\nimport type { StartSpanOptions } from '../types-hoist/startSpanOptions';\nimport { baggageHeaderToDynamicSamplingContext } from '../utils/baggage';\nimport { debug } from '../utils/debug-logger';\nimport { handleCallbackErrors } from '../utils/handleCallbackErrors';\nimport { hasSpansEnabled } from '../utils/hasSpansEnabled';\nimport { parseSampleRate } from '../utils/parseSampleRate';\nimport { generateTraceId } from '../utils/propagationContext';\nimport { _getSpanForScope, _setSpanForScope } from '../utils/spanOnScope';\nimport { addChildSpanToSpan, getRootSpan, spanIsSampled, spanTimeInputToSeconds, spanToJSON } from '../utils/spanUtils';\nimport { propagationContextFromHeaders, shouldContinueTrace } from '../utils/tracing';\nimport { freezeDscOnSpan, getDynamicSamplingContextFromSpan } from './dynamicSamplingContext';\nimport { logSpanStart } from './logSpans';\nimport { sampleSpan } from './sampling';\nimport { SentryNonRecordingSpan } from './sentryNonRecordingSpan';\nimport { SentrySpan } from './sentrySpan';\nimport { SPAN_STATUS_ERROR } from './spanstatus';\nimport { setCapturedScopesOnSpan } from './utils';\n\nconst SUPPRESS_TRACING_KEY = '__SENTRY_SUPPRESS_TRACING__';\n\n/**\n * Wraps a function with a transaction/span and finishes the span after the function is done.\n * The created span is the active span and will be used as parent by other spans created inside the function\n * and can be accessed via `Sentry.getActiveSpan()`, as long as the function is executed while the scope is active.\n *\n * If you want to create a span that is not set as active, use {@link startInactiveSpan}.\n *\n * You'll always get a span passed to the callback,\n * it may just be a non-recording span if the span is not sampled or if tracing is disabled.\n */\nexport function startSpan<T>(options: StartSpanOptions, callback: (span: Span) => T): T {\n  const acs = getAcs();\n  if (acs.startSpan) {\n    return acs.startSpan(options, callback);\n  }\n\n  const spanArguments = parseSentrySpanArguments(options);\n  const { forceTransaction, parentSpan: customParentSpan, scope: customScope } = options;\n\n  // We still need to fork a potentially passed scope, as we set the active span on it\n  // and we need to ensure that it is cleaned up properly once the span ends.\n  const customForkedScope = customScope?.clone();\n\n  return withScope(customForkedScope, () => {\n    // If `options.parentSpan` is defined, we want to wrap the callback in `withActiveSpan`\n    const wrapper = getActiveSpanWrapper<T>(customParentSpan);\n\n    return wrapper(() => {\n      const scope = getCurrentScope();\n      const parentSpan = getParentSpan(scope, customParentSpan);\n\n      const shouldSkipSpan = options.onlyIfParent && !parentSpan;\n      const activeSpan = shouldSkipSpan\n        ? new SentryNonRecordingSpan()\n        : createChildOrRootSpan({\n            parentSpan,\n            spanArguments,\n            forceTransaction,\n            scope,\n          });\n\n      _setSpanForScope(scope, activeSpan);\n\n      return handleCallbackErrors(\n        () => callback(activeSpan),\n        () => {\n          // Only update the span status if it hasn't been changed yet, and the span is not yet finished\n          const { status } = spanToJSON(activeSpan);\n          if (activeSpan.isRecording() && (!status || status === 'ok')) {\n            activeSpan.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n          }\n        },\n        () => {\n          activeSpan.end();\n        },\n      );\n    });\n  });\n}\n\n/**\n * Similar to `Sentry.startSpan`. Wraps a function with a transaction/span, but does not finish the span\n * after the function is done automatically. Use `span.end()` to end the span.\n *\n * The created span is the active span and will be used as parent by other spans created inside the function\n * and can be accessed via `Sentry.getActiveSpan()`, as long as the function is executed while the scope is active.\n *\n * You'll always get a span passed to the callback,\n * it may just be a non-recording span if the span is not sampled or if tracing is disabled.\n */\nexport function startSpanManual<T>(options: StartSpanOptions, callback: (span: Span, finish: () => void) => T): T {\n  const acs = getAcs();\n  if (acs.startSpanManual) {\n    return acs.startSpanManual(options, callback);\n  }\n\n  const spanArguments = parseSentrySpanArguments(options);\n  const { forceTransaction, parentSpan: customParentSpan, scope: customScope } = options;\n\n  const customForkedScope = customScope?.clone();\n\n  return withScope(customForkedScope, () => {\n    // If `options.parentSpan` is defined, we want to wrap the callback in `withActiveSpan`\n    const wrapper = getActiveSpanWrapper<T>(customParentSpan);\n\n    return wrapper(() => {\n      const scope = getCurrentScope();\n      const parentSpan = getParentSpan(scope, customParentSpan);\n\n      const shouldSkipSpan = options.onlyIfParent && !parentSpan;\n      const activeSpan = shouldSkipSpan\n        ? new SentryNonRecordingSpan()\n        : createChildOrRootSpan({\n            parentSpan,\n            spanArguments,\n            forceTransaction,\n            scope,\n          });\n\n      _setSpanForScope(scope, activeSpan);\n\n      return handleCallbackErrors(\n        // We pass the `finish` function to the callback, so the user can finish the span manually\n        // this is mainly here for historic purposes because previously, we instructed users to call\n        // `finish` instead of `span.end()` to also clean up the scope. Nowadays, calling `span.end()`\n        // or `finish` has the same effect and we simply leave it here to avoid breaking user code.\n        () => callback(activeSpan, () => activeSpan.end()),\n        () => {\n          // Only update the span status if it hasn't been changed yet, and the span is not yet finished\n          const { status } = spanToJSON(activeSpan);\n          if (activeSpan.isRecording() && (!status || status === 'ok')) {\n            activeSpan.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n          }\n        },\n      );\n    });\n  });\n}\n\n/**\n * Creates a span. This span is not set as active, so will not get automatic instrumentation spans\n * as children or be able to be accessed via `Sentry.getActiveSpan()`.\n *\n * If you want to create a span that is set as active, use {@link startSpan}.\n *\n * This function will always return a span,\n * it may just be a non-recording span if the span is not sampled or if tracing is disabled.\n */\nexport function startInactiveSpan(options: StartSpanOptions): Span {\n  const acs = getAcs();\n  if (acs.startInactiveSpan) {\n    return acs.startInactiveSpan(options);\n  }\n\n  const spanArguments = parseSentrySpanArguments(options);\n  const { forceTransaction, parentSpan: customParentSpan } = options;\n\n  // If `options.scope` is defined, we use this as as a wrapper,\n  // If `options.parentSpan` is defined, we want to wrap the callback in `withActiveSpan`\n  const wrapper = options.scope\n    ? (callback: () => Span) => withScope(options.scope, callback)\n    : customParentSpan !== undefined\n      ? (callback: () => Span) => withActiveSpan(customParentSpan, callback)\n      : (callback: () => Span) => callback();\n\n  return wrapper(() => {\n    const scope = getCurrentScope();\n    const parentSpan = getParentSpan(scope, customParentSpan);\n\n    const shouldSkipSpan = options.onlyIfParent && !parentSpan;\n\n    if (shouldSkipSpan) {\n      return new SentryNonRecordingSpan();\n    }\n\n    return createChildOrRootSpan({\n      parentSpan,\n      spanArguments,\n      forceTransaction,\n      scope,\n    });\n  });\n}\n\n/**\n * Continue a trace from `sentry-trace` and `baggage` values.\n * These values can be obtained from incoming request headers, or in the browser from `<meta name=\"sentry-trace\">`\n * and `<meta name=\"baggage\">` HTML tags.\n *\n * Spans started with `startSpan`, `startSpanManual` and `startInactiveSpan`, within the callback will automatically\n * be attached to the incoming trace.\n */\nexport const continueTrace = <V>(\n  options: {\n    sentryTrace: Parameters<typeof propagationContextFromHeaders>[0];\n    baggage: Parameters<typeof propagationContextFromHeaders>[1];\n  },\n  callback: () => V,\n): V => {\n  const carrier = getMainCarrier();\n  const acs = getAsyncContextStrategy(carrier);\n  if (acs.continueTrace) {\n    return acs.continueTrace(options, callback);\n  }\n\n  const { sentryTrace, baggage } = options;\n\n  const client = getClient();\n  const incomingDsc = baggageHeaderToDynamicSamplingContext(baggage);\n  if (client && !shouldContinueTrace(client, incomingDsc?.org_id)) {\n    return startNewTrace(callback);\n  }\n\n  return withScope(scope => {\n    const propagationContext = propagationContextFromHeaders(sentryTrace, baggage);\n    scope.setPropagationContext(propagationContext);\n    return callback();\n  });\n};\n\n/**\n * Forks the current scope and sets the provided span as active span in the context of the provided callback. Can be\n * passed `null` to start an entirely new span tree.\n *\n * @param span Spans started in the context of the provided callback will be children of this span. If `null` is passed,\n * spans started within the callback will not be attached to a parent span.\n * @param callback Execution context in which the provided span will be active. Is passed the newly forked scope.\n * @returns the value returned from the provided callback function.\n */\nexport function withActiveSpan<T>(span: Span | null, callback: (scope: Scope) => T): T {\n  const acs = getAcs();\n  if (acs.withActiveSpan) {\n    return acs.withActiveSpan(span, callback);\n  }\n\n  return withScope(scope => {\n    _setSpanForScope(scope, span || undefined);\n    return callback(scope);\n  });\n}\n\n/** Suppress tracing in the given callback, ensuring no spans are generated inside of it. */\nexport function suppressTracing<T>(callback: () => T): T {\n  const acs = getAcs();\n\n  if (acs.suppressTracing) {\n    return acs.suppressTracing(callback);\n  }\n\n  return withScope(scope => {\n    // Note: We do not wait for the callback to finish before we reset the metadata\n    // the reason for this is that otherwise, in the browser this can lead to very weird behavior\n    // as there is only a single top scope, if the callback takes longer to finish,\n    // other, unrelated spans may also be suppressed, which we do not want\n    // so instead, we only suppress tracing synchronoysly in the browser\n    scope.setSDKProcessingMetadata({ [SUPPRESS_TRACING_KEY]: true });\n    const res = callback();\n    scope.setSDKProcessingMetadata({ [SUPPRESS_TRACING_KEY]: undefined });\n    return res;\n  });\n}\n\n/**\n * Starts a new trace for the duration of the provided callback. Spans started within the\n * callback will be part of the new trace instead of a potentially previously started trace.\n *\n * Important: Only use this function if you want to override the default trace lifetime and\n * propagation mechanism of the SDK for the duration and scope of the provided callback.\n * The newly created trace will also be the root of a new distributed trace, for example if\n * you make http requests within the callback.\n * This function might be useful if the operation you want to instrument should not be part\n * of a potentially ongoing trace.\n *\n * Default behavior:\n * - Server-side: A new trace is started for each incoming request.\n * - Browser: A new trace is started for each page our route. Navigating to a new route\n *            or page will automatically create a new trace.\n */\nexport function startNewTrace<T>(callback: () => T): T {\n  return withScope(scope => {\n    scope.setPropagationContext({\n      traceId: generateTraceId(),\n      sampleRand: Math.random(),\n    });\n    DEBUG_BUILD && debug.log(`Starting a new trace with id ${scope.getPropagationContext().traceId}`);\n    return withActiveSpan(null, callback);\n  });\n}\n\nfunction createChildOrRootSpan({\n  parentSpan,\n  spanArguments,\n  forceTransaction,\n  scope,\n}: {\n  parentSpan: SentrySpan | undefined;\n  spanArguments: SentrySpanArguments;\n  forceTransaction?: boolean;\n  scope: Scope;\n}): Span {\n  if (!hasSpansEnabled()) {\n    const span = new SentryNonRecordingSpan();\n\n    // If this is a root span, we ensure to freeze a DSC\n    // So we can have at least partial data here\n    if (forceTransaction || !parentSpan) {\n      const dsc = {\n        sampled: 'false',\n        sample_rate: '0',\n        transaction: spanArguments.name,\n        ...getDynamicSamplingContextFromSpan(span),\n      } satisfies Partial<DynamicSamplingContext>;\n      freezeDscOnSpan(span, dsc);\n    }\n\n    return span;\n  }\n\n  const isolationScope = getIsolationScope();\n\n  let span: Span;\n  if (parentSpan && !forceTransaction) {\n    span = _startChildSpan(parentSpan, scope, spanArguments);\n    addChildSpanToSpan(parentSpan, span);\n  } else if (parentSpan) {\n    // If we forced a transaction but have a parent span, make sure to continue from the parent span, not the scope\n    const dsc = getDynamicSamplingContextFromSpan(parentSpan);\n    const { traceId, spanId: parentSpanId } = parentSpan.spanContext();\n    const parentSampled = spanIsSampled(parentSpan);\n\n    span = _startRootSpan(\n      {\n        traceId,\n        parentSpanId,\n        ...spanArguments,\n      },\n      scope,\n      parentSampled,\n    );\n\n    freezeDscOnSpan(span, dsc);\n  } else {\n    const {\n      traceId,\n      dsc,\n      parentSpanId,\n      sampled: parentSampled,\n    } = {\n      ...isolationScope.getPropagationContext(),\n      ...scope.getPropagationContext(),\n    };\n\n    span = _startRootSpan(\n      {\n        traceId,\n        parentSpanId,\n        ...spanArguments,\n      },\n      scope,\n      parentSampled,\n    );\n\n    if (dsc) {\n      freezeDscOnSpan(span, dsc);\n    }\n  }\n\n  logSpanStart(span);\n\n  setCapturedScopesOnSpan(span, scope, isolationScope);\n\n  return span;\n}\n\n/**\n * This converts StartSpanOptions to SentrySpanArguments.\n * For the most part (for now) we accept the same options,\n * but some of them need to be transformed.\n */\nfunction parseSentrySpanArguments(options: StartSpanOptions): SentrySpanArguments {\n  const exp = options.experimental || {};\n  const initialCtx: SentrySpanArguments = {\n    isStandalone: exp.standalone,\n    ...options,\n  };\n\n  if (options.startTime) {\n    const ctx: SentrySpanArguments & { startTime?: SpanTimeInput } = { ...initialCtx };\n    ctx.startTimestamp = spanTimeInputToSeconds(options.startTime);\n    delete ctx.startTime;\n    return ctx;\n  }\n\n  return initialCtx;\n}\n\nfunction getAcs(): AsyncContextStrategy {\n  const carrier = getMainCarrier();\n  return getAsyncContextStrategy(carrier);\n}\n\nfunction _startRootSpan(spanArguments: SentrySpanArguments, scope: Scope, parentSampled?: boolean): SentrySpan {\n  const client = getClient();\n  const options: Partial<ClientOptions> = client?.getOptions() || {};\n\n  const { name = '' } = spanArguments;\n\n  const mutableSpanSamplingData = { spanAttributes: { ...spanArguments.attributes }, spanName: name, parentSampled };\n\n  // we don't care about the decision for the moment; this is just a placeholder\n  client?.emit('beforeSampling', mutableSpanSamplingData, { decision: false });\n\n  // If hook consumers override the parentSampled flag, we will use that value instead of the actual one\n  const finalParentSampled = mutableSpanSamplingData.parentSampled ?? parentSampled;\n  const finalAttributes = mutableSpanSamplingData.spanAttributes;\n\n  const currentPropagationContext = scope.getPropagationContext();\n  const [sampled, sampleRate, localSampleRateWasApplied] = scope.getScopeData().sdkProcessingMetadata[\n    SUPPRESS_TRACING_KEY\n  ]\n    ? [false]\n    : sampleSpan(\n        options,\n        {\n          name,\n          parentSampled: finalParentSampled,\n          attributes: finalAttributes,\n          parentSampleRate: parseSampleRate(currentPropagationContext.dsc?.sample_rate),\n        },\n        currentPropagationContext.sampleRand,\n      );\n\n  const rootSpan = new SentrySpan({\n    ...spanArguments,\n    attributes: {\n      [SEMANTIC_ATTRIBUTE_SENTRY_SOURCE]: 'custom',\n      [SEMANTIC_ATTRIBUTE_SENTRY_SAMPLE_RATE]:\n        sampleRate !== undefined && localSampleRateWasApplied ? sampleRate : undefined,\n      ...finalAttributes,\n    },\n    sampled,\n  });\n\n  if (!sampled && client) {\n    DEBUG_BUILD && debug.log('[Tracing] Discarding root span because its trace was not chosen to be sampled.');\n    client.recordDroppedEvent('sample_rate', 'transaction');\n  }\n\n  if (client) {\n    client.emit('spanStart', rootSpan);\n  }\n\n  return rootSpan;\n}\n\n/**\n * Creates a new `Span` while setting the current `Span.id` as `parentSpanId`.\n * This inherits the sampling decision from the parent span.\n */\nfunction _startChildSpan(parentSpan: Span, scope: Scope, spanArguments: SentrySpanArguments): Span {\n  const { spanId, traceId } = parentSpan.spanContext();\n  const sampled = scope.getScopeData().sdkProcessingMetadata[SUPPRESS_TRACING_KEY] ? false : spanIsSampled(parentSpan);\n\n  const childSpan = sampled\n    ? new SentrySpan({\n        ...spanArguments,\n        parentSpanId: spanId,\n        traceId,\n        sampled,\n      })\n    : new SentryNonRecordingSpan({ traceId });\n\n  addChildSpanToSpan(parentSpan, childSpan);\n\n  const client = getClient();\n  if (client) {\n    client.emit('spanStart', childSpan);\n    // If it has an endTimestamp, it's already ended\n    if (spanArguments.endTimestamp) {\n      client.emit('spanEnd', childSpan);\n    }\n  }\n\n  return childSpan;\n}\n\nfunction getParentSpan(scope: Scope, customParentSpan: Span | null | undefined): SentrySpan | undefined {\n  // always use the passed in span directly\n  if (customParentSpan) {\n    return customParentSpan as SentrySpan;\n  }\n\n  // This is different from `undefined` as it means the user explicitly wants no parent span\n  if (customParentSpan === null) {\n    return undefined;\n  }\n\n  const span = _getSpanForScope(scope) as SentrySpan | undefined;\n\n  if (!span) {\n    return undefined;\n  }\n\n  const client = getClient();\n  const options: Partial<ClientOptions> = client ? client.getOptions() : {};\n  if (options.parentSpanIsAlwaysRootSpan) {\n    return getRootSpan(span) as SentrySpan;\n  }\n\n  return span;\n}\n\nfunction getActiveSpanWrapper<T>(parentSpan: Span | undefined | null): (callback: () => T) => T {\n  return parentSpan !== undefined\n    ? (callback: () => T) => {\n        return withActiveSpan(parentSpan, callback);\n      }\n    : (callback: () => T) => callback();\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,4BAAA,GA8BA,MAAM,oBAAA,GAAuB,6BAA6B;AAE1D;;;;;;;;;CASA,GACO,SAAS,SAAS,CAAI,OAAO,EAAoB,QAAQ,EAAwB;IACtF,MAAM,GAAA,GAAM,MAAM,EAAE;IACpB,IAAI,GAAG,CAAC,SAAS,EAAE;QACjB,OAAO,GAAG,CAAC,SAAS,CAAC,OAAO,EAAE,QAAQ,CAAC;IACzC;IAEA,MAAM,aAAA,GAAgB,wBAAwB,CAAC,OAAO,CAAC;IACvD,MAAM,EAAE,gBAAgB,EAAE,UAAU,EAAE,gBAAgB,EAAE,KAAK,EAAE,WAAA,EAAY,GAAI,OAAO;IAExF,oFAAA;IACA,2EAAA;IACE,MAAM,iBAAA,GAAoB,WAAW,EAAE,KAAK,EAAE;IAE9C,WAAO,kPAAS,EAAC,iBAAiB,EAAE,MAAM;QAC5C,uFAAA;QACI,MAAM,OAAA,GAAU,oBAAoB,CAAI,gBAAgB,CAAC;QAEzD,OAAO,OAAO,CAAC,MAAM;YACnB,MAAM,KAAA,OAAQ,wPAAe,EAAE;YAC/B,MAAM,aAAa,aAAa,CAAC,KAAK,EAAE,gBAAgB,CAAC;YAEzD,MAAM,iBAAiB,OAAO,CAAC,YAAA,IAAgB,CAAC,UAAU;YAC1D,MAAM,aAAa,iBACf,IAAI,mRAAsB,KAC1B,qBAAqB,CAAC;gBACpB,UAAU;gBACV,aAAa;gBACb,gBAAgB;gBAChB,KAAK;YACjB,CAAW,CAAC;gBAEN,gQAAgB,EAAC,KAAK,EAAE,UAAU,CAAC;YAEnC,WAAO,6QAAoB,EACzB,IAAM,QAAQ,CAAC,UAAU,CAAC,EAC1B,MAAM;gBACd,8FAAA;gBACU,MAAM,EAAE,MAAA,EAAO,OAAI,wPAAU,EAAC,UAAU,CAAC;gBACzC,IAAI,UAAU,CAAC,WAAW,EAAC,IAAA,CAAM,CAAC,UAAU,MAAA,KAAW,IAAI,CAAC,EAAE;oBAC5D,UAAU,CAAC,SAAS,CAAC;wBAAE,IAAI,EAAE,kQAAiB;wBAAE,OAAO,EAAE,gBAAA;oBAAA,CAAkB,CAAC;gBAC9E;YACF,CAAC,EACD,MAAM;gBACJ,UAAU,CAAC,GAAG,EAAE;YAClB,CAAC;QAEL,CAAC,CAAC;IACJ,CAAC,CAAC;AACJ;AAEA;;;;;;;;;CASA,GACO,SAAS,eAAe,CAAI,OAAO,EAAoB,QAAQ,EAA4C;IAChH,MAAM,GAAA,GAAM,MAAM,EAAE;IACpB,IAAI,GAAG,CAAC,eAAe,EAAE;QACvB,OAAO,GAAG,CAAC,eAAe,CAAC,OAAO,EAAE,QAAQ,CAAC;IAC/C;IAEA,MAAM,aAAA,GAAgB,wBAAwB,CAAC,OAAO,CAAC;IACvD,MAAM,EAAE,gBAAgB,EAAE,UAAU,EAAE,gBAAgB,EAAE,KAAK,EAAE,WAAA,EAAY,GAAI,OAAO;IAEtF,MAAM,iBAAA,GAAoB,WAAW,EAAE,KAAK,EAAE;IAE9C,WAAO,kPAAS,EAAC,iBAAiB,EAAE,MAAM;QAC5C,uFAAA;QACI,MAAM,OAAA,GAAU,oBAAoB,CAAI,gBAAgB,CAAC;QAEzD,OAAO,OAAO,CAAC,MAAM;YACnB,MAAM,KAAA,OAAQ,wPAAe,EAAE;YAC/B,MAAM,aAAa,aAAa,CAAC,KAAK,EAAE,gBAAgB,CAAC;YAEzD,MAAM,iBAAiB,OAAO,CAAC,YAAA,IAAgB,CAAC,UAAU;YAC1D,MAAM,aAAa,iBACf,IAAI,mRAAsB,KAC1B,qBAAqB,CAAC;gBACpB,UAAU;gBACV,aAAa;gBACb,gBAAgB;gBAChB,KAAK;YACjB,CAAW,CAAC;gBAEN,gQAAgB,EAAC,KAAK,EAAE,UAAU,CAAC;YAEnC,WAAO,6QAAoB,EACjC,0FAAA;YACA,4FAAA;YACA,8FAAA;YACA,2FAAA;YACQ,IAAM,QAAQ,CAAC,UAAU,EAAE,IAAM,UAAU,CAAC,GAAG,EAAE,CAAC,EAClD,MAAM;gBACd,8FAAA;gBACU,MAAM,EAAE,MAAA,EAAO,OAAI,wPAAU,EAAC,UAAU,CAAC;gBACzC,IAAI,UAAU,CAAC,WAAW,EAAC,IAAA,CAAM,CAAC,UAAU,MAAA,KAAW,IAAI,CAAC,EAAE;oBAC5D,UAAU,CAAC,SAAS,CAAC;wBAAE,IAAI,EAAE,kQAAiB;wBAAE,OAAO,EAAE,gBAAA;oBAAA,CAAkB,CAAC;gBAC9E;YACF,CAAC;QAEL,CAAC,CAAC;IACJ,CAAC,CAAC;AACJ;AAEA;;;;;;;;CAQA,GACO,SAAS,iBAAiB,CAAC,OAAO,EAA0B;IACjE,MAAM,GAAA,GAAM,MAAM,EAAE;IACpB,IAAI,GAAG,CAAC,iBAAiB,EAAE;QACzB,OAAO,GAAG,CAAC,iBAAiB,CAAC,OAAO,CAAC;IACvC;IAEA,MAAM,aAAA,GAAgB,wBAAwB,CAAC,OAAO,CAAC;IACvD,MAAM,EAAE,gBAAgB,EAAE,UAAU,EAAE,gBAAA,EAAiB,GAAI,OAAO;IAEpE,8DAAA;IACA,uFAAA;IACE,MAAM,OAAA,GAAU,OAAO,CAAC,KAAA,GACpB,CAAC,QAAQ,OAAiB,kPAAS,EAAC,OAAO,CAAC,KAAK,EAAE,QAAQ,IAC3D,qBAAqB,YACnB,CAAC,QAAQ,GAAiB,cAAc,CAAC,gBAAgB,EAAE,QAAQ,IACnE,CAAC,QAAQ,GAAiB,QAAQ,EAAE;IAE1C,OAAO,OAAO,CAAC,MAAM;QACnB,MAAM,KAAA,OAAQ,wPAAe,EAAE;QAC/B,MAAM,aAAa,aAAa,CAAC,KAAK,EAAE,gBAAgB,CAAC;QAEzD,MAAM,iBAAiB,OAAO,CAAC,YAAA,IAAgB,CAAC,UAAU;QAE1D,IAAI,cAAc,EAAE;YAClB,OAAO,IAAI,mRAAsB,EAAE;QACrC;QAEA,OAAO,qBAAqB,CAAC;YAC3B,UAAU;YACV,aAAa;YACb,gBAAgB;YAChB,KAAK;QACX,CAAK,CAAC;IACJ,CAAC,CAAC;AACJ;AAEA;;;;;;;CAOA,GACO,MAAM,gBAAgB,CAC3B,SAIA,QAAQ;IAER,MAAM,OAAA,OAAU,iPAAc,EAAE;IAChC,MAAM,GAAA,OAAM,wQAAuB,EAAC,OAAO,CAAC;IAC5C,IAAI,GAAG,CAAC,aAAa,EAAE;QACrB,OAAO,GAAG,CAAC,aAAa,CAAC,OAAO,EAAE,QAAQ,CAAC;IAC7C;IAEA,MAAM,EAAE,WAAW,EAAE,OAAA,EAAQ,GAAI,OAAO;IAExC,MAAM,MAAA,OAAS,kPAAS,EAAE;IAC1B,MAAM,WAAA,OAAc,iRAAqC,EAAC,OAAO,CAAC;IAClE,IAAI,MAAA,IAAU,KAAC,+PAAmB,EAAC,MAAM,EAAE,WAAW,EAAE,MAAM,CAAC,EAAE;QAC/D,OAAO,aAAa,CAAC,QAAQ,CAAC;IAChC;IAEA,WAAO,kPAAS,GAAC,KAAA,IAAS;QACxB,MAAM,yBAAqB,yQAA6B,EAAC,WAAW,EAAE,OAAO,CAAC;QAC9E,KAAK,CAAC,qBAAqB,CAAC,kBAAkB,CAAC;QAC/C,OAAO,QAAQ,EAAE;IACnB,CAAC,CAAC;AACJ;AAEA;;;;;;;;CAQA,GACO,SAAS,cAAc,CAAI,IAAI,EAAe,QAAQ,EAA0B;IACrF,MAAM,GAAA,GAAM,MAAM,EAAE;IACpB,IAAI,GAAG,CAAC,cAAc,EAAE;QACtB,OAAO,GAAG,CAAC,cAAc,CAAC,IAAI,EAAE,QAAQ,CAAC;IAC3C;IAEA,WAAO,kPAAS,GAAC,KAAA,IAAS;YACxB,gQAAgB,EAAC,KAAK,EAAE,IAAA,IAAQ,SAAS,CAAC;QAC1C,OAAO,QAAQ,CAAC,KAAK,CAAC;IACxB,CAAC,CAAC;AACJ;AAEA,0FAAA,GACO,SAAS,eAAe,CAAI,QAAQ,EAAc;IACvD,MAAM,GAAA,GAAM,MAAM,EAAE;IAEpB,IAAI,GAAG,CAAC,eAAe,EAAE;QACvB,OAAO,GAAG,CAAC,eAAe,CAAC,QAAQ,CAAC;IACtC;IAEA,WAAO,kPAAS,GAAC,KAAA,IAAS;QAC5B,+EAAA;QACA,6FAAA;QACA,+EAAA;QACA,sEAAA;QACA,oEAAA;QACI,KAAK,CAAC,wBAAwB,CAAC;YAAE,CAAC,oBAAoB,CAAA,EAAG,IAAA;QAAA,CAAM,CAAC;QAChE,MAAM,GAAA,GAAM,QAAQ,EAAE;QACtB,KAAK,CAAC,wBAAwB,CAAC;YAAE,CAAC,oBAAoB,CAAA,EAAG,SAAA;QAAA,CAAW,CAAC;QACrE,OAAO,GAAG;IACZ,CAAC,CAAC;AACJ;AAEA;;;;;;;;;;;;;;;CAeA,GACO,SAAS,aAAa,CAAI,QAAQ,EAAc;IACrD,WAAO,kPAAS,GAAC,KAAA,IAAS;QACxB,KAAK,CAAC,qBAAqB,CAAC;YAC1B,OAAO,MAAE,sQAAe,EAAE;YAC1B,UAAU,EAAE,IAAI,CAAC,MAAM,EAAE;QAC/B,CAAK,CAAC;QACF,qPAAA,IAAe,yPAAK,CAAC,GAAG,CAAC,CAAC,6BAA6B,EAAE,KAAK,CAAC,qBAAqB,EAAE,CAAC,OAAO,CAAC,CAAA,CAAA;QACA,OAAA,cAAA,CAAA,IAAA,EAAA,QAAA,CAAA;IACA,CAAA,CAAA;AACA;AAEA,SAAA,qBAAA,CAAA,EACA,UAAA,EACA,aAAA,EACA,gBAAA,EACA,KAAA,EACA;IAMA,IAAA,KAAA,mQAAA,EAAA,GAAA;QACA,MAAA,IAAA,GAAA,IAAA,mRAAA,EAAA;QAEA,oDAAA;QACA,4CAAA;QACA,IAAA,gBAAA,IAAA,CAAA,UAAA,EAAA;YACA,MAAA,GAAA,GAAA;gBACA,OAAA,EAAA,OAAA;gBACA,WAAA,EAAA,GAAA;gBACA,WAAA,EAAA,aAAA,CAAA,IAAA;gBACA,OAAA,8RAAA,EAAA,IAAA,CAAA;YACA,CAAA;gBACA,4QAAA,EAAA,IAAA,EAAA,GAAA,CAAA;QACA;QAEA,OAAA,IAAA;IACA;IAEA,MAAA,cAAA,OAAA,0PAAA,EAAA;IAEA,IAAA,IAAA;IACA,IAAA,UAAA,IAAA,CAAA,gBAAA,EAAA;QACA,IAAA,GAAA,eAAA,CAAA,UAAA,EAAA,KAAA,EAAA,aAAA,CAAA;YACA,gQAAA,EAAA,UAAA,EAAA,IAAA,CAAA;IACA,CAAA,MAAA,IAAA,UAAA,EAAA;QACA,+GAAA;QACA,MAAA,GAAA,OAAA,8RAAA,EAAA,UAAA,CAAA;QACA,MAAA,EAAA,OAAA,EAAA,MAAA,EAAA,YAAA,EAAA,GAAA,UAAA,CAAA,WAAA,EAAA;QACA,MAAA,aAAA,OAAA,2PAAA,EAAA,UAAA,CAAA;QAEA,IAAA,GAAA,cAAA,CACA;YACA,OAAA;YACA,YAAA;YACA,GAAA,aAAA;QACA,CAAA,EACA,KAAA,EACA,aAAA;YAGA,4QAAA,EAAA,IAAA,EAAA,GAAA,CAAA;IACA,CAAA,MAAA;QACA,MAAA,EACA,OAAA,EACA,GAAA,EACA,YAAA,EACA,OAAA,EAAA,aAAA,EACA,GAAA;YACA,GAAA,cAAA,CAAA,qBAAA,EAAA;YACA,GAAA,KAAA,CAAA,qBAAA,EAAA;QACA,CAAA;QAEA,IAAA,GAAA,cAAA,CACA;YACA,OAAA;YACA,YAAA;YACA,GAAA,aAAA;QACA,CAAA,EACA,KAAA,EACA,aAAA;QAGA,IAAA,GAAA,EAAA;gBACA,4QAAA,EAAA,IAAA,EAAA,GAAA,CAAA;QACA;IACA;QAEA,2PAAA,EAAA,IAAA,CAAA;QAEA,mQAAA,EAAA,IAAA,EAAA,KAAA,EAAA,cAAA,CAAA;IAEA,OAAA,IAAA;AACA;AAEA;;;;CAIA,GACA,SAAA,wBAAA,CAAA,OAAA,EAAA;IACA,MAAA,GAAA,GAAA,OAAA,CAAA,YAAA,IAAA,CAAA,CAAA;IACA,MAAA,UAAA,GAAA;QACA,YAAA,EAAA,GAAA,CAAA,UAAA;QACA,GAAA,OAAA;IACA,CAAA;IAEA,IAAA,OAAA,CAAA,SAAA,EAAA;QACA,MAAA,GAAA,GAAA;YAAA,GAAA,UAAA;QAAA,CAAA;QACA,GAAA,CAAA,cAAA,OAAA,oQAAA,EAAA,OAAA,CAAA,SAAA,CAAA;QACA,OAAA,GAAA,CAAA,SAAA;QACA,OAAA,GAAA;IACA;IAEA,OAAA,UAAA;AACA;AAEA,SAAA,MAAA,GAAA;IACA,MAAA,OAAA,OAAA,iPAAA,EAAA;IACA,WAAA,wQAAA,EAAA,OAAA,CAAA;AACA;AAEA,SAAA,cAAA,CAAA,aAAA,EAAA,KAAA,EAAA,aAAA,EAAA;IACA,MAAA,MAAA,OAAA,kPAAA,EAAA;IACA,MAAA,OAAA,GAAA,MAAA,EAAA,UAAA,EAAA,IAAA,CAAA,CAAA;IAEA,MAAA,EAAA,IAAA,GAAA,EAAA,EAAA,GAAA,aAAA;IAEA,MAAA,uBAAA,GAAA;QAAA,cAAA,EAAA;YAAA,GAAA,aAAA,CAAA,UAAA;QAAA,CAAA;QAAA,QAAA,EAAA,IAAA;QAAA,aAAA;IAAA,CAAA;IAEA,8EAAA;IACA,MAAA,EAAA,IAAA,CAAA,gBAAA,EAAA,uBAAA,EAAA;QAAA,QAAA,EAAA,KAAA;IAAA,CAAA,CAAA;IAEA,sGAAA;IACA,MAAA,kBAAA,GAAA,uBAAA,CAAA,aAAA,IAAA,aAAA;IACA,MAAA,eAAA,GAAA,uBAAA,CAAA,cAAA;IAEA,MAAA,yBAAA,GAAA,KAAA,CAAA,qBAAA,EAAA;IACA,MAAA,CAAA,OAAA,EAAA,UAAA,EAAA,yBAAA,CAAA,GAAA,KAAA,CAAA,YAAA,EAAA,CAAA,qBAAA,CACA,qBACA,GACA;QAAA,KAAA;KAAA,OACA,yPAAA,EACA,OAAA,EACA;QACA,IAAA;QACA,aAAA,EAAA,kBAAA;QACA,UAAA,EAAA,eAAA;QACA,gBAAA,MAAA,mQAAA,EAAA,yBAAA,CAAA,GAAA,EAAA,WAAA,CAAA;IACA,CAAA,EACA,yBAAA,CAAA,UAAA;IAGA,MAAA,QAAA,GAAA,IAAA,2PAAA,CAAA;QACA,GAAA,aAAA;QACA,UAAA,EAAA;YACA,CAAA,8QAAA,CAAA,EAAA,QAAA;YACA,CAAA,mRAAA,CAAA,EACA,UAAA,KAAA,SAAA,IAAA,yBAAA,GAAA,UAAA,GAAA,SAAA;YACA,GAAA,eAAA;QACA,CAAA;QACA,OAAA;IACA,CAAA,CAAA;IAEA,IAAA,CAAA,OAAA,IAAA,MAAA,EAAA;QACA,qPAAA,IAAA,yPAAA,CAAA,GAAA,CAAA,gFAAA,CAAA;QACA,MAAA,CAAA,kBAAA,CAAA,aAAA,EAAA,aAAA,CAAA;IACA;IAEA,IAAA,MAAA,EAAA;QACA,MAAA,CAAA,IAAA,CAAA,WAAA,EAAA,QAAA,CAAA;IACA;IAEA,OAAA,QAAA;AACA;AAEA;;;CAGA,GACA,SAAA,eAAA,CAAA,UAAA,EAAA,KAAA,EAAA,aAAA,EAAA;IACA,MAAA,EAAA,MAAA,EAAA,OAAA,EAAA,GAAA,UAAA,CAAA,WAAA,EAAA;IACA,MAAA,OAAA,GAAA,KAAA,CAAA,YAAA,EAAA,CAAA,qBAAA,CAAA,oBAAA,CAAA,GAAA,KAAA,OAAA,2PAAA,EAAA,UAAA,CAAA;IAEA,MAAA,SAAA,GAAA,UACA,IAAA,2PAAA,CAAA;QACA,GAAA,aAAA;QACA,YAAA,EAAA,MAAA;QACA,OAAA;QACA,OAAA;IACA,CAAA,IACA,IAAA,mRAAA,CAAA;QAAA,OAAA;IAAA,CAAA,CAAA;QAEA,gQAAA,EAAA,UAAA,EAAA,SAAA,CAAA;IAEA,MAAA,MAAA,OAAA,kPAAA,EAAA;IACA,IAAA,MAAA,EAAA;QACA,MAAA,CAAA,IAAA,CAAA,WAAA,EAAA,SAAA,CAAA;QACA,gDAAA;QACA,IAAA,aAAA,CAAA,YAAA,EAAA;YACA,MAAA,CAAA,IAAA,CAAA,SAAA,EAAA,SAAA,CAAA;QACA;IACA;IAEA,OAAA,SAAA;AACA;AAEA,SAAA,aAAA,CAAA,KAAA,EAAA,gBAAA,EAAA;IACA,yCAAA;IACA,IAAA,gBAAA,EAAA;QACA,OAAA,gBAAA;IACA;IAEA,0FAAA;IACA,IAAA,gBAAA,KAAA,IAAA,EAAA;QACA,OAAA,SAAA;IACA;IAEA,MAAA,IAAA,OAAA,gQAAA,EAAA,KAAA,CAAA;IAEA,IAAA,CAAA,IAAA,EAAA;QACA,OAAA,SAAA;IACA;IAEA,MAAA,MAAA,OAAA,kPAAA,EAAA;IACA,MAAA,OAAA,GAAA,MAAA,GAAA,MAAA,CAAA,UAAA,EAAA,GAAA,CAAA,CAAA;IACA,IAAA,OAAA,CAAA,0BAAA,EAAA;QACA,WAAA,yPAAA,EAAA,IAAA,CAAA;IACA;IAEA,OAAA,IAAA;AACA;AAEA,SAAA,oBAAA,CAAA,UAAA,EAAA;IACA,OAAA,UAAA,KAAA,YACA,CAAA,QAAA,KAAA;QACA,OAAA,cAAA,CAAA,UAAA,EAAA,QAAA,CAAA;IACA,IACA,CAAA,QAAA,GAAA,QAAA,EAAA;AACA"}},
    {"offset": {"line": 1362, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/ai/gen-ai-attributes.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/ai/gen-ai-attributes.ts"],"sourcesContent":["/**\n * OpenAI Integration Telemetry Attributes\n * Based on OpenTelemetry Semantic Conventions for Generative AI\n * @see https://opentelemetry.io/docs/specs/semconv/gen-ai/\n */\n\n// =============================================================================\n// OPENTELEMETRY SEMANTIC CONVENTIONS FOR GENAI\n// =============================================================================\n\n/**\n * The input messages sent to the model\n */\nexport const GEN_AI_PROMPT_ATTRIBUTE = 'gen_ai.prompt';\n\n/**\n * The Generative AI system being used\n * For OpenAI, this should always be \"openai\"\n */\nexport const GEN_AI_SYSTEM_ATTRIBUTE = 'gen_ai.system';\n\n/**\n * The name of the model as requested\n * Examples: \"gpt-4\", \"gpt-3.5-turbo\"\n */\nexport const GEN_AI_REQUEST_MODEL_ATTRIBUTE = 'gen_ai.request.model';\n\n/**\n * Whether streaming was enabled for the request\n */\nexport const GEN_AI_REQUEST_STREAM_ATTRIBUTE = 'gen_ai.request.stream';\n\n/**\n * The temperature setting for the model request\n */\nexport const GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE = 'gen_ai.request.temperature';\n\n/**\n * The maximum number of tokens requested\n */\nexport const GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE = 'gen_ai.request.max_tokens';\n\n/**\n * The frequency penalty setting for the model request\n */\nexport const GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE = 'gen_ai.request.frequency_penalty';\n\n/**\n * The presence penalty setting for the model request\n */\nexport const GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE = 'gen_ai.request.presence_penalty';\n\n/**\n * The top_p (nucleus sampling) setting for the model request\n */\nexport const GEN_AI_REQUEST_TOP_P_ATTRIBUTE = 'gen_ai.request.top_p';\n\n/**\n * The top_k setting for the model request\n */\nexport const GEN_AI_REQUEST_TOP_K_ATTRIBUTE = 'gen_ai.request.top_k';\n\n/**\n * Stop sequences for the model request\n */\nexport const GEN_AI_REQUEST_STOP_SEQUENCES_ATTRIBUTE = 'gen_ai.request.stop_sequences';\n\n/**\n * The encoding format for the model request\n */\nexport const GEN_AI_REQUEST_ENCODING_FORMAT_ATTRIBUTE = 'gen_ai.request.encoding_format';\n\n/**\n * The dimensions for the model request\n */\nexport const GEN_AI_REQUEST_DIMENSIONS_ATTRIBUTE = 'gen_ai.request.dimensions';\n\n/**\n * Array of reasons why the model stopped generating tokens\n */\nexport const GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE = 'gen_ai.response.finish_reasons';\n\n/**\n * The name of the model that generated the response\n */\nexport const GEN_AI_RESPONSE_MODEL_ATTRIBUTE = 'gen_ai.response.model';\n\n/**\n * The unique identifier for the response\n */\nexport const GEN_AI_RESPONSE_ID_ATTRIBUTE = 'gen_ai.response.id';\n\n/**\n * The reason why the model stopped generating tokens\n */\nexport const GEN_AI_RESPONSE_STOP_REASON_ATTRIBUTE = 'gen_ai.response.stop_reason';\n\n/**\n * The number of tokens used in the prompt\n */\nexport const GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE = 'gen_ai.usage.input_tokens';\n\n/**\n * The number of tokens used in the response\n */\nexport const GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE = 'gen_ai.usage.output_tokens';\n\n/**\n * The total number of tokens used (input + output)\n */\nexport const GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE = 'gen_ai.usage.total_tokens';\n\n/**\n * The operation name\n */\nexport const GEN_AI_OPERATION_NAME_ATTRIBUTE = 'gen_ai.operation.name';\n\n/**\n * The prompt messages\n * Only recorded when recordInputs is enabled\n */\nexport const GEN_AI_REQUEST_MESSAGES_ATTRIBUTE = 'gen_ai.request.messages';\n\n/**\n * The response text\n * Only recorded when recordOutputs is enabled\n */\nexport const GEN_AI_RESPONSE_TEXT_ATTRIBUTE = 'gen_ai.response.text';\n\n/**\n * The available tools from incoming request\n * Only recorded when recordInputs is enabled\n */\nexport const GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE = 'gen_ai.request.available_tools';\n\n/**\n * Whether the response is a streaming response\n */\nexport const GEN_AI_RESPONSE_STREAMING_ATTRIBUTE = 'gen_ai.response.streaming';\n\n/**\n * The tool calls from the response\n * Only recorded when recordOutputs is enabled\n */\nexport const GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE = 'gen_ai.response.tool_calls';\n\n/**\n * The agent name\n */\nexport const GEN_AI_AGENT_NAME_ATTRIBUTE = 'gen_ai.agent.name';\n\n/**\n * The pipeline name\n */\nexport const GEN_AI_PIPELINE_NAME_ATTRIBUTE = 'gen_ai.pipeline.name';\n\n/**\n * The number of cache creation input tokens used\n */\nexport const GEN_AI_USAGE_CACHE_CREATION_INPUT_TOKENS_ATTRIBUTE = 'gen_ai.usage.cache_creation_input_tokens';\n\n/**\n * The number of cache read input tokens used\n */\nexport const GEN_AI_USAGE_CACHE_READ_INPUT_TOKENS_ATTRIBUTE = 'gen_ai.usage.cache_read_input_tokens';\n\n/**\n * The number of cache write input tokens used\n */\nexport const GEN_AI_USAGE_INPUT_TOKENS_CACHE_WRITE_ATTRIBUTE = 'gen_ai.usage.input_tokens.cache_write';\n\n/**\n * The number of cached input tokens that were used\n */\nexport const GEN_AI_USAGE_INPUT_TOKENS_CACHED_ATTRIBUTE = 'gen_ai.usage.input_tokens.cached';\n\n/**\n * The span operation name for invoking an agent\n */\nexport const GEN_AI_INVOKE_AGENT_OPERATION_ATTRIBUTE = 'gen_ai.invoke_agent';\n\n// =============================================================================\n// OPENAI-SPECIFIC ATTRIBUTES\n// =============================================================================\n\n/**\n * The response ID from OpenAI\n */\nexport const OPENAI_RESPONSE_ID_ATTRIBUTE = 'openai.response.id';\n\n/**\n * The response model from OpenAI\n */\nexport const OPENAI_RESPONSE_MODEL_ATTRIBUTE = 'openai.response.model';\n\n/**\n * The response timestamp from OpenAI (ISO string)\n */\nexport const OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE = 'openai.response.timestamp';\n\n/**\n * The number of completion tokens used\n */\nexport const OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE = 'openai.usage.completion_tokens';\n\n/**\n * The number of prompt tokens used\n */\nexport const OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE = 'openai.usage.prompt_tokens';\n\n// =============================================================================\n// OPENAI OPERATIONS\n// =============================================================================\n\n/**\n * OpenAI API operations\n */\nexport const OPENAI_OPERATIONS = {\n  CHAT: 'chat',\n  RESPONSES: 'responses',\n  EMBEDDINGS: 'embeddings',\n} as const;\n\n// =============================================================================\n// ANTHROPIC AI OPERATIONS\n// =============================================================================\n\n/**\n * The response timestamp from Anthropic AI (ISO string)\n */\nexport const ANTHROPIC_AI_RESPONSE_TIMESTAMP_ATTRIBUTE = 'anthropic.response.timestamp';\n"],"names":[],"mappings":"AAAA;;;;CAIA,GAEA,gFAAA;AACA,+CAAA;AACA,gFAAA;AAEA;;CAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AACO,MAAM,uBAAA,GAA0B;AAEvC;;;CAGA,GACO,MAAM,uBAAA,GAA0B;AAEvC;;;CAGA,GACO,MAAM,8BAAA,GAAiC;AAE9C;;CAEA,GACO,MAAM,+BAAA,GAAkC;AAE/C;;CAEA,GACO,MAAM,oCAAA,GAAuC;AAEpD;;CAEA,GACO,MAAM,mCAAA,GAAsC;AAEnD;;CAEA,GACO,MAAM,0CAAA,GAA6C;AAE1D;;CAEA,GACO,MAAM,yCAAA,GAA4C;AAEzD;;CAEA,GACO,MAAM,8BAAA,GAAiC;AAE9C;;CAEA,GACO,MAAM,8BAAA,GAAiC;AAO9C;;CAEA,GACO,MAAM,wCAAA,GAA2C;AAExD;;CAEA,GACO,MAAM,mCAAA,GAAsC;AAEnD;;CAEA,GACO,MAAM,wCAAA,GAA2C;AAExD;;CAEA,GACO,MAAM,+BAAA,GAAkC;AAE/C;;CAEA,GACO,MAAM,4BAAA,GAA+B;AAE5C;;CAEA,GACO,MAAM,qCAAA,GAAwC;AAErD;;CAEA,GACO,MAAM,mCAAA,GAAsC;AAEnD;;CAEA,GACO,MAAM,oCAAA,GAAuC;AAEpD;;CAEA,GACO,MAAM,mCAAA,GAAsC;AAEnD;;CAEA,GACO,MAAM,+BAAA,GAAkC;AAE/C;;;CAGA,GACO,MAAM,iCAAA,GAAoC;AAEjD;;;CAGA,GACO,MAAM,8BAAA,GAAiC;AAE9C;;;CAGA,GACO,MAAM,wCAAA,GAA2C;AAExD;;CAEA,GACO,MAAM,mCAAA,GAAsC;AAEnD;;;CAGA,GACO,MAAM,oCAAA,GAAuC;AAEpD;;CAEA,GACO,MAAM,2BAAA,GAA8B;AAE3C;;CAEA,GACO,MAAM,8BAAA,GAAiC;AAE9C;;CAEA,GACO,MAAM,kDAAA,GAAqD;AAElE;;CAEA,GACO,MAAM,8CAAA,GAAiD;AAE9D;;CAEA,GACO,MAAM,+CAAA,GAAkD;AAE/D;;CAEA,GACO,MAAM,0CAAA,GAA6C;AAE1D;;CAEA,GACO,MAAM,uCAAA,GAA0C;AAEvD,gFAAA;AACA,6BAAA;AACA,gFAAA;AAEA;;CAEA,GACO,MAAM,4BAAA,GAA+B;AAE5C;;CAEA,GACO,MAAM,+BAAA,GAAkC;AAE/C;;CAEA,GACO,MAAM,mCAAA,GAAsC;AAEnD;;CAEA,GACO,MAAM,wCAAA,GAA2C;AAExD;;CAEA,GACO,MAAM,oCAAA,GAAuC;AAEpD,gFAAA;AACA,oBAAA;AACA,gFAAA;AAEA;;CAEA,GACO,MAAM,oBAAoB;IAC/B,IAAI,EAAE,MAAM;IACZ,SAAS,EAAE,WAAW;IACtB,UAAU,EAAE,YAAY;AAC1B,CAAA;AAEA,gFAAA;AACA,0BAAA;AACA,gFAAA;AAEA;;CAEA,GACO,MAAM,yCAAA,GAA4C"}},
    {"offset": {"line": 1591, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/ai/messageTruncation.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/ai/messageTruncation.ts"],"sourcesContent":["/**\n * Default maximum size in bytes for GenAI messages.\n * Messages exceeding this limit will be truncated.\n */\nexport const DEFAULT_GEN_AI_MESSAGES_BYTE_LIMIT = 20000;\n\n/**\n * Message format used by OpenAI and Anthropic APIs.\n */\ntype ContentMessage = {\n  [key: string]: unknown;\n  content: string;\n};\n\n/**\n * Message format used by Google GenAI API.\n * Parts can be strings or objects with a text property.\n */\ntype PartsMessage = {\n  [key: string]: unknown;\n  parts: Array<string | { text: string }>;\n};\n\n/**\n * A part in a Google GenAI message that contains text.\n */\ntype TextPart = string | { text: string };\n\n/**\n * Calculate the UTF-8 byte length of a string.\n */\nconst utf8Bytes = (text: string): number => {\n  return new TextEncoder().encode(text).length;\n};\n\n/**\n * Calculate the UTF-8 byte length of a value's JSON representation.\n */\nconst jsonBytes = (value: unknown): number => {\n  return utf8Bytes(JSON.stringify(value));\n};\n\n/**\n * Truncate a string to fit within maxBytes when encoded as UTF-8.\n * Uses binary search for efficiency with multi-byte characters.\n *\n * @param text - The string to truncate\n * @param maxBytes - Maximum byte length (UTF-8 encoded)\n * @returns Truncated string that fits within maxBytes\n */\nfunction truncateTextByBytes(text: string, maxBytes: number): string {\n  if (utf8Bytes(text) <= maxBytes) {\n    return text;\n  }\n\n  let low = 0;\n  let high = text.length;\n  let bestFit = '';\n\n  while (low <= high) {\n    const mid = Math.floor((low + high) / 2);\n    const candidate = text.slice(0, mid);\n    const byteSize = utf8Bytes(candidate);\n\n    if (byteSize <= maxBytes) {\n      bestFit = candidate;\n      low = mid + 1;\n    } else {\n      high = mid - 1;\n    }\n  }\n\n  return bestFit;\n}\n\n/**\n * Extract text content from a Google GenAI message part.\n * Parts are either plain strings or objects with a text property.\n *\n * @returns The text content\n */\nfunction getPartText(part: TextPart): string {\n  if (typeof part === 'string') {\n    return part;\n  }\n  return part.text;\n}\n\n/**\n * Create a new part with updated text content while preserving the original structure.\n *\n * @param part - Original part (string or object)\n * @param text - New text content\n * @returns New part with updated text\n */\nfunction withPartText(part: TextPart, text: string): TextPart {\n  if (typeof part === 'string') {\n    return text;\n  }\n  return { ...part, text };\n}\n\n/**\n * Check if a message has the OpenAI/Anthropic content format.\n */\nfunction isContentMessage(message: unknown): message is ContentMessage {\n  return (\n    message !== null &&\n    typeof message === 'object' &&\n    'content' in message &&\n    typeof (message as ContentMessage).content === 'string'\n  );\n}\n\n/**\n * Check if a message has the Google GenAI parts format.\n */\nfunction isPartsMessage(message: unknown): message is PartsMessage {\n  return (\n    message !== null &&\n    typeof message === 'object' &&\n    'parts' in message &&\n    Array.isArray((message as PartsMessage).parts) &&\n    (message as PartsMessage).parts.length > 0\n  );\n}\n\n/**\n * Truncate a message with `content: string` format (OpenAI/Anthropic).\n *\n * @param message - Message with content property\n * @param maxBytes - Maximum byte limit\n * @returns Array with truncated message, or empty array if it doesn't fit\n */\nfunction truncateContentMessage(message: ContentMessage, maxBytes: number): unknown[] {\n  // Calculate overhead (message structure without content)\n  const emptyMessage = { ...message, content: '' };\n  const overhead = jsonBytes(emptyMessage);\n  const availableForContent = maxBytes - overhead;\n\n  if (availableForContent <= 0) {\n    return [];\n  }\n\n  const truncatedContent = truncateTextByBytes(message.content, availableForContent);\n  return [{ ...message, content: truncatedContent }];\n}\n\n/**\n * Truncate a message with `parts: [...]` format (Google GenAI).\n * Keeps as many complete parts as possible, only truncating the first part if needed.\n *\n * @param message - Message with parts array\n * @param maxBytes - Maximum byte limit\n * @returns Array with truncated message, or empty array if it doesn't fit\n */\nfunction truncatePartsMessage(message: PartsMessage, maxBytes: number): unknown[] {\n  const { parts } = message;\n\n  // Calculate overhead by creating empty text parts\n  const emptyParts = parts.map(part => withPartText(part, ''));\n  const overhead = jsonBytes({ ...message, parts: emptyParts });\n  let remainingBytes = maxBytes - overhead;\n\n  if (remainingBytes <= 0) {\n    return [];\n  }\n\n  // Include parts until we run out of space\n  const includedParts: TextPart[] = [];\n\n  for (const part of parts) {\n    const text = getPartText(part);\n    const textSize = utf8Bytes(text);\n\n    if (textSize <= remainingBytes) {\n      // Part fits: include it as-is\n      includedParts.push(part);\n      remainingBytes -= textSize;\n    } else if (includedParts.length === 0) {\n      // First part doesn't fit: truncate it\n      const truncated = truncateTextByBytes(text, remainingBytes);\n      if (truncated) {\n        includedParts.push(withPartText(part, truncated));\n      }\n      break;\n    } else {\n      // Subsequent part doesn't fit: stop here\n      break;\n    }\n  }\n\n  return includedParts.length > 0 ? [{ ...message, parts: includedParts }] : [];\n}\n\n/**\n * Truncate a single message to fit within maxBytes.\n *\n * Supports two message formats:\n * - OpenAI/Anthropic: `{ ..., content: string }`\n * - Google GenAI: `{ ..., parts: Array<string | {text: string} | non-text> }`\n *\n * @param message - The message to truncate\n * @param maxBytes - Maximum byte limit for the message\n * @returns Array containing the truncated message, or empty array if truncation fails\n */\nfunction truncateSingleMessage(message: unknown, maxBytes: number): unknown[] {\n  if (!message || typeof message !== 'object') {\n    return [];\n  }\n\n  if (isContentMessage(message)) {\n    return truncateContentMessage(message, maxBytes);\n  }\n\n  if (isPartsMessage(message)) {\n    return truncatePartsMessage(message, maxBytes);\n  }\n\n  // Unknown message format: cannot truncate safely\n  return [];\n}\n\n/**\n * Truncate an array of messages to fit within a byte limit.\n *\n * Strategy:\n * - Keeps the newest messages (from the end of the array)\n * - Uses O(n) algorithm: precompute sizes once, then find largest suffix under budget\n * - If no complete messages fit, attempts to truncate the newest single message\n *\n * @param messages - Array of messages to truncate\n * @param maxBytes - Maximum total byte limit for all messages\n * @returns Truncated array of messages\n *\n * @example\n * ```ts\n * const messages = [msg1, msg2, msg3, msg4]; // newest is msg4\n * const truncated = truncateMessagesByBytes(messages, 10000);\n * // Returns [msg3, msg4] if they fit, or [msg4] if only it fits, etc.\n * ```\n */\nexport function truncateMessagesByBytes(messages: unknown[], maxBytes: number): unknown[] {\n  // Early return for empty or invalid input\n  if (!Array.isArray(messages) || messages.length === 0) {\n    return messages;\n  }\n\n  // Fast path: if all messages fit, return as-is\n  const totalBytes = jsonBytes(messages);\n  if (totalBytes <= maxBytes) {\n    return messages;\n  }\n\n  // Precompute each message's JSON size once for efficiency\n  const messageSizes = messages.map(jsonBytes);\n\n  // Find the largest suffix (newest messages) that fits within the budget\n  let bytesUsed = 0;\n  let startIndex = messages.length; // Index where the kept suffix starts\n\n  for (let i = messages.length - 1; i >= 0; i--) {\n    const messageSize = messageSizes[i];\n\n    if (messageSize && bytesUsed + messageSize > maxBytes) {\n      // Adding this message would exceed the budget\n      break;\n    }\n\n    if (messageSize) {\n      bytesUsed += messageSize;\n    }\n    startIndex = i;\n  }\n\n  // If no complete messages fit, try truncating just the newest message\n  if (startIndex === messages.length) {\n    const newestMessage = messages[messages.length - 1];\n    return truncateSingleMessage(newestMessage, maxBytes);\n  }\n\n  // Return the suffix that fits\n  return messages.slice(startIndex);\n}\n\n/**\n * Truncate GenAI messages using the default byte limit.\n *\n * Convenience wrapper around `truncateMessagesByBytes` with the default limit.\n *\n * @param messages - Array of messages to truncate\n * @returns Truncated array of messages\n */\nexport function truncateGenAiMessages(messages: unknown[]): unknown[] {\n  return truncateMessagesByBytes(messages, DEFAULT_GEN_AI_MESSAGES_BYTE_LIMIT);\n}\n\n/**\n * Truncate GenAI string input using the default byte limit.\n *\n * @param input - The string to truncate\n * @returns Truncated string\n */\nexport function truncateGenAiStringInput(input: string): string {\n  return truncateTextByBytes(input, DEFAULT_GEN_AI_MESSAGES_BYTE_LIMIT);\n}\n"],"names":[],"mappings":"AAAA;;;CAGA;;;;;;;;;;AACO,MAAM,kCAAA,GAAqC;AAElD;;CAEA,GAoBA;;CAEA,GACA,MAAM,SAAA,GAAY,CAAC,IAAI,KAAqB;IAC1C,OAAO,IAAI,WAAW,EAAE,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,MAAM;AAC9C,CAAC;AAED;;CAEA,GACA,MAAM,SAAA,GAAY,CAAC,KAAK,KAAsB;IAC5C,OAAO,SAAS,CAAC,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC;AACzC,CAAC;AAED;;;;;;;CAOA,GACA,SAAS,mBAAmB,CAAC,IAAI,EAAU,QAAQ,EAAkB;IACnE,IAAI,SAAS,CAAC,IAAI,CAAA,IAAK,QAAQ,EAAE;QAC/B,OAAO,IAAI;IACb;IAEA,IAAI,GAAA,GAAM,CAAC;IACX,IAAI,IAAA,GAAO,IAAI,CAAC,MAAM;IACtB,IAAI,OAAA,GAAU,EAAE;IAEhB,MAAO,GAAA,IAAO,IAAI,CAAE;QAClB,MAAM,GAAA,GAAM,IAAI,CAAC,KAAK,CAAC,CAAC,GAAA,GAAM,IAAI,IAAI,CAAC,CAAC;QACxC,MAAM,SAAA,GAAY,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC;QACpC,MAAM,QAAA,GAAW,SAAS,CAAC,SAAS,CAAC;QAErC,IAAI,QAAA,IAAY,QAAQ,EAAE;YACxB,OAAA,GAAU,SAAS;YACnB,GAAA,GAAM,GAAA,GAAM,CAAC;QACf,OAAO;YACL,IAAA,GAAO,GAAA,GAAM,CAAC;QAChB;IACF;IAEA,OAAO,OAAO;AAChB;AAEA;;;;;CAKA,GACA,SAAS,WAAW,CAAC,IAAI,EAAoB;IAC3C,IAAI,OAAO,IAAA,KAAS,QAAQ,EAAE;QAC5B,OAAO,IAAI;IACb;IACA,OAAO,IAAI,CAAC,IAAI;AAClB;AAEA;;;;;;CAMA,GACA,SAAS,YAAY,CAAC,IAAI,EAAY,IAAI,EAAoB;IAC5D,IAAI,OAAO,IAAA,KAAS,QAAQ,EAAE;QAC5B,OAAO,IAAI;IACb;IACA,OAAO;QAAE,GAAG,IAAI;QAAE;IAAA,CAAM;AAC1B;AAEA;;CAEA,GACA,SAAS,gBAAgB,CAAC,OAAO,EAAsC;IACrE,OACE,OAAA,KAAY,IAAA,IACZ,OAAO,OAAA,KAAY,QAAA,IACnB,SAAA,IAAa,OAAA,IACb,OAAO,AAAC,OAAA,CAA2B,OAAA,KAAY;AAEnD;AAEA;;CAEA,GACA,SAAS,cAAc,CAAC,OAAO,EAAoC;IACjE,OACE,OAAA,KAAY,IAAA,IACZ,OAAO,OAAA,KAAY,QAAA,IACnB,OAAA,IAAW,OAAA,IACX,KAAK,CAAC,OAAO,CAAC,AAAC,OAAA,CAAyB,KAAK,CAAA,IAC7C,AAAC,OAAA,CAAyB,KAAK,CAAC,MAAA,GAAS;AAE7C;AAEA;;;;;;CAMA,GACA,SAAS,sBAAsB,CAAC,OAAO,EAAkB,QAAQ,EAAqB;IACtF,yDAAA;IACE,MAAM,YAAA,GAAe;QAAE,GAAG,OAAO;QAAE,OAAO,EAAE,EAAA;IAAA,CAAI;IAChD,MAAM,QAAA,GAAW,SAAS,CAAC,YAAY,CAAC;IACxC,MAAM,mBAAA,GAAsB,QAAA,GAAW,QAAQ;IAE/C,IAAI,mBAAA,IAAuB,CAAC,EAAE;QAC5B,OAAO,EAAE;IACX;IAEA,MAAM,gBAAA,GAAmB,mBAAmB,CAAC,OAAO,CAAC,OAAO,EAAE,mBAAmB,CAAC;IAClF,OAAO;QAAC;YAAE,GAAG,OAAO;YAAE,OAAO,EAAE,gBAAA;QAAA,CAAkB;KAAC;AACpD;AAEA;;;;;;;CAOA,GACA,SAAS,oBAAoB,CAAC,OAAO,EAAgB,QAAQ,EAAqB;IAChF,MAAM,EAAE,KAAA,EAAM,GAAI,OAAO;IAE3B,kDAAA;IACE,MAAM,UAAA,GAAa,KAAK,CAAC,GAAG,EAAC,IAAA,GAAQ,YAAY,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;IAC5D,MAAM,QAAA,GAAW,SAAS,CAAC;QAAE,GAAG,OAAO;QAAE,KAAK,EAAE,UAAA;IAAA,CAAY,CAAC;IAC7D,IAAI,cAAA,GAAiB,QAAA,GAAW,QAAQ;IAExC,IAAI,cAAA,IAAkB,CAAC,EAAE;QACvB,OAAO,EAAE;IACX;IAEF,0CAAA;IACE,MAAM,aAAa,GAAe,EAAE;IAEpC,KAAK,MAAM,IAAA,IAAQ,KAAK,CAAE;QACxB,MAAM,IAAA,GAAO,WAAW,CAAC,IAAI,CAAC;QAC9B,MAAM,QAAA,GAAW,SAAS,CAAC,IAAI,CAAC;QAEhC,IAAI,QAAA,IAAY,cAAc,EAAE;YACpC,8BAAA;YACM,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC;YACxB,cAAA,IAAkB,QAAQ;QAC5B,CAAA,MAAO,IAAI,aAAa,CAAC,MAAA,KAAW,CAAC,EAAE;YAC3C,sCAAA;YACM,MAAM,YAAY,mBAAmB,CAAC,IAAI,EAAE,cAAc,CAAC;YAC3D,IAAI,SAAS,EAAE;gBACb,aAAa,CAAC,IAAI,CAAC,YAAY,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;YACnD;YACA;QACF,OAAO;YAEL;QACF;IACF;IAEA,OAAO,aAAa,CAAC,MAAA,GAAS,CAAA,GAAI;QAAC;YAAE,GAAG,OAAO;YAAE,KAAK,EAAE,aAAA;QAAA,CAAe;KAAA,GAAI,EAAE;AAC/E;AAEA;;;;;;;;;;CAUA,GACA,SAAS,qBAAqB,CAAC,OAAO,EAAW,QAAQ,EAAqB;IAC5E,IAAI,CAAC,OAAA,IAAW,OAAO,OAAA,KAAY,QAAQ,EAAE;QAC3C,OAAO,EAAE;IACX;IAEA,IAAI,gBAAgB,CAAC,OAAO,CAAC,EAAE;QAC7B,OAAO,sBAAsB,CAAC,OAAO,EAAE,QAAQ,CAAC;IAClD;IAEA,IAAI,cAAc,CAAC,OAAO,CAAC,EAAE;QAC3B,OAAO,oBAAoB,CAAC,OAAO,EAAE,QAAQ,CAAC;IAChD;IAEF,iDAAA;IACE,OAAO,EAAE;AACX;AAEA;;;;;;;;;;;;;;;;;;CAkBA,GACO,SAAS,uBAAuB,CAAC,QAAQ,EAAa,QAAQ,EAAqB;IAC1F,0CAAA;IACE,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAA,IAAK,QAAQ,CAAC,MAAA,KAAW,CAAC,EAAE;QACrD,OAAO,QAAQ;IACjB;IAEF,+CAAA;IACE,MAAM,UAAA,GAAa,SAAS,CAAC,QAAQ,CAAC;IACtC,IAAI,UAAA,IAAc,QAAQ,EAAE;QAC1B,OAAO,QAAQ;IACjB;IAEF,0DAAA;IACE,MAAM,eAAe,QAAQ,CAAC,GAAG,CAAC,SAAS,CAAC;IAE9C,wEAAA;IACE,IAAI,SAAA,GAAY,CAAC;IACjB,IAAI,UAAA,GAAa,QAAQ,CAAC,MAAM,CAAA,CAAA,qCAAA;IAEhC,IAAK,IAAI,CAAA,GAAI,QAAQ,CAAC,MAAA,GAAS,CAAC,EAAE,CAAA,IAAK,CAAC,EAAE,CAAC,EAAE,CAAE;QAC7C,MAAM,WAAA,GAAc,YAAY,CAAC,CAAC,CAAC;QAEnC,IAAI,WAAA,IAAe,YAAY,WAAA,GAAc,QAAQ,EAAE;YAErD;QACF;QAEA,IAAI,WAAW,EAAE;YACf,SAAA,IAAa,WAAW;QAC1B;QACA,UAAA,GAAa,CAAC;IAChB;IAEF,sEAAA;IACE,IAAI,UAAA,KAAe,QAAQ,CAAC,MAAM,EAAE;QAClC,MAAM,aAAA,GAAgB,QAAQ,CAAC,QAAQ,CAAC,MAAA,GAAS,CAAC,CAAC;QACnD,OAAO,qBAAqB,CAAC,aAAa,EAAE,QAAQ,CAAC;IACvD;IAEF,8BAAA;IACE,OAAO,QAAQ,CAAC,KAAK,CAAC,UAAU,CAAC;AACnC;AAEA;;;;;;;CAOA,GACO,SAAS,qBAAqB,CAAC,QAAQ,EAAwB;IACpE,OAAO,uBAAuB,CAAC,QAAQ,EAAE,kCAAkC,CAAC;AAC9E;AAEA;;;;;CAKA,GACO,SAAS,wBAAwB,CAAC,KAAK,EAAkB;IAC9D,OAAO,mBAAmB,CAAC,KAAK,EAAE,kCAAkC,CAAC;AACvE"}},
    {"offset": {"line": 1849, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/ai/utils.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/ai/utils.ts"],"sourcesContent":["/**\n * Shared utils for AI integrations (OpenAI, Anthropic, Verce.AI, etc.)\n */\nimport type { Span } from '../../types-hoist/span';\nimport {\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE,\n} from './gen-ai-attributes';\nimport { truncateGenAiMessages, truncateGenAiStringInput } from './messageTruncation';\n/**\n * Maps AI method paths to Sentry operation name\n */\nexport function getFinalOperationName(methodPath: string): string {\n  if (methodPath.includes('messages')) {\n    return 'messages';\n  }\n  if (methodPath.includes('completions')) {\n    return 'completions';\n  }\n  if (methodPath.includes('models')) {\n    return 'models';\n  }\n  if (methodPath.includes('chat')) {\n    return 'chat';\n  }\n  return methodPath.split('.').pop() || 'unknown';\n}\n\n/**\n * Get the span operation for AI methods\n * Following Sentry's convention: \"gen_ai.{operation_name}\"\n */\nexport function getSpanOperation(methodPath: string): string {\n  return `gen_ai.${getFinalOperationName(methodPath)}`;\n}\n\n/**\n * Build method path from current traversal\n */\nexport function buildMethodPath(currentPath: string, prop: string): string {\n  return currentPath ? `${currentPath}.${prop}` : prop;\n}\n\n/**\n * Set token usage attributes\n * @param span - The span to add attributes to\n * @param promptTokens - The number of prompt tokens\n * @param completionTokens - The number of completion tokens\n * @param cachedInputTokens - The number of cached input tokens\n * @param cachedOutputTokens - The number of cached output tokens\n */\nexport function setTokenUsageAttributes(\n  span: Span,\n  promptTokens?: number,\n  completionTokens?: number,\n  cachedInputTokens?: number,\n  cachedOutputTokens?: number,\n): void {\n  if (promptTokens !== undefined) {\n    span.setAttributes({\n      [GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE]: promptTokens,\n    });\n  }\n  if (completionTokens !== undefined) {\n    span.setAttributes({\n      [GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE]: completionTokens,\n    });\n  }\n  if (\n    promptTokens !== undefined ||\n    completionTokens !== undefined ||\n    cachedInputTokens !== undefined ||\n    cachedOutputTokens !== undefined\n  ) {\n    /**\n     * Total input tokens in a request is the summation of `input_tokens`,\n     * `cache_creation_input_tokens`, and `cache_read_input_tokens`.\n     */\n    const totalTokens =\n      (promptTokens ?? 0) + (completionTokens ?? 0) + (cachedInputTokens ?? 0) + (cachedOutputTokens ?? 0);\n\n    span.setAttributes({\n      [GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE]: totalTokens,\n    });\n  }\n}\n\n/**\n * Get the truncated JSON string for a string or array of strings.\n *\n * @param value - The string or array of strings to truncate\n * @returns The truncated JSON string\n */\nexport function getTruncatedJsonString<T>(value: T | T[]): string {\n  if (typeof value === 'string') {\n    // Some values are already JSON strings, so we don't need to duplicate the JSON parsing\n    return truncateGenAiStringInput(value);\n  }\n  if (Array.isArray(value)) {\n    // truncateGenAiMessages returns an array of strings, so we need to stringify it\n    const truncatedMessages = truncateGenAiMessages(value);\n    return JSON.stringify(truncatedMessages);\n  }\n  // value is an object, so we need to stringify it\n  return JSON.stringify(value);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAUA;;CAEA,GACO,SAAS,qBAAqB,CAAC,UAAU,EAAkB;IAChE,IAAI,UAAU,CAAC,QAAQ,CAAC,UAAU,CAAC,EAAE;QACnC,OAAO,UAAU;IACnB;IACA,IAAI,UAAU,CAAC,QAAQ,CAAC,aAAa,CAAC,EAAE;QACtC,OAAO,aAAa;IACtB;IACA,IAAI,UAAU,CAAC,QAAQ,CAAC,QAAQ,CAAC,EAAE;QACjC,OAAO,QAAQ;IACjB;IACA,IAAI,UAAU,CAAC,QAAQ,CAAC,MAAM,CAAC,EAAE;QAC/B,OAAO,MAAM;IACf;IACA,OAAO,UAAU,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,GAAG,EAAC,IAAK,SAAS;AACjD;AAEA;;;CAGA,GACO,SAAS,gBAAgB,CAAC,UAAU,EAAkB;IAC3D,OAAO,CAAC,OAAO,EAAE,qBAAqB,CAAC,UAAU,CAAC,CAAC,CAAA;AACA;AAEA;;CAEA,GACA,SAAA,eAAA,CAAA,WAAA,EAAA,IAAA,EAAA;IACA,OAAA,WAAA,GAAA,CAAA,EAAA,WAAA,CAAA,CAAA,EAAA,IAAA,CAAA,CAAA,GAAA,IAAA;AACA;AAEA;;;;;;;CAOA,GACA,SAAA,uBAAA,CACA,IAAA,EACA,YAAA,EACA,gBAAA,EACA,iBAAA,EACA,kBAAA;IAEA,IAAA,YAAA,KAAA,SAAA,EAAA;QACA,IAAA,CAAA,aAAA,CAAA;YACA,CAAA,uSAAA,CAAA,EAAA,YAAA;QACA,CAAA,CAAA;IACA;IACA,IAAA,gBAAA,KAAA,SAAA,EAAA;QACA,IAAA,CAAA,aAAA,CAAA;YACA,CAAA,wSAAA,CAAA,EAAA,gBAAA;QACA,CAAA,CAAA;IACA;IACA,IACA,YAAA,KAAA,SAAA,IACA,gBAAA,KAAA,SAAA,IACA,iBAAA,KAAA,SAAA,IACA,kBAAA,KAAA,WACA;QACA;;;KAGA,GACA,MAAA,WAAA,GACA,CAAA,YAAA,IAAA,CAAA,IAAA,CAAA,gBAAA,IAAA,CAAA,CAAA,GAAA,CAAA,iBAAA,IAAA,CAAA,CAAA,GAAA,CAAA,kBAAA,IAAA,CAAA,CAAA;QAEA,IAAA,CAAA,aAAA,CAAA;YACA,CAAA,uSAAA,CAAA,EAAA,WAAA;QACA,CAAA,CAAA;IACA;AACA;AAEA;;;;;CAKA,GACA,SAAA,sBAAA,CAAA,KAAA,EAAA;IACA,IAAA,OAAA,KAAA,KAAA,QAAA,EAAA;QACA,uFAAA;QACA,WAAA,sRAAA,EAAA,KAAA,CAAA;IACA;IACA,IAAA,KAAA,CAAA,OAAA,CAAA,KAAA,CAAA,EAAA;QACA,gFAAA;QACA,MAAA,iBAAA,OAAA,mRAAA,EAAA,KAAA,CAAA;QACA,OAAA,IAAA,CAAA,SAAA,CAAA,iBAAA,CAAA;IACA;IACA,iDAAA;IACA,OAAA,IAAA,CAAA,SAAA,CAAA,KAAA,CAAA;AACA"}},
    {"offset": {"line": 1945, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/vercel-ai/constants.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/vercel-ai/constants.ts"],"sourcesContent":["import type { Span } from '../../types-hoist/span';\n\n// Global Map to track tool call IDs to their corresponding spans\n// This allows us to capture tool errors and link them to the correct span\nexport const toolCallSpanMap = new Map<string, Span>();\n"],"names":[],"mappings":"AAEA,iEAAA;AACA,0EAAA;;;;;MACa,eAAA,GAAkB,IAAI,GAAG"}},
    {"offset": {"line": 1958, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/vercel-ai/utils.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/vercel-ai/utils.ts"],"sourcesContent":["import type { TraceContext } from '../../types-hoist/context';\nimport type { Span, SpanJSON } from '../../types-hoist/span';\nimport { GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE, GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE } from '../ai/gen-ai-attributes';\nimport { toolCallSpanMap } from './constants';\nimport type { TokenSummary } from './types';\n\n/**\n * Accumulates token data from a span to its parent in the token accumulator map.\n * This function extracts token usage from the current span and adds it to the\n * accumulated totals for its parent span.\n */\nexport function accumulateTokensForParent(span: SpanJSON, tokenAccumulator: Map<string, TokenSummary>): void {\n  const parentSpanId = span.parent_span_id;\n  if (!parentSpanId) {\n    return;\n  }\n\n  const inputTokens = span.data[GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE];\n  const outputTokens = span.data[GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE];\n\n  if (typeof inputTokens === 'number' || typeof outputTokens === 'number') {\n    const existing = tokenAccumulator.get(parentSpanId) || { inputTokens: 0, outputTokens: 0 };\n\n    if (typeof inputTokens === 'number') {\n      existing.inputTokens += inputTokens;\n    }\n    if (typeof outputTokens === 'number') {\n      existing.outputTokens += outputTokens;\n    }\n\n    tokenAccumulator.set(parentSpanId, existing);\n  }\n}\n\n/**\n * Applies accumulated token data to the `gen_ai.invoke_agent` span.\n * Only immediate children of the `gen_ai.invoke_agent` span are considered,\n * since aggregation will automatically occur for each parent span.\n */\nexport function applyAccumulatedTokens(\n  spanOrTrace: SpanJSON | TraceContext,\n  tokenAccumulator: Map<string, TokenSummary>,\n): void {\n  const accumulated = tokenAccumulator.get(spanOrTrace.span_id);\n  if (!accumulated || !spanOrTrace.data) {\n    return;\n  }\n\n  if (accumulated.inputTokens > 0) {\n    spanOrTrace.data[GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE] = accumulated.inputTokens;\n  }\n  if (accumulated.outputTokens > 0) {\n    spanOrTrace.data[GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE] = accumulated.outputTokens;\n  }\n  if (accumulated.inputTokens > 0 || accumulated.outputTokens > 0) {\n    spanOrTrace.data['gen_ai.usage.total_tokens'] = accumulated.inputTokens + accumulated.outputTokens;\n  }\n}\n\n/**\n * Get the span associated with a tool call ID\n */\nexport function _INTERNAL_getSpanForToolCallId(toolCallId: string): Span | undefined {\n  return toolCallSpanMap.get(toolCallId);\n}\n\n/**\n * Clean up the span mapping for a tool call ID\n */\nexport function _INTERNAL_cleanupToolCallSpan(toolCallId: string): void {\n  toolCallSpanMap.delete(toolCallId);\n}\n\n/**\n * Convert an array of tool strings to a JSON string\n */\nexport function convertAvailableToolsToJsonString(tools: unknown[]): string {\n  const toolObjects = tools.map(tool => {\n    if (typeof tool === 'string') {\n      try {\n        return JSON.parse(tool);\n      } catch {\n        return tool;\n      }\n    }\n    return tool;\n  });\n  return JSON.stringify(toolObjects);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAMA;;;;CAIA,GACO,SAAS,yBAAyB,CAAC,IAAI,EAAY,gBAAgB,EAAmC;IAC3G,MAAM,YAAA,GAAe,IAAI,CAAC,cAAc;IACxC,IAAI,CAAC,YAAY,EAAE;QACjB;IACF;IAEA,MAAM,cAAc,IAAI,CAAC,IAAI,CAAC,uSAAmC,CAAC;IAClE,MAAM,eAAe,IAAI,CAAC,IAAI,CAAC,wSAAoC,CAAC;IAEpE,IAAI,OAAO,WAAA,KAAgB,QAAA,IAAY,OAAO,YAAA,KAAiB,QAAQ,EAAE;QACvE,MAAM,QAAA,GAAW,gBAAgB,CAAC,GAAG,CAAC,YAAY,CAAA,IAAK;YAAE,WAAW,EAAE,CAAC;YAAE,YAAY,EAAE;QAAA,CAAG;QAE1F,IAAI,OAAO,WAAA,KAAgB,QAAQ,EAAE;YACnC,QAAQ,CAAC,WAAA,IAAe,WAAW;QACrC;QACA,IAAI,OAAO,YAAA,KAAiB,QAAQ,EAAE;YACpC,QAAQ,CAAC,YAAA,IAAgB,YAAY;QACvC;QAEA,gBAAgB,CAAC,GAAG,CAAC,YAAY,EAAE,QAAQ,CAAC;IAC9C;AACF;AAEA;;;;CAIA,GACO,SAAS,sBAAsB,CACpC,WAAW,EACX,gBAAgB;IAEhB,MAAM,WAAA,GAAc,gBAAgB,CAAC,GAAG,CAAC,WAAW,CAAC,OAAO,CAAC;IAC7D,IAAI,CAAC,WAAA,IAAe,CAAC,WAAW,CAAC,IAAI,EAAE;QACrC;IACF;IAEA,IAAI,WAAW,CAAC,WAAA,GAAc,CAAC,EAAE;QAC/B,WAAW,CAAC,IAAI,CAAC,uSAAmC,CAAA,GAAI,WAAW,CAAC,WAAW;IACjF;IACA,IAAI,WAAW,CAAC,YAAA,GAAe,CAAC,EAAE;QAChC,WAAW,CAAC,IAAI,CAAC,wSAAoC,CAAA,GAAI,WAAW,CAAC,YAAY;IACnF;IACA,IAAI,WAAW,CAAC,WAAA,GAAc,CAAA,IAAK,WAAW,CAAC,YAAA,GAAe,CAAC,EAAE;QAC/D,WAAW,CAAC,IAAI,CAAC,2BAA2B,CAAA,GAAI,WAAW,CAAC,WAAA,GAAc,WAAW,CAAC,YAAY;IACpG;AACF;AAEA;;CAEA,GACO,SAAS,8BAA8B,CAAC,UAAU,EAA4B;IACnF,OAAO,+QAAe,CAAC,GAAG,CAAC,UAAU,CAAC;AACxC;AAEA;;CAEA,GACO,SAAS,6BAA6B,CAAC,UAAU,EAAgB;IACtE,+QAAe,CAAC,MAAM,CAAC,UAAU,CAAC;AACpC;AAEA;;CAEA,GACO,SAAS,iCAAiC,CAAC,KAAK,EAAqB;IAC1E,MAAM,cAAc,KAAK,CAAC,GAAG,EAAC,QAAQ;QACpC,IAAI,OAAO,IAAA,KAAS,QAAQ,EAAE;YAC5B,IAAI;gBACF,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;YACzB,EAAE,OAAM;gBACN,OAAO,IAAI;YACb;QACF;QACA,OAAO,IAAI;IACb,CAAC,CAAC;IACF,OAAO,IAAI,CAAC,SAAS,CAAC,WAAW,CAAC;AACpC"}},
    {"offset": {"line": 2049, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/vercel-ai/vercel-ai-attributes.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/vercel-ai/vercel-ai-attributes.ts"],"sourcesContent":["/* eslint-disable max-lines */\n/**\n * AI SDK Telemetry Attributes\n * Based on https://ai-sdk.dev/docs/ai-sdk-core/telemetry#collected-data\n */\n\n// =============================================================================\n// COMMON ATTRIBUTES\n// =============================================================================\n\n/**\n * Common attribute for operation name across all functions and spans\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#collected-data\n */\nexport const OPERATION_NAME_ATTRIBUTE = 'operation.name';\n\n/**\n * Common attribute for AI operation ID across all functions and spans\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#collected-data\n */\nexport const AI_OPERATION_ID_ATTRIBUTE = 'ai.operationId';\n\n// =============================================================================\n// SHARED ATTRIBUTES\n// =============================================================================\n\n/**\n * `generateText` function - `ai.generateText` span\n * `streamText` function - `ai.streamText` span\n *\n * The prompt that was used when calling the function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamtext-function\n */\nexport const AI_PROMPT_ATTRIBUTE = 'ai.prompt';\n\n/**\n * `generateObject` function - `ai.generateObject` span\n * `streamObject` function - `ai.streamObject` span\n *\n * The JSON schema version of the schema that was passed into the function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generateobject-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamobject-function\n */\nexport const AI_SCHEMA_ATTRIBUTE = 'ai.schema';\n\n/**\n * `generateObject` function - `ai.generateObject` span\n * `streamObject` function - `ai.streamObject` span\n *\n * The name of the schema that was passed into the function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generateobject-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamobject-function\n */\nexport const AI_SCHEMA_NAME_ATTRIBUTE = 'ai.schema.name';\n\n/**\n * `generateObject` function - `ai.generateObject` span\n * `streamObject` function - `ai.streamObject` span\n *\n * The description of the schema that was passed into the function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generateobject-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamobject-function\n */\nexport const AI_SCHEMA_DESCRIPTION_ATTRIBUTE = 'ai.schema.description';\n\n/**\n * `generateObject` function - `ai.generateObject` span\n * `streamObject` function - `ai.streamObject` span\n *\n * The object that was generated (stringified JSON)\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generateobject-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamobject-function\n */\nexport const AI_RESPONSE_OBJECT_ATTRIBUTE = 'ai.response.object';\n\n/**\n * `generateObject` function - `ai.generateObject` span\n * `streamObject` function - `ai.streamObject` span\n *\n * The object generation mode, e.g. `json`\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generateobject-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamobject-function\n */\nexport const AI_SETTINGS_MODE_ATTRIBUTE = 'ai.settings.mode';\n\n/**\n * `generateObject` function - `ai.generateObject` span\n * `streamObject` function - `ai.streamObject` span\n *\n * The output type that was used, e.g. `object` or `no-schema`\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generateobject-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamobject-function\n */\nexport const AI_SETTINGS_OUTPUT_ATTRIBUTE = 'ai.settings.output';\n\n/**\n * `embed` function - `ai.embed.doEmbed` span\n * `embedMany` function - `ai.embedMany` span\n *\n * The values that were passed into the function (array)\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embed-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embedmany-function\n */\nexport const AI_VALUES_ATTRIBUTE = 'ai.values';\n\n/**\n * `embed` function - `ai.embed.doEmbed` span\n * `embedMany` function - `ai.embedMany` span\n *\n * An array of JSON-stringified embeddings\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embed-function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embedmany-function\n */\nexport const AI_EMBEDDINGS_ATTRIBUTE = 'ai.embeddings';\n\n// =============================================================================\n// GENERATETEXT FUNCTION - UNIQUE ATTRIBUTES\n// =============================================================================\n\n/**\n * `generateText` function - `ai.generateText` span\n *\n * The text that was generated\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_RESPONSE_TEXT_ATTRIBUTE = 'ai.response.text';\n\n/**\n * `generateText` function - `ai.generateText` span\n *\n * The tool calls that were made as part of the generation (stringified JSON)\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_RESPONSE_TOOL_CALLS_ATTRIBUTE = 'ai.response.toolCalls';\n\n/**\n * `generateText` function - `ai.generateText` span\n *\n * The reason why the generation finished\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_RESPONSE_FINISH_REASON_ATTRIBUTE = 'ai.response.finishReason';\n\n/**\n * `generateText` function - `ai.generateText` span\n *\n * The maximum number of steps that were set\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_SETTINGS_MAX_STEPS_ATTRIBUTE = 'ai.settings.maxSteps';\n\n/**\n * `generateText` function - `ai.generateText.doGenerate` span\n *\n * The format of the prompt\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_PROMPT_FORMAT_ATTRIBUTE = 'ai.prompt.format';\n\n/**\n * `generateText` function - `ai.generateText.doGenerate` span\n *\n * The messages that were passed into the provider\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_PROMPT_MESSAGES_ATTRIBUTE = 'ai.prompt.messages';\n\n/**\n * `generateText` function - `ai.generateText.doGenerate` span\n *\n * Array of stringified tool definitions\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_PROMPT_TOOLS_ATTRIBUTE = 'ai.prompt.tools';\n\n/**\n * `generateText` function - `ai.generateText.doGenerate` span\n *\n * The stringified tool choice setting (JSON)\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_PROMPT_TOOL_CHOICE_ATTRIBUTE = 'ai.prompt.toolChoice';\n\n// =============================================================================\n// STREAMTEXT FUNCTION - UNIQUE ATTRIBUTES\n// =============================================================================\n\n/**\n * `streamText` function - `ai.streamText.doStream` span\n *\n * The time it took to receive the first chunk in milliseconds\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamtext-function\n */\nexport const AI_RESPONSE_MS_TO_FIRST_CHUNK_ATTRIBUTE = 'ai.response.msToFirstChunk';\n\n/**\n * `streamText` function - `ai.streamText.doStream` span\n *\n * The time it took to receive the finish part of the LLM stream in milliseconds\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamtext-function\n */\nexport const AI_RESPONSE_MS_TO_FINISH_ATTRIBUTE = 'ai.response.msToFinish';\n\n/**\n * `streamText` function - `ai.streamText.doStream` span\n *\n * The average completion tokens per second\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamtext-function\n */\nexport const AI_RESPONSE_AVG_COMPLETION_TOKENS_PER_SECOND_ATTRIBUTE = 'ai.response.avgCompletionTokensPerSecond';\n\n// =============================================================================\n// EMBED FUNCTION - UNIQUE ATTRIBUTES\n// =============================================================================\n\n/**\n * `embed` function - `ai.embed` span\n *\n * The value that was passed into the `embed` function\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embed-function\n */\nexport const AI_VALUE_ATTRIBUTE = 'ai.value';\n\n/**\n * `embed` function - `ai.embed` span\n *\n * A JSON-stringified embedding\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embed-function\n */\nexport const AI_EMBEDDING_ATTRIBUTE = 'ai.embedding';\n\n// =============================================================================\n// BASIC LLM SPAN INFORMATION\n// =============================================================================\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The functionId that was set through `telemetry.functionId`\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const RESOURCE_NAME_ATTRIBUTE = 'resource.name';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The id of the model\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_MODEL_ID_ATTRIBUTE = 'ai.model.id';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The provider of the model\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_MODEL_PROVIDER_ATTRIBUTE = 'ai.model.provider';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The request headers that were passed in through `headers`\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_REQUEST_HEADERS_ATTRIBUTE = 'ai.request.headers';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * Provider specific metadata returned with the generation response\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_RESPONSE_PROVIDER_METADATA_ATTRIBUTE = 'ai.response.providerMetadata';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The maximum number of retries that were set\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_SETTINGS_MAX_RETRIES_ATTRIBUTE = 'ai.settings.maxRetries';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The number of cached input tokens that were used\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_USAGE_CACHED_INPUT_TOKENS_ATTRIBUTE = 'ai.usage.cachedInputTokens';\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The functionId that was set through `telemetry.functionId`\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE = 'ai.telemetry.functionId';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The metadata that was passed in through `telemetry.metadata`\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_TELEMETRY_METADATA_ATTRIBUTE = 'ai.telemetry.metadata';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The number of completion tokens that were used\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE = 'ai.usage.completionTokens';\n\n/**\n * Basic LLM span information\n * Multiple spans\n *\n * The number of prompt tokens that were used\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-llm-span-information\n */\nexport const AI_USAGE_PROMPT_TOKENS_ATTRIBUTE = 'ai.usage.promptTokens';\n\n// =============================================================================\n// CALL LLM SPAN INFORMATION\n// =============================================================================\n\n/**\n * Call LLM span information\n * Individual LLM call spans\n *\n * The model that was used to generate the response\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const AI_RESPONSE_MODEL_ATTRIBUTE = 'ai.response.model';\n\n/**\n * Call LLM span information\n * Individual LLM call spans\n *\n * The id of the response\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const AI_RESPONSE_ID_ATTRIBUTE = 'ai.response.id';\n\n/**\n * Call LLM span information\n * Individual LLM call spans\n *\n * The timestamp of the response\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const AI_RESPONSE_TIMESTAMP_ATTRIBUTE = 'ai.response.timestamp';\n\n// =============================================================================\n// SEMANTIC CONVENTIONS FOR GENAI OPERATIONS\n// =============================================================================\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The provider that was used\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_SYSTEM_ATTRIBUTE = 'gen_ai.system';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The model that was requested\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_REQUEST_MODEL_ATTRIBUTE = 'gen_ai.request.model';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The temperature that was set\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE = 'gen_ai.request.temperature';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The maximum number of tokens that were set\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE = 'gen_ai.request.max_tokens';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The frequency penalty that was set\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE = 'gen_ai.request.frequency_penalty';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The presence penalty that was set\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE = 'gen_ai.request.presence_penalty';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The topK parameter value that was set\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_REQUEST_TOP_K_ATTRIBUTE = 'gen_ai.request.top_k';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The topP parameter value that was set\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_REQUEST_TOP_P_ATTRIBUTE = 'gen_ai.request.top_p';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The stop sequences\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_REQUEST_STOP_SEQUENCES_ATTRIBUTE = 'gen_ai.request.stop_sequences';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The finish reasons that were returned by the provider\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE = 'gen_ai.response.finish_reasons';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The model that was used to generate the response\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_RESPONSE_MODEL_ATTRIBUTE = 'gen_ai.response.model';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The id of the response\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_RESPONSE_ID_ATTRIBUTE = 'gen_ai.response.id';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The number of prompt tokens that were used\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE = 'gen_ai.usage.input_tokens';\n\n/**\n * Semantic Conventions for GenAI operations\n * Individual LLM call spans\n *\n * The number of completion tokens that were used\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#call-llm-span-information\n */\nexport const GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE = 'gen_ai.usage.output_tokens';\n\n// =============================================================================\n// BASIC EMBEDDING SPAN INFORMATION\n// =============================================================================\n\n/**\n * Basic embedding span information\n * Embedding spans\n *\n * The number of tokens that were used\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#basic-embedding-span-information\n */\nexport const AI_USAGE_TOKENS_ATTRIBUTE = 'ai.usage.tokens';\n\n// =============================================================================\n// TOOL CALL SPANS\n// =============================================================================\n\n/**\n * Tool call spans\n * `ai.toolCall` span\n *\n * The name of the tool\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#tool-call-spans\n */\nexport const AI_TOOL_CALL_NAME_ATTRIBUTE = 'ai.toolCall.name';\n\n/**\n * Tool call spans\n * `ai.toolCall` span\n *\n * The id of the tool call\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#tool-call-spans\n */\nexport const AI_TOOL_CALL_ID_ATTRIBUTE = 'ai.toolCall.id';\n\n/**\n * Tool call spans\n * `ai.toolCall` span\n *\n * The parameters of the tool call\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#tool-call-spans\n */\nexport const AI_TOOL_CALL_ARGS_ATTRIBUTE = 'ai.toolCall.args';\n\n/**\n * Tool call spans\n * `ai.toolCall` span\n *\n * The result of the tool call\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#tool-call-spans\n */\nexport const AI_TOOL_CALL_RESULT_ATTRIBUTE = 'ai.toolCall.result';\n\n// =============================================================================\n// SPAN ATTRIBUTE OBJECTS\n// =============================================================================\n\n/**\n * Attributes collected for `ai.generateText` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_GENERATE_TEXT_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_PROMPT: AI_PROMPT_ATTRIBUTE,\n  AI_RESPONSE_TEXT: AI_RESPONSE_TEXT_ATTRIBUTE,\n  AI_RESPONSE_TOOL_CALLS: AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  AI_RESPONSE_FINISH_REASON: AI_RESPONSE_FINISH_REASON_ATTRIBUTE,\n  AI_SETTINGS_MAX_STEPS: AI_SETTINGS_MAX_STEPS_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  AI_USAGE_COMPLETION_TOKENS: AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  AI_USAGE_PROMPT_TOKENS: AI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.generateText.doGenerate` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generatetext-function\n */\nexport const AI_GENERATE_TEXT_DO_GENERATE_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_PROMPT_FORMAT: AI_PROMPT_FORMAT_ATTRIBUTE,\n  AI_PROMPT_MESSAGES: AI_PROMPT_MESSAGES_ATTRIBUTE,\n  AI_PROMPT_TOOLS: AI_PROMPT_TOOLS_ATTRIBUTE,\n  AI_PROMPT_TOOL_CHOICE: AI_PROMPT_TOOL_CHOICE_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  AI_USAGE_COMPLETION_TOKENS: AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  AI_USAGE_PROMPT_TOKENS: AI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n  // Call LLM span information\n  AI_RESPONSE_MODEL: AI_RESPONSE_MODEL_ATTRIBUTE,\n  AI_RESPONSE_ID: AI_RESPONSE_ID_ATTRIBUTE,\n  AI_RESPONSE_TIMESTAMP: AI_RESPONSE_TIMESTAMP_ATTRIBUTE,\n  // Semantic Conventions for GenAI operations\n  GEN_AI_SYSTEM: GEN_AI_SYSTEM_ATTRIBUTE,\n  GEN_AI_REQUEST_MODEL: GEN_AI_REQUEST_MODEL_ATTRIBUTE,\n  GEN_AI_REQUEST_TEMPERATURE: GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE,\n  GEN_AI_REQUEST_MAX_TOKENS: GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE,\n  GEN_AI_REQUEST_FREQUENCY_PENALTY: GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_PRESENCE_PENALTY: GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_K: GEN_AI_REQUEST_TOP_K_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_P: GEN_AI_REQUEST_TOP_P_ATTRIBUTE,\n  GEN_AI_REQUEST_STOP_SEQUENCES: GEN_AI_REQUEST_STOP_SEQUENCES_ATTRIBUTE,\n  GEN_AI_RESPONSE_FINISH_REASONS: GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL: GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID: GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS: GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS: GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.streamText` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamtext-function\n */\nexport const AI_STREAM_TEXT_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_PROMPT: AI_PROMPT_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  AI_USAGE_COMPLETION_TOKENS: AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  AI_USAGE_PROMPT_TOKENS: AI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.streamText.doStream` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamtext-function\n */\nexport const AI_STREAM_TEXT_DO_STREAM_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_RESPONSE_MS_TO_FIRST_CHUNK: AI_RESPONSE_MS_TO_FIRST_CHUNK_ATTRIBUTE,\n  AI_RESPONSE_MS_TO_FINISH: AI_RESPONSE_MS_TO_FINISH_ATTRIBUTE,\n  AI_RESPONSE_AVG_COMPLETION_TOKENS_PER_SECOND: AI_RESPONSE_AVG_COMPLETION_TOKENS_PER_SECOND_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  AI_USAGE_COMPLETION_TOKENS: AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  AI_USAGE_PROMPT_TOKENS: AI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n  // Call LLM span information\n  AI_RESPONSE_MODEL: AI_RESPONSE_MODEL_ATTRIBUTE,\n  AI_RESPONSE_ID: AI_RESPONSE_ID_ATTRIBUTE,\n  AI_RESPONSE_TIMESTAMP: AI_RESPONSE_TIMESTAMP_ATTRIBUTE,\n  // Semantic Conventions for GenAI operations\n  GEN_AI_SYSTEM: GEN_AI_SYSTEM_ATTRIBUTE,\n  GEN_AI_REQUEST_MODEL: GEN_AI_REQUEST_MODEL_ATTRIBUTE,\n  GEN_AI_REQUEST_TEMPERATURE: GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE,\n  GEN_AI_REQUEST_MAX_TOKENS: GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE,\n  GEN_AI_REQUEST_FREQUENCY_PENALTY: GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_PRESENCE_PENALTY: GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_K: GEN_AI_REQUEST_TOP_K_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_P: GEN_AI_REQUEST_TOP_P_ATTRIBUTE,\n  GEN_AI_REQUEST_STOP_SEQUENCES: GEN_AI_REQUEST_STOP_SEQUENCES_ATTRIBUTE,\n  GEN_AI_RESPONSE_FINISH_REASONS: GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL: GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID: GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS: GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS: GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.generateObject` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#generateobject-function\n */\nexport const AI_GENERATE_OBJECT_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_SCHEMA: AI_SCHEMA_ATTRIBUTE,\n  AI_SCHEMA_NAME: AI_SCHEMA_NAME_ATTRIBUTE,\n  AI_SCHEMA_DESCRIPTION: AI_SCHEMA_DESCRIPTION_ATTRIBUTE,\n  AI_RESPONSE_OBJECT: AI_RESPONSE_OBJECT_ATTRIBUTE,\n  AI_SETTINGS_MODE: AI_SETTINGS_MODE_ATTRIBUTE,\n  AI_SETTINGS_OUTPUT: AI_SETTINGS_OUTPUT_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  AI_USAGE_COMPLETION_TOKENS: AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  AI_USAGE_PROMPT_TOKENS: AI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.streamObject` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#streamobject-function\n */\nexport const AI_STREAM_OBJECT_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_SCHEMA: AI_SCHEMA_ATTRIBUTE,\n  AI_SCHEMA_NAME: AI_SCHEMA_NAME_ATTRIBUTE,\n  AI_SCHEMA_DESCRIPTION: AI_SCHEMA_DESCRIPTION_ATTRIBUTE,\n  AI_RESPONSE_OBJECT: AI_RESPONSE_OBJECT_ATTRIBUTE,\n  AI_SETTINGS_MODE: AI_SETTINGS_MODE_ATTRIBUTE,\n  AI_SETTINGS_OUTPUT: AI_SETTINGS_OUTPUT_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  AI_USAGE_COMPLETION_TOKENS: AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  AI_USAGE_PROMPT_TOKENS: AI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.embed` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embed-function\n */\nexport const AI_EMBED_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_VALUE: AI_VALUE_ATTRIBUTE,\n  AI_EMBEDDING: AI_EMBEDDING_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  // Basic embedding span information\n  AI_USAGE_TOKENS: AI_USAGE_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.embed.doEmbed` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embed-function\n */\nexport const AI_EMBED_DO_EMBED_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_VALUES: AI_VALUES_ATTRIBUTE,\n  AI_EMBEDDINGS: AI_EMBEDDINGS_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  // Basic embedding span information\n  AI_USAGE_TOKENS: AI_USAGE_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.embedMany` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#embedmany-function\n */\nexport const AI_EMBED_MANY_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_VALUES: AI_VALUES_ATTRIBUTE,\n  AI_EMBEDDINGS: AI_EMBEDDINGS_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n  // Basic embedding span information\n  AI_USAGE_TOKENS: AI_USAGE_TOKENS_ATTRIBUTE,\n} as const;\n\n/**\n * Attributes collected for `ai.toolCall` span\n * @see https://ai-sdk.dev/docs/ai-sdk-core/telemetry#tool-call-spans\n */\nexport const AI_TOOL_CALL_SPAN_ATTRIBUTES = {\n  OPERATION_NAME: OPERATION_NAME_ATTRIBUTE,\n  AI_OPERATION_ID: AI_OPERATION_ID_ATTRIBUTE,\n  AI_TOOL_CALL_NAME: AI_TOOL_CALL_NAME_ATTRIBUTE,\n  AI_TOOL_CALL_ID: AI_TOOL_CALL_ID_ATTRIBUTE,\n  AI_TOOL_CALL_ARGS: AI_TOOL_CALL_ARGS_ATTRIBUTE,\n  AI_TOOL_CALL_RESULT: AI_TOOL_CALL_RESULT_ATTRIBUTE,\n  // Basic LLM span information\n  RESOURCE_NAME: RESOURCE_NAME_ATTRIBUTE,\n  AI_MODEL_ID: AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER: AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_REQUEST_HEADERS: AI_REQUEST_HEADERS_ATTRIBUTE,\n  AI_SETTINGS_MAX_RETRIES: AI_SETTINGS_MAX_RETRIES_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID: AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TELEMETRY_METADATA: AI_TELEMETRY_METADATA_ATTRIBUTE,\n} as const;\n\n// =============================================================================\n// PROVIDER METADATA\n// =============================================================================\n\n/**\n * OpenAI Provider Metadata\n * @see https://ai-sdk.dev/providers/ai-sdk-providers/openai\n * @see https://github.com/vercel/ai/blob/65e042afde6aad4da9d7a62526ece839eb34f9a5/packages/openai/src/openai-chat-language-model.ts#L397-L416\n * @see https://github.com/vercel/ai/blob/65e042afde6aad4da9d7a62526ece839eb34f9a5/packages/openai/src/responses/openai-responses-language-model.ts#L377C7-L384\n */\ninterface OpenAiProviderMetadata {\n  /**\n   * The number of predicted output tokens that were accepted.\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/openai#predicted-outputs\n   */\n  acceptedPredictionTokens?: number;\n\n  /**\n   * The number of predicted output tokens that were rejected.\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/openai#predicted-outputs\n   */\n  rejectedPredictionTokens?: number;\n\n  /**\n   * The number of reasoning tokens that the model generated.\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/openai#responses-models\n   */\n  reasoningTokens?: number;\n\n  /**\n   * The number of prompt tokens that were a cache hit.\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/openai#responses-models\n   */\n  cachedPromptTokens?: number;\n\n  /**\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/openai#responses-models\n   *\n   * The ID of the response. Can be used to continue a conversation.\n   */\n  responseId?: string;\n}\n\n/**\n * Anthropic Provider Metadata\n * @see https://ai-sdk.dev/providers/ai-sdk-providers/anthropic\n * @see https://github.com/vercel/ai/blob/65e042afde6aad4da9d7a62526ece839eb34f9a5/packages/anthropic/src/anthropic-messages-language-model.ts#L346-L352\n */\ninterface AnthropicProviderMetadata {\n  /**\n   * The number of tokens that were used to create the cache.\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/anthropic#cache-control\n   */\n  cacheCreationInputTokens?: number;\n\n  /**\n   * The number of tokens that were read from the cache.\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/anthropic#cache-control\n   */\n  cacheReadInputTokens?: number;\n\n  /**\n   * Usage metrics for the Anthropic model.\n   */\n  usage?: {\n    input_tokens: number;\n    cache_creation_input_tokens?: number;\n    cache_read_input_tokens?: number;\n    cache_creation?: {\n      ephemeral_5m_input_tokens?: number;\n      ephemeral_1h_input_tokens?: number;\n    };\n    output_tokens?: number;\n    service_tier?: string;\n  };\n}\n\n/**\n * Amazon Bedrock Provider Metadata\n * @see https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock\n * @see https://github.com/vercel/ai/blob/65e042afde6aad4da9d7a62526ece839eb34f9a5/packages/amazon-bedrock/src/bedrock-chat-language-model.ts#L263-L280\n */\ninterface AmazonBedrockProviderMetadata {\n  /**\n   * @see https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ConverseTrace.html\n   */\n  trace?: {\n    /**\n     * The guardrail trace object.\n     * @see https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_GuardrailTraceAssessment.html\n     *\n     * This was purposely left as unknown as it's a complex object. This can be typed in the future\n     * if the SDK decides to support bedrock in a more advanced way.\n     */\n    guardrail?: unknown;\n    /**\n     * The request's prompt router.\n     * @see https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_PromptRouterTrace.html\n     */\n    promptRouter?: {\n      /**\n       * The ID of the invoked model.\n       */\n      invokedModelId?: string;\n    };\n  };\n  usage?: {\n    /**\n     * The number of tokens that were read from the cache.\n     * @see https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock#cache-points\n     */\n    cacheReadInputTokens?: number;\n\n    /**\n     * The number of tokens that were written to the cache.\n     * @see https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock#cache-points\n     */\n    cacheWriteInputTokens?: number;\n  };\n}\n\n/**\n * Google Generative AI Provider Metadata\n * @see https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai\n */\nexport interface GoogleGenerativeAIProviderMetadata {\n  /**\n   * @see https://github.com/vercel/ai/blob/65e042afde6aad4da9d7a62526ece839eb34f9a5/packages/google/src/google-generative-ai-prompt.ts#L28-L30\n   */\n  groundingMetadata: null | {\n    /**\n     * Array of search queries used to retrieve information\n     * @example [\"What's the weather in Chicago this weekend?\"]\n     *\n     * @see https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai#search-grounding\n     */\n    webSearchQueries: string[] | null;\n    /**\n     * Contains the main search result content used as an entry point\n     * The `renderedContent` field contains the formatted content\n     * @see https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai#search-grounding\n     */\n    searchEntryPoint?: {\n      renderedContent: string;\n    } | null;\n    /**\n     * Contains details about how specific response parts are supported by search results\n     * @see https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai#search-grounding\n     */\n    groundingSupports: Array<{\n      /**\n       * Information about the grounded text segment.\n       */\n      segment: {\n        /**\n         * The start index of the text segment.\n         */\n        startIndex?: number | null;\n        /**\n         * The end index of the text segment.\n         */\n        endIndex?: number | null;\n        /**\n         * The actual text segment.\n         */\n        text?: string | null;\n      };\n      /**\n       * References to supporting search result chunks.\n       */\n      groundingChunkIndices?: number[] | null;\n      /**\n       * Confidence scores (0-1) for each supporting chunk.\n       */\n      confidenceScores?: number[] | null;\n    }> | null;\n  };\n  /**\n   * @see https://github.com/vercel/ai/blob/65e042afde6aad4da9d7a62526ece839eb34f9a5/packages/google/src/google-generative-ai-language-model.ts#L620-L627\n   * @see https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters\n   */\n  safetyRatings?: null | unknown;\n}\n\n/**\n * DeepSeek Provider Metadata\n * @see https://ai-sdk.dev/providers/ai-sdk-providers/deepseek\n */\ninterface DeepSeekProviderMetadata {\n  /**\n   * The number of tokens that were cache hits.\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/deepseek#cache-token-usage\n   */\n  promptCacheHitTokens?: number;\n\n  /**\n   * The number of tokens that were cache misses.\n   * @see https://ai-sdk.dev/providers/ai-sdk-providers/deepseek#cache-token-usage\n   */\n  promptCacheMissTokens?: number;\n}\n\n/**\n * Perplexity Provider Metadata\n * @see https://ai-sdk.dev/providers/ai-sdk-providers/perplexity\n */\ninterface PerplexityProviderMetadata {\n  /**\n   * Object containing citationTokens and numSearchQueries metrics\n   */\n  usage?: {\n    citationTokens?: number;\n    numSearchQueries?: number;\n  };\n  /**\n   * Array of image URLs when return_images is enabled.\n   *\n   * You can enable image responses by setting return_images: true in the provider options.\n   * This feature is only available to Perplexity Tier-2 users and above.\n   */\n  images?: Array<{\n    imageUrl?: string;\n    originUrl?: string;\n    height?: number;\n    width?: number;\n  }>;\n}\n\nexport interface ProviderMetadata {\n  openai?: OpenAiProviderMetadata;\n  anthropic?: AnthropicProviderMetadata;\n  bedrock?: AmazonBedrockProviderMetadata;\n  google?: GoogleGenerativeAIProviderMetadata;\n  deepseek?: DeepSeekProviderMetadata;\n  perplexity?: PerplexityProviderMetadata;\n}\n"],"names":[],"mappings":"AAAA,4BAAA,GACA;;;CAGA,GAkBA,gFAAA;AACA,oBAAA;AACA,gFAAA;AAEA;;;;;;;CAOA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AACO,MAAM,mBAAA,GAAsB;AAEnC;;;;;;;CAOA,GACO,MAAM,mBAAA,GAAsB;AAsBnC;;;;;;;CAOA,GACO,MAAM,4BAAA,GAA+B;AA0C5C,gFAAA;AACA,4CAAA;AACA,gFAAA;AAEA;;;;;CAKA,GACO,MAAM,0BAAA,GAA6B;AAE1C;;;;;CAKA,GACO,MAAM,gCAAA,GAAmC;AA0BhD;;;;;CAKA,GACO,MAAM,4BAAA,GAA+B;AAE5C;;;;;CAKA,GACO,MAAM,yBAAA,GAA4B;AAuEzC;;;;;;CAMA,GACO,MAAM,qBAAA,GAAwB;AAErC;;;;;;CAMA,GACO,MAAM,2BAAA,GAA8B;AAW3C;;;;;;CAMA,GACO,MAAM,uCAAA,GAA0C;AAWvD;;;;;;CAMA,GACO,MAAM,sCAAA,GAAyC;AACtD;;;;;;CAMA,GACO,MAAM,kCAAA,GAAqC;AAWlD;;;;;;CAMA,GACO,MAAM,oCAAA,GAAuC;AAEpD;;;;;;CAMA,GACO,MAAM,gCAAA,GAAmC;AA+HhD;;;;;;CAMA,GACO,MAAM,+BAAA,GAAkC;AAW/C;;;;;;CAMA,GACO,MAAM,mCAAA,GAAsC;AAEnD;;;;;;CAMA,GACO,MAAM,oCAAA,GAAuC;AAepD,gFAAA;AACA,kBAAA;AACA,gFAAA;AAEA;;;;;;CAMA,GACO,MAAM,2BAAA,GAA8B;AAE3C;;;;;;CAMA,GACO,MAAM,yBAAA,GAA4B;AAEzC;;;;;;CAMA,GACO,MAAM,2BAAA,GAA8B;AAE3C;;;;;;CAMA,GACO,MAAM,6BAAA,GAAgC"}},
    {"offset": {"line": 2257, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/vercel-ai/index.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/vercel-ai/index.ts"],"sourcesContent":["import type { Client } from '../../client';\nimport { SEMANTIC_ATTRIBUTE_SENTRY_OP, SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN } from '../../semanticAttributes';\nimport type { Event } from '../../types-hoist/event';\nimport type { Span, SpanAttributes, SpanAttributeValue, SpanJSON, SpanOrigin } from '../../types-hoist/span';\nimport { spanToJSON } from '../../utils/spanUtils';\nimport {\n  GEN_AI_USAGE_INPUT_TOKENS_CACHE_WRITE_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_CACHED_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { getTruncatedJsonString } from '../ai/utils';\nimport { toolCallSpanMap } from './constants';\nimport type { TokenSummary } from './types';\nimport { accumulateTokensForParent, applyAccumulatedTokens, convertAvailableToolsToJsonString } from './utils';\nimport type { ProviderMetadata } from './vercel-ai-attributes';\nimport {\n  AI_MODEL_ID_ATTRIBUTE,\n  AI_MODEL_PROVIDER_ATTRIBUTE,\n  AI_PROMPT_ATTRIBUTE,\n  AI_PROMPT_MESSAGES_ATTRIBUTE,\n  AI_PROMPT_TOOLS_ATTRIBUTE,\n  AI_RESPONSE_OBJECT_ATTRIBUTE,\n  AI_RESPONSE_PROVIDER_METADATA_ATTRIBUTE,\n  AI_RESPONSE_TEXT_ATTRIBUTE,\n  AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  AI_SCHEMA_ATTRIBUTE,\n  AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE,\n  AI_TOOL_CALL_ARGS_ATTRIBUTE,\n  AI_TOOL_CALL_ID_ATTRIBUTE,\n  AI_TOOL_CALL_NAME_ATTRIBUTE,\n  AI_TOOL_CALL_RESULT_ATTRIBUTE,\n  AI_USAGE_CACHED_INPUT_TOKENS_ATTRIBUTE,\n  AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  AI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n} from './vercel-ai-attributes';\n\nfunction addOriginToSpan(span: Span, origin: SpanOrigin): void {\n  span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN, origin);\n}\n\n/**\n * Post-process spans emitted by the Vercel AI SDK.\n * This is supposed to be used in `client.on('spanStart', ...)\n */\nfunction onVercelAiSpanStart(span: Span): void {\n  const { data: attributes, description: name } = spanToJSON(span);\n\n  if (!name) {\n    return;\n  }\n\n  // Tool call spans\n  // https://ai-sdk.dev/docs/ai-sdk-core/telemetry#tool-call-spans\n  if (attributes[AI_TOOL_CALL_NAME_ATTRIBUTE] && attributes[AI_TOOL_CALL_ID_ATTRIBUTE] && name === 'ai.toolCall') {\n    processToolCallSpan(span, attributes);\n    return;\n  }\n\n  // The AI and Provider must be defined for generate, stream, and embed spans.\n  // The id of the model\n  const aiModelId = attributes[AI_MODEL_ID_ATTRIBUTE];\n  // the provider of the model\n  const aiModelProvider = attributes[AI_MODEL_PROVIDER_ATTRIBUTE];\n  if (typeof aiModelId !== 'string' || typeof aiModelProvider !== 'string' || !aiModelId || !aiModelProvider) {\n    return;\n  }\n\n  processGenerateSpan(span, name, attributes);\n}\n\nfunction vercelAiEventProcessor(event: Event): Event {\n  if (event.type === 'transaction' && event.spans) {\n    // Map to accumulate token data by parent span ID\n    const tokenAccumulator: Map<string, TokenSummary> = new Map();\n\n    // First pass: process all spans and accumulate token data\n    for (const span of event.spans) {\n      processEndedVercelAiSpan(span);\n\n      // Accumulate token data for parent spans\n      accumulateTokensForParent(span, tokenAccumulator);\n    }\n\n    // Second pass: apply accumulated token data to parent spans\n    for (const span of event.spans) {\n      if (span.op !== 'gen_ai.invoke_agent') {\n        continue;\n      }\n\n      applyAccumulatedTokens(span, tokenAccumulator);\n    }\n\n    // Also apply to root when it is the invoke_agent pipeline\n    const trace = event.contexts?.trace;\n    if (trace && trace.op === 'gen_ai.invoke_agent') {\n      applyAccumulatedTokens(trace, tokenAccumulator);\n    }\n  }\n\n  return event;\n}\n/**\n * Post-process spans emitted by the Vercel AI SDK.\n */\nfunction processEndedVercelAiSpan(span: SpanJSON): void {\n  const { data: attributes, origin } = span;\n\n  if (origin !== 'auto.vercelai.otel') {\n    return;\n  }\n\n  renameAttributeKey(attributes, AI_USAGE_COMPLETION_TOKENS_ATTRIBUTE, GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE);\n  renameAttributeKey(attributes, AI_USAGE_PROMPT_TOKENS_ATTRIBUTE, GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE);\n  renameAttributeKey(attributes, AI_USAGE_CACHED_INPUT_TOKENS_ATTRIBUTE, GEN_AI_USAGE_INPUT_TOKENS_CACHED_ATTRIBUTE);\n\n  if (\n    typeof attributes[GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE] === 'number' &&\n    typeof attributes[GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE] === 'number'\n  ) {\n    attributes['gen_ai.usage.total_tokens'] =\n      attributes[GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE] + attributes[GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE];\n  }\n\n  // Convert the available tools array to a JSON string\n  if (attributes[AI_PROMPT_TOOLS_ATTRIBUTE] && Array.isArray(attributes[AI_PROMPT_TOOLS_ATTRIBUTE])) {\n    attributes[AI_PROMPT_TOOLS_ATTRIBUTE] = convertAvailableToolsToJsonString(\n      attributes[AI_PROMPT_TOOLS_ATTRIBUTE] as unknown[],\n    );\n  }\n\n  // Rename AI SDK attributes to standardized gen_ai attributes\n  renameAttributeKey(attributes, AI_PROMPT_MESSAGES_ATTRIBUTE, 'gen_ai.request.messages');\n  renameAttributeKey(attributes, AI_RESPONSE_TEXT_ATTRIBUTE, 'gen_ai.response.text');\n  renameAttributeKey(attributes, AI_RESPONSE_TOOL_CALLS_ATTRIBUTE, 'gen_ai.response.tool_calls');\n  renameAttributeKey(attributes, AI_RESPONSE_OBJECT_ATTRIBUTE, 'gen_ai.response.object');\n  renameAttributeKey(attributes, AI_PROMPT_TOOLS_ATTRIBUTE, 'gen_ai.request.available_tools');\n\n  renameAttributeKey(attributes, AI_TOOL_CALL_ARGS_ATTRIBUTE, 'gen_ai.tool.input');\n  renameAttributeKey(attributes, AI_TOOL_CALL_RESULT_ATTRIBUTE, 'gen_ai.tool.output');\n\n  renameAttributeKey(attributes, AI_SCHEMA_ATTRIBUTE, 'gen_ai.request.schema');\n\n  addProviderMetadataToAttributes(attributes);\n\n  // Change attributes namespaced with `ai.X` to `vercel.ai.X`\n  for (const key of Object.keys(attributes)) {\n    if (key.startsWith('ai.')) {\n      renameAttributeKey(attributes, key, `vercel.${key}`);\n    }\n  }\n}\n\n/**\n * Renames an attribute key in the provided attributes object if the old key exists.\n * This function safely handles null and undefined values.\n */\nfunction renameAttributeKey(attributes: Record<string, unknown>, oldKey: string, newKey: string): void {\n  if (attributes[oldKey] != null) {\n    attributes[newKey] = attributes[oldKey];\n    // eslint-disable-next-line @typescript-eslint/no-dynamic-delete\n    delete attributes[oldKey];\n  }\n}\n\nfunction processToolCallSpan(span: Span, attributes: SpanAttributes): void {\n  addOriginToSpan(span, 'auto.vercelai.otel');\n  span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.execute_tool');\n  renameAttributeKey(attributes, AI_TOOL_CALL_NAME_ATTRIBUTE, 'gen_ai.tool.name');\n  renameAttributeKey(attributes, AI_TOOL_CALL_ID_ATTRIBUTE, 'gen_ai.tool.call.id');\n\n  // Store the span in our global map using the tool call ID\n  // This allows us to capture tool errors and link them to the correct span\n  const toolCallId = attributes['gen_ai.tool.call.id'];\n\n  if (typeof toolCallId === 'string') {\n    toolCallSpanMap.set(toolCallId, span);\n  }\n\n  // https://opentelemetry.io/docs/specs/semconv/registry/attributes/gen-ai/#gen-ai-tool-type\n  if (!attributes['gen_ai.tool.type']) {\n    span.setAttribute('gen_ai.tool.type', 'function');\n  }\n  const toolName = attributes['gen_ai.tool.name'];\n  if (toolName) {\n    span.updateName(`execute_tool ${toolName}`);\n  }\n}\n\nfunction processGenerateSpan(span: Span, name: string, attributes: SpanAttributes): void {\n  addOriginToSpan(span, 'auto.vercelai.otel');\n\n  const nameWthoutAi = name.replace('ai.', '');\n  span.setAttribute('ai.pipeline.name', nameWthoutAi);\n  span.updateName(nameWthoutAi);\n\n  // If a telemetry name is set and the span represents a pipeline, use it as the operation name.\n  // This name can be set at the request level by adding `experimental_telemetry.functionId`.\n  const functionId = attributes[AI_TELEMETRY_FUNCTION_ID_ATTRIBUTE];\n  if (functionId && typeof functionId === 'string') {\n    span.updateName(`${nameWthoutAi} ${functionId}`);\n    span.setAttribute('gen_ai.function_id', functionId);\n  }\n\n  if (attributes[AI_PROMPT_ATTRIBUTE]) {\n    const truncatedPrompt = getTruncatedJsonString(attributes[AI_PROMPT_ATTRIBUTE] as string | string[]);\n    span.setAttribute('gen_ai.prompt', truncatedPrompt);\n  }\n  if (attributes[AI_MODEL_ID_ATTRIBUTE] && !attributes[GEN_AI_RESPONSE_MODEL_ATTRIBUTE]) {\n    span.setAttribute(GEN_AI_RESPONSE_MODEL_ATTRIBUTE, attributes[AI_MODEL_ID_ATTRIBUTE]);\n  }\n  span.setAttribute('ai.streaming', name.includes('stream'));\n\n  // Generate Spans\n  if (name === 'ai.generateText') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.invoke_agent');\n    return;\n  }\n\n  if (name === 'ai.generateText.doGenerate') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.generate_text');\n    span.updateName(`generate_text ${attributes[AI_MODEL_ID_ATTRIBUTE]}`);\n    return;\n  }\n\n  if (name === 'ai.streamText') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.invoke_agent');\n    return;\n  }\n\n  if (name === 'ai.streamText.doStream') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.stream_text');\n    span.updateName(`stream_text ${attributes[AI_MODEL_ID_ATTRIBUTE]}`);\n    return;\n  }\n\n  if (name === 'ai.generateObject') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.invoke_agent');\n    return;\n  }\n\n  if (name === 'ai.generateObject.doGenerate') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.generate_object');\n    span.updateName(`generate_object ${attributes[AI_MODEL_ID_ATTRIBUTE]}`);\n    return;\n  }\n\n  if (name === 'ai.streamObject') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.invoke_agent');\n    return;\n  }\n\n  if (name === 'ai.streamObject.doStream') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.stream_object');\n    span.updateName(`stream_object ${attributes[AI_MODEL_ID_ATTRIBUTE]}`);\n    return;\n  }\n\n  if (name === 'ai.embed') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.invoke_agent');\n    return;\n  }\n\n  if (name === 'ai.embed.doEmbed') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.embed');\n    span.updateName(`embed ${attributes[AI_MODEL_ID_ATTRIBUTE]}`);\n    return;\n  }\n\n  if (name === 'ai.embedMany') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.invoke_agent');\n    return;\n  }\n\n  if (name === 'ai.embedMany.doEmbed') {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'gen_ai.embed_many');\n    span.updateName(`embed_many ${attributes[AI_MODEL_ID_ATTRIBUTE]}`);\n    return;\n  }\n\n  if (name.startsWith('ai.stream')) {\n    span.setAttribute(SEMANTIC_ATTRIBUTE_SENTRY_OP, 'ai.run');\n    return;\n  }\n}\n\n/**\n * Add event processors to the given client to process Vercel AI spans.\n */\nexport function addVercelAiProcessors(client: Client): void {\n  client.on('spanStart', onVercelAiSpanStart);\n  // Note: We cannot do this on `spanEnd`, because the span cannot be mutated anymore at this point\n  client.addEventProcessor(Object.assign(vercelAiEventProcessor, { id: 'VercelAiEventProcessor' }));\n}\n\nfunction addProviderMetadataToAttributes(attributes: SpanAttributes): void {\n  const providerMetadata = attributes[AI_RESPONSE_PROVIDER_METADATA_ATTRIBUTE] as string | undefined;\n  if (providerMetadata) {\n    try {\n      const providerMetadataObject = JSON.parse(providerMetadata) as ProviderMetadata;\n      if (providerMetadataObject.openai) {\n        setAttributeIfDefined(\n          attributes,\n          GEN_AI_USAGE_INPUT_TOKENS_CACHED_ATTRIBUTE,\n          providerMetadataObject.openai.cachedPromptTokens,\n        );\n        setAttributeIfDefined(\n          attributes,\n          'gen_ai.usage.output_tokens.reasoning',\n          providerMetadataObject.openai.reasoningTokens,\n        );\n        setAttributeIfDefined(\n          attributes,\n          'gen_ai.usage.output_tokens.prediction_accepted',\n          providerMetadataObject.openai.acceptedPredictionTokens,\n        );\n        setAttributeIfDefined(\n          attributes,\n          'gen_ai.usage.output_tokens.prediction_rejected',\n          providerMetadataObject.openai.rejectedPredictionTokens,\n        );\n        setAttributeIfDefined(attributes, 'gen_ai.conversation.id', providerMetadataObject.openai.responseId);\n      }\n\n      if (providerMetadataObject.anthropic) {\n        const cachedInputTokens =\n          providerMetadataObject.anthropic.usage?.cache_read_input_tokens ??\n          providerMetadataObject.anthropic.cacheReadInputTokens;\n        setAttributeIfDefined(attributes, GEN_AI_USAGE_INPUT_TOKENS_CACHED_ATTRIBUTE, cachedInputTokens);\n\n        const cacheWriteInputTokens =\n          providerMetadataObject.anthropic.usage?.cache_creation_input_tokens ??\n          providerMetadataObject.anthropic.cacheCreationInputTokens;\n        setAttributeIfDefined(attributes, GEN_AI_USAGE_INPUT_TOKENS_CACHE_WRITE_ATTRIBUTE, cacheWriteInputTokens);\n      }\n\n      if (providerMetadataObject.bedrock?.usage) {\n        setAttributeIfDefined(\n          attributes,\n          GEN_AI_USAGE_INPUT_TOKENS_CACHED_ATTRIBUTE,\n          providerMetadataObject.bedrock.usage.cacheReadInputTokens,\n        );\n        setAttributeIfDefined(\n          attributes,\n          GEN_AI_USAGE_INPUT_TOKENS_CACHE_WRITE_ATTRIBUTE,\n          providerMetadataObject.bedrock.usage.cacheWriteInputTokens,\n        );\n      }\n\n      if (providerMetadataObject.deepseek) {\n        setAttributeIfDefined(\n          attributes,\n          GEN_AI_USAGE_INPUT_TOKENS_CACHED_ATTRIBUTE,\n          providerMetadataObject.deepseek.promptCacheHitTokens,\n        );\n        setAttributeIfDefined(\n          attributes,\n          'gen_ai.usage.input_tokens.cache_miss',\n          providerMetadataObject.deepseek.promptCacheMissTokens,\n        );\n      }\n    } catch {\n      // Ignore\n    }\n  }\n}\n\n/**\n * Sets an attribute only if the value is not null or undefined.\n */\nfunction setAttributeIfDefined(attributes: SpanAttributes, key: string, value: SpanAttributeValue | undefined): void {\n  if (value != null) {\n    attributes[key] = value;\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAsCA,SAAS,eAAe,CAAC,IAAI,EAAQ,MAAM,EAAoB;IAC7D,IAAI,CAAC,YAAY,CAAC,8QAAgC,EAAE,MAAM,CAAC;AAC7D;AAEA;;;CAGA,GACA,SAAS,mBAAmB,CAAC,IAAI,EAAc;IAC7C,MAAM,EAAE,IAAI,EAAE,UAAU,EAAE,WAAW,EAAE,IAAA,EAAK,OAAI,wPAAU,EAAC,IAAI,CAAC;IAEhE,IAAI,CAAC,IAAI,EAAE;QACT;IACF;IAEF,kBAAA;IACA,gEAAA;IACE,IAAI,UAAU,CAAC,4SAA2B,CAAA,IAAK,UAAU,CAAC,0SAAyB,CAAA,IAAK,IAAA,KAAS,aAAa,EAAE;QAC9G,mBAAmB,CAAC,IAAI,EAAE,UAAU,CAAC;QACrC;IACF;IAEF,6EAAA;IACA,sBAAA;IACE,MAAM,SAAA,GAAY,UAAU,CAAC,sSAAqB,CAAC;IACrD,4BAAA;IACE,MAAM,eAAA,GAAkB,UAAU,CAAC,4SAA2B,CAAC;IAC/D,IAAI,OAAO,SAAA,KAAc,YAAY,OAAO,eAAA,KAAoB,YAAY,CAAC,aAAa,CAAC,eAAe,EAAE;QAC1G;IACF;IAEA,mBAAmB,CAAC,IAAI,EAAE,IAAI,EAAE,UAAU,CAAC;AAC7C;AAEA,SAAS,sBAAsB,CAAC,KAAK,EAAgB;IACnD,IAAI,KAAK,CAAC,IAAA,KAAS,aAAA,IAAiB,KAAK,CAAC,KAAK,EAAE;QACnD,iDAAA;QACI,MAAM,gBAAgB,GAA8B,IAAI,GAAG,EAAE;QAEjE,0DAAA;QACI,KAAK,MAAM,IAAA,IAAQ,KAAK,CAAC,KAAK,CAAE;YAC9B,wBAAwB,CAAC,IAAI,CAAC;YAEpC,yCAAA;gBACM,qRAAyB,EAAC,IAAI,EAAE,gBAAgB,CAAC;QACnD;QAEJ,4DAAA;QACI,KAAK,MAAM,IAAA,IAAQ,KAAK,CAAC,KAAK,CAAE;YAC9B,IAAI,IAAI,CAAC,EAAA,KAAO,qBAAqB,EAAE;gBACrC;YACF;gBAEA,kRAAsB,EAAC,IAAI,EAAE,gBAAgB,CAAC;QAChD;QAEJ,0DAAA;QACI,MAAM,KAAA,GAAQ,KAAK,CAAC,QAAQ,EAAE,KAAK;QACnC,IAAI,KAAA,IAAS,KAAK,CAAC,EAAA,KAAO,qBAAqB,EAAE;gBAC/C,kRAAsB,EAAC,KAAK,EAAE,gBAAgB,CAAC;QACjD;IACF;IAEA,OAAO,KAAK;AACd;AACA;;CAEA,GACA,SAAS,wBAAwB,CAAC,IAAI,EAAkB;IACtD,MAAM,EAAE,IAAI,EAAE,UAAU,EAAE,MAAA,EAAO,GAAI,IAAI;IAEzC,IAAI,MAAA,KAAW,oBAAoB,EAAE;QACnC;IACF;IAEA,kBAAkB,CAAC,UAAU,EAAE,qTAAoC,EAAE,qTAAoC,CAAC;IAC1G,kBAAkB,CAAC,UAAU,EAAE,iTAAgC,EAAE,oTAAmC,CAAC;IACrG,kBAAkB,CAAC,UAAU,EAAE,uTAAsC,EAAE,8SAA0C,CAAC;IAElH,IACE,OAAO,UAAU,CAAC,qTAAoC,CAAA,KAAM,QAAA,IAC5D,OAAO,UAAU,CAAC,oTAAmC,CAAA,KAAM,UAC3D;QACA,UAAU,CAAC,2BAA2B,CAAA,GACpC,UAAU,CAAC,qTAAoC,CAAA,GAAI,UAAU,CAAC,oTAAmC,CAAC;IACtG;IAEF,qDAAA;IACE,IAAI,UAAU,CAAC,0SAAyB,CAAA,IAAK,KAAK,CAAC,OAAO,CAAC,UAAU,CAAC,0SAAyB,CAAC,CAAC,EAAE;QACjG,UAAU,CAAC,0SAAyB,CAAA,OAAI,6RAAiC,EACvE,UAAU,CAAC,0SAAyB,CAAA;IAExC;IAEF,6DAAA;IACE,kBAAkB,CAAC,UAAU,EAAE,6SAA4B,EAAE,yBAAyB,CAAC;IACvF,kBAAkB,CAAC,UAAU,EAAE,2SAA0B,EAAE,sBAAsB,CAAC;IAClF,kBAAkB,CAAC,UAAU,EAAE,iTAAgC,EAAE,4BAA4B,CAAC;IAC9F,kBAAkB,CAAC,UAAU,EAAE,6SAA4B,EAAE,wBAAwB,CAAC;IACtF,kBAAkB,CAAC,UAAU,EAAE,0SAAyB,EAAE,gCAAgC,CAAC;IAE3F,kBAAkB,CAAC,UAAU,EAAE,4SAA2B,EAAE,mBAAmB,CAAC;IAChF,kBAAkB,CAAC,UAAU,EAAE,8SAA6B,EAAE,oBAAoB,CAAC;IAEnF,kBAAkB,CAAC,UAAU,EAAE,oSAAmB,EAAE,uBAAuB,CAAC;IAE5E,+BAA+B,CAAC,UAAU,CAAC;IAE7C,4DAAA;IACE,KAAK,MAAM,GAAA,IAAO,MAAM,CAAC,IAAI,CAAC,UAAU,CAAC,CAAE;QACzC,IAAI,GAAG,CAAC,UAAU,CAAC,KAAK,CAAC,EAAE;YACzB,kBAAkB,CAAC,UAAU,EAAE,GAAG,EAAE,CAAC,OAAO,EAAE,GAAG,CAAC,CAAA,CAAA;QACA;IACA;AACA;AAEA;;;CAGA,GACA,SAAA,kBAAA,CAAA,UAAA,EAAA,MAAA,EAAA,MAAA,EAAA;IACA,IAAA,UAAA,CAAA,MAAA,CAAA,IAAA,IAAA,EAAA;QACA,UAAA,CAAA,MAAA,CAAA,GAAA,UAAA,CAAA,MAAA,CAAA;QACA,gEAAA;QACA,OAAA,UAAA,CAAA,MAAA,CAAA;IACA;AACA;AAEA,SAAA,mBAAA,CAAA,IAAA,EAAA,UAAA,EAAA;IACA,eAAA,CAAA,IAAA,EAAA,oBAAA,CAAA;IACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,qBAAA,CAAA;IACA,kBAAA,CAAA,UAAA,EAAA,4SAAA,EAAA,kBAAA,CAAA;IACA,kBAAA,CAAA,UAAA,EAAA,0SAAA,EAAA,qBAAA,CAAA;IAEA,0DAAA;IACA,0EAAA;IACA,MAAA,UAAA,GAAA,UAAA,CAAA,qBAAA,CAAA;IAEA,IAAA,OAAA,UAAA,KAAA,QAAA,EAAA;QACA,+QAAA,CAAA,GAAA,CAAA,UAAA,EAAA,IAAA,CAAA;IACA;IAEA,2FAAA;IACA,IAAA,CAAA,UAAA,CAAA,kBAAA,CAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,kBAAA,EAAA,UAAA,CAAA;IACA;IACA,MAAA,QAAA,GAAA,UAAA,CAAA,kBAAA,CAAA;IACA,IAAA,QAAA,EAAA;QACA,IAAA,CAAA,UAAA,CAAA,CAAA,aAAA,EAAA,QAAA,CAAA,CAAA,CAAA;IACA;AACA;AAEA,SAAA,mBAAA,CAAA,IAAA,EAAA,IAAA,EAAA,UAAA,EAAA;IACA,eAAA,CAAA,IAAA,EAAA,oBAAA,CAAA;IAEA,MAAA,YAAA,GAAA,IAAA,CAAA,OAAA,CAAA,KAAA,EAAA,EAAA,CAAA;IACA,IAAA,CAAA,YAAA,CAAA,kBAAA,EAAA,YAAA,CAAA;IACA,IAAA,CAAA,UAAA,CAAA,YAAA,CAAA;IAEA,+FAAA;IACA,2FAAA;IACA,MAAA,UAAA,GAAA,UAAA,CAAA,mTAAA,CAAA;IACA,IAAA,UAAA,IAAA,OAAA,UAAA,KAAA,QAAA,EAAA;QACA,IAAA,CAAA,UAAA,CAAA,CAAA,EAAA,YAAA,CAAA,CAAA,EAAA,UAAA,CAAA,CAAA,CAAA;QACA,IAAA,CAAA,YAAA,CAAA,oBAAA,EAAA,UAAA,CAAA;IACA;IAEA,IAAA,UAAA,CAAA,oSAAA,CAAA,EAAA;QACA,MAAA,eAAA,OAAA,wQAAA,EAAA,UAAA,CAAA,oSAAA,CAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,eAAA,EAAA,eAAA,CAAA;IACA;IACA,IAAA,UAAA,CAAA,sSAAA,CAAA,IAAA,CAAA,UAAA,CAAA,gTAAA,CAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,gTAAA,EAAA,UAAA,CAAA,sSAAA,CAAA,CAAA;IACA;IACA,IAAA,CAAA,YAAA,CAAA,cAAA,EAAA,IAAA,CAAA,QAAA,CAAA,QAAA,CAAA,CAAA;IAEA,iBAAA;IACA,IAAA,IAAA,KAAA,iBAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,qBAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,4BAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,sBAAA,CAAA;QACA,IAAA,CAAA,UAAA,CAAA,CAAA,cAAA,EAAA,UAAA,CAAA,sSAAA,CAAA,CAAA,CAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,eAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,qBAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,wBAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,oBAAA,CAAA;QACA,IAAA,CAAA,UAAA,CAAA,CAAA,YAAA,EAAA,UAAA,CAAA,sSAAA,CAAA,CAAA,CAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,mBAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,qBAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,8BAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,wBAAA,CAAA;QACA,IAAA,CAAA,UAAA,CAAA,CAAA,gBAAA,EAAA,UAAA,CAAA,sSAAA,CAAA,CAAA,CAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,iBAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,qBAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,0BAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,sBAAA,CAAA;QACA,IAAA,CAAA,UAAA,CAAA,CAAA,cAAA,EAAA,UAAA,CAAA,sSAAA,CAAA,CAAA,CAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,UAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,qBAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,kBAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,cAAA,CAAA;QACA,IAAA,CAAA,UAAA,CAAA,CAAA,MAAA,EAAA,UAAA,CAAA,sSAAA,CAAA,CAAA,CAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,cAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,qBAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,KAAA,sBAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,mBAAA,CAAA;QACA,IAAA,CAAA,UAAA,CAAA,CAAA,WAAA,EAAA,UAAA,CAAA,sSAAA,CAAA,CAAA,CAAA,CAAA;QACA;IACA;IAEA,IAAA,IAAA,CAAA,UAAA,CAAA,WAAA,CAAA,EAAA;QACA,IAAA,CAAA,YAAA,CAAA,0QAAA,EAAA,QAAA,CAAA;QACA;IACA;AACA;AAEA;;CAEA,GACA,SAAA,qBAAA,CAAA,MAAA,EAAA;IACA,MAAA,CAAA,EAAA,CAAA,WAAA,EAAA,mBAAA,CAAA;IACA,iGAAA;IACA,MAAA,CAAA,iBAAA,CAAA,MAAA,CAAA,MAAA,CAAA,sBAAA,EAAA;QAAA,EAAA,EAAA,wBAAA;IAAA,CAAA,CAAA,CAAA;AACA;AAEA,SAAA,+BAAA,CAAA,UAAA,EAAA;IACA,MAAA,gBAAA,GAAA,UAAA,CAAA,wTAAA,CAAA;IACA,IAAA,gBAAA,EAAA;QACA,IAAA;YACA,MAAA,sBAAA,GAAA,IAAA,CAAA,KAAA,CAAA,gBAAA,CAAA;YACA,IAAA,sBAAA,CAAA,MAAA,EAAA;gBACA,qBAAA,CACA,UAAA,EACA,8SAAA,EACA,sBAAA,CAAA,MAAA,CAAA,kBAAA;gBAEA,qBAAA,CACA,UAAA,EACA,sCAAA,EACA,sBAAA,CAAA,MAAA,CAAA,eAAA;gBAEA,qBAAA,CACA,UAAA,EACA,gDAAA,EACA,sBAAA,CAAA,MAAA,CAAA,wBAAA;gBAEA,qBAAA,CACA,UAAA,EACA,gDAAA,EACA,sBAAA,CAAA,MAAA,CAAA,wBAAA;gBAEA,qBAAA,CAAA,UAAA,EAAA,wBAAA,EAAA,sBAAA,CAAA,MAAA,CAAA,UAAA,CAAA;YACA;YAEA,IAAA,sBAAA,CAAA,SAAA,EAAA;gBACA,MAAA,iBAAA,GACA,sBAAA,CAAA,SAAA,CAAA,KAAA,EAAA,uBAAA,IACA,sBAAA,CAAA,SAAA,CAAA,oBAAA;gBACA,qBAAA,CAAA,UAAA,EAAA,8SAAA,EAAA,iBAAA,CAAA;gBAEA,MAAA,qBAAA,GACA,sBAAA,CAAA,SAAA,CAAA,KAAA,EAAA,2BAAA,IACA,sBAAA,CAAA,SAAA,CAAA,wBAAA;gBACA,qBAAA,CAAA,UAAA,EAAA,mTAAA,EAAA,qBAAA,CAAA;YACA;YAEA,IAAA,sBAAA,CAAA,OAAA,EAAA,KAAA,EAAA;gBACA,qBAAA,CACA,UAAA,EACA,8SAAA,EACA,sBAAA,CAAA,OAAA,CAAA,KAAA,CAAA,oBAAA;gBAEA,qBAAA,CACA,UAAA,EACA,mTAAA,EACA,sBAAA,CAAA,OAAA,CAAA,KAAA,CAAA,qBAAA;YAEA;YAEA,IAAA,sBAAA,CAAA,QAAA,EAAA;gBACA,qBAAA,CACA,UAAA,EACA,8SAAA,EACA,sBAAA,CAAA,QAAA,CAAA,oBAAA;gBAEA,qBAAA,CACA,UAAA,EACA,sCAAA,EACA,sBAAA,CAAA,QAAA,CAAA,qBAAA;YAEA;QACA,CAAA,CAAA,OAAA;QACA,SAAA;QACA;IACA;AACA;AAEA;;CAEA,GACA,SAAA,qBAAA,CAAA,UAAA,EAAA,GAAA,EAAA,KAAA,EAAA;IACA,IAAA,KAAA,IAAA,IAAA,EAAA;QACA,UAAA,CAAA,GAAA,CAAA,GAAA,KAAA;IACA;AACA"}},
    {"offset": {"line": 2524, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/openai/constants.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/openai/constants.ts"],"sourcesContent":["export const OPENAI_INTEGRATION_NAME = 'OpenAI';\n\n// https://platform.openai.com/docs/quickstart?api-mode=responses\n// https://platform.openai.com/docs/quickstart?api-mode=chat\nexport const INSTRUMENTED_METHODS = ['responses.create', 'chat.completions.create', 'embeddings.create'] as const;\nexport const RESPONSES_TOOL_CALL_EVENT_TYPES = [\n  'response.output_item.added',\n  'response.function_call_arguments.delta',\n  'response.function_call_arguments.done',\n  'response.output_item.done',\n] as const;\nexport const RESPONSE_EVENT_TYPES = [\n  'response.created',\n  'response.in_progress',\n  'response.failed',\n  'response.completed',\n  'response.incomplete',\n  'response.queued',\n  'response.output_text.delta',\n  ...RESPONSES_TOOL_CALL_EVENT_TYPES,\n] as const;\n"],"names":[],"mappings":";;;;;;;;;;AAAO,MAAM,uBAAA,GAA0B;AAEvC,iEAAA;AACA,4DAAA;AACO,MAAM,uBAAuB;IAAC,kBAAkB;IAAE,yBAAyB;IAAE,mBAAmB;CAAA;AAChG,MAAM,kCAAkC;IAC7C,4BAA4B;IAC5B,wCAAwC;IACxC,uCAAuC;IACvC,2BAA2B;CAC7B;AACO,MAAM,uBAAuB;IAClC,kBAAkB;IAClB,sBAAsB;IACtB,iBAAiB;IACjB,oBAAoB;IACpB,qBAAqB;IACrB,iBAAiB;IACjB,4BAA4B;OACzB,+BAA+B;CACpC"}},
    {"offset": {"line": 2564, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/openai/utils.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/openai/utils.ts"],"sourcesContent":["import type { Span } from '../../types-hoist/span';\nimport {\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE,\n  OPENAI_OPERATIONS,\n  OPENAI_RESPONSE_ID_ATTRIBUTE,\n  OPENAI_RESPONSE_MODEL_ATTRIBUTE,\n  OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE,\n  OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { INSTRUMENTED_METHODS } from './constants';\nimport type {\n  ChatCompletionChunk,\n  InstrumentedMethod,\n  OpenAiChatCompletionObject,\n  OpenAICreateEmbeddingsObject,\n  OpenAIResponseObject,\n  ResponseStreamingEvent,\n} from './types';\n\n/**\n * Maps OpenAI method paths to Sentry operation names\n */\nexport function getOperationName(methodPath: string): string {\n  if (methodPath.includes('chat.completions')) {\n    return OPENAI_OPERATIONS.CHAT;\n  }\n  if (methodPath.includes('responses')) {\n    return OPENAI_OPERATIONS.RESPONSES;\n  }\n  if (methodPath.includes('embeddings')) {\n    return OPENAI_OPERATIONS.EMBEDDINGS;\n  }\n  return methodPath.split('.').pop() || 'unknown';\n}\n\n/**\n * Get the span operation for OpenAI methods\n * Following Sentry's convention: \"gen_ai.{operation_name}\"\n */\nexport function getSpanOperation(methodPath: string): string {\n  return `gen_ai.${getOperationName(methodPath)}`;\n}\n\n/**\n * Check if a method path should be instrumented\n */\nexport function shouldInstrument(methodPath: string): methodPath is InstrumentedMethod {\n  return INSTRUMENTED_METHODS.includes(methodPath as InstrumentedMethod);\n}\n\n/**\n * Build method path from current traversal\n */\nexport function buildMethodPath(currentPath: string, prop: string): string {\n  return currentPath ? `${currentPath}.${prop}` : prop;\n}\n\n/**\n * Check if response is a Chat Completion object\n */\nexport function isChatCompletionResponse(response: unknown): response is OpenAiChatCompletionObject {\n  return (\n    response !== null &&\n    typeof response === 'object' &&\n    'object' in response &&\n    (response as Record<string, unknown>).object === 'chat.completion'\n  );\n}\n\n/**\n * Check if response is a Responses API object\n */\nexport function isResponsesApiResponse(response: unknown): response is OpenAIResponseObject {\n  return (\n    response !== null &&\n    typeof response === 'object' &&\n    'object' in response &&\n    (response as Record<string, unknown>).object === 'response'\n  );\n}\n\n/**\n * Check if response is an Embeddings API object\n */\nexport function isEmbeddingsResponse(response: unknown): response is OpenAICreateEmbeddingsObject {\n  if (response === null || typeof response !== 'object' || !('object' in response)) {\n    return false;\n  }\n  const responseObject = response as Record<string, unknown>;\n  return (\n    responseObject.object === 'list' &&\n    typeof responseObject.model === 'string' &&\n    responseObject.model.toLowerCase().includes('embedding')\n  );\n}\n\n/**\n * Check if streaming event is from the Responses API\n */\nexport function isResponsesApiStreamEvent(event: unknown): event is ResponseStreamingEvent {\n  return (\n    event !== null &&\n    typeof event === 'object' &&\n    'type' in event &&\n    typeof (event as Record<string, unknown>).type === 'string' &&\n    ((event as Record<string, unknown>).type as string).startsWith('response.')\n  );\n}\n\n/**\n * Check if streaming event is a chat completion chunk\n */\nexport function isChatCompletionChunk(event: unknown): event is ChatCompletionChunk {\n  return (\n    event !== null &&\n    typeof event === 'object' &&\n    'object' in event &&\n    (event as Record<string, unknown>).object === 'chat.completion.chunk'\n  );\n}\n\n/**\n * Add attributes for Chat Completion responses\n */\nexport function addChatCompletionAttributes(\n  span: Span,\n  response: OpenAiChatCompletionObject,\n  recordOutputs?: boolean,\n): void {\n  setCommonResponseAttributes(span, response.id, response.model, response.created);\n  if (response.usage) {\n    setTokenUsageAttributes(\n      span,\n      response.usage.prompt_tokens,\n      response.usage.completion_tokens,\n      response.usage.total_tokens,\n    );\n  }\n  if (Array.isArray(response.choices)) {\n    const finishReasons = response.choices\n      .map(choice => choice.finish_reason)\n      .filter((reason): reason is string => reason !== null);\n    if (finishReasons.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(finishReasons),\n      });\n    }\n\n    // Extract tool calls from all choices (only if recordOutputs is true)\n    if (recordOutputs) {\n      const toolCalls = response.choices\n        .map(choice => choice.message?.tool_calls)\n        .filter(calls => Array.isArray(calls) && calls.length > 0)\n        .flat();\n\n      if (toolCalls.length > 0) {\n        span.setAttributes({\n          [GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE]: JSON.stringify(toolCalls),\n        });\n      }\n    }\n  }\n}\n\n/**\n * Add attributes for Responses API responses\n */\nexport function addResponsesApiAttributes(span: Span, response: OpenAIResponseObject, recordOutputs?: boolean): void {\n  setCommonResponseAttributes(span, response.id, response.model, response.created_at);\n  if (response.status) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify([response.status]),\n    });\n  }\n  if (response.usage) {\n    setTokenUsageAttributes(\n      span,\n      response.usage.input_tokens,\n      response.usage.output_tokens,\n      response.usage.total_tokens,\n    );\n  }\n\n  // Extract function calls from output (only if recordOutputs is true)\n  if (recordOutputs) {\n    const responseWithOutput = response as OpenAIResponseObject & { output?: unknown[] };\n    if (Array.isArray(responseWithOutput.output) && responseWithOutput.output.length > 0) {\n      // Filter for function_call type objects in the output array\n      const functionCalls = responseWithOutput.output.filter(\n        (item): unknown =>\n          typeof item === 'object' && item !== null && (item as Record<string, unknown>).type === 'function_call',\n      );\n\n      if (functionCalls.length > 0) {\n        span.setAttributes({\n          [GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE]: JSON.stringify(functionCalls),\n        });\n      }\n    }\n  }\n}\n\n/**\n * Add attributes for Embeddings API responses\n */\nexport function addEmbeddingsAttributes(span: Span, response: OpenAICreateEmbeddingsObject): void {\n  span.setAttributes({\n    [OPENAI_RESPONSE_MODEL_ATTRIBUTE]: response.model,\n    [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: response.model,\n  });\n\n  if (response.usage) {\n    setTokenUsageAttributes(span, response.usage.prompt_tokens, undefined, response.usage.total_tokens);\n  }\n}\n\n/**\n * Set token usage attributes\n * @param span - The span to add attributes to\n * @param promptTokens - The number of prompt tokens\n * @param completionTokens - The number of completion tokens\n * @param totalTokens - The number of total tokens\n */\nexport function setTokenUsageAttributes(\n  span: Span,\n  promptTokens?: number,\n  completionTokens?: number,\n  totalTokens?: number,\n): void {\n  if (promptTokens !== undefined) {\n    span.setAttributes({\n      [OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE]: promptTokens,\n      [GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE]: promptTokens,\n    });\n  }\n  if (completionTokens !== undefined) {\n    span.setAttributes({\n      [OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE]: completionTokens,\n      [GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE]: completionTokens,\n    });\n  }\n  if (totalTokens !== undefined) {\n    span.setAttributes({\n      [GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE]: totalTokens,\n    });\n  }\n}\n\n/**\n * Set common response attributes\n * @param span - The span to add attributes to\n * @param id - The response id\n * @param model - The response model\n * @param timestamp - The response timestamp\n */\nexport function setCommonResponseAttributes(span: Span, id: string, model: string, timestamp: number): void {\n  span.setAttributes({\n    [OPENAI_RESPONSE_ID_ATTRIBUTE]: id,\n    [GEN_AI_RESPONSE_ID_ATTRIBUTE]: id,\n  });\n  span.setAttributes({\n    [OPENAI_RESPONSE_MODEL_ATTRIBUTE]: model,\n    [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: model,\n  });\n  span.setAttributes({\n    [OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE]: new Date(timestamp * 1000).toISOString(),\n  });\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0BA;;CAEA,GACO,SAAS,gBAAgB,CAAC,UAAU,EAAkB;IAC3D,IAAI,UAAU,CAAC,QAAQ,CAAC,kBAAkB,CAAC,EAAE;QAC3C,OAAO,qRAAiB,CAAC,IAAI;IAC/B;IACA,IAAI,UAAU,CAAC,QAAQ,CAAC,WAAW,CAAC,EAAE;QACpC,OAAO,qRAAiB,CAAC,SAAS;IACpC;IACA,IAAI,UAAU,CAAC,QAAQ,CAAC,YAAY,CAAC,EAAE;QACrC,OAAO,qRAAiB,CAAC,UAAU;IACrC;IACA,OAAO,UAAU,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,GAAG,EAAC,IAAK,SAAS;AACjD;AAEA;;;CAGA,GACO,SAAS,gBAAgB,CAAC,UAAU,EAAkB;IAC3D,OAAO,CAAC,OAAO,EAAE,gBAAgB,CAAC,UAAU,CAAC,CAAC,CAAA;AACA;AAEA;;CAEA,GACA,SAAA,gBAAA,CAAA,UAAA,EAAA;IACA,OAAA,8QAAA,CAAA,QAAA,CAAA,UAAA,EAAA;AACA;AAEA;;CAEA,GACA,SAAA,eAAA,CAAA,WAAA,EAAA,IAAA,EAAA;IACA,OAAA,WAAA,GAAA,CAAA,EAAA,WAAA,CAAA,CAAA,EAAA,IAAA,CAAA,CAAA,GAAA,IAAA;AACA;AAEA;;CAEA,GACA,SAAA,wBAAA,CAAA,QAAA,EAAA;IACA,OACA,QAAA,KAAA,IAAA,IACA,OAAA,QAAA,KAAA,QAAA,IACA,QAAA,IAAA,QAAA,IACA,QAAA,CAAA,MAAA,KAAA;AAEA;AAEA;;CAEA,GACA,SAAA,sBAAA,CAAA,QAAA,EAAA;IACA,OACA,QAAA,KAAA,IAAA,IACA,OAAA,QAAA,KAAA,QAAA,IACA,QAAA,IAAA,QAAA,IACA,QAAA,CAAA,MAAA,KAAA;AAEA;AAEA;;CAEA,GACA,SAAA,oBAAA,CAAA,QAAA,EAAA;IACA,IAAA,QAAA,KAAA,IAAA,IAAA,OAAA,QAAA,KAAA,QAAA,IAAA,CAAA,CAAA,QAAA,IAAA,QAAA,CAAA,EAAA;QACA,OAAA,KAAA;IACA;IACA,MAAA,cAAA,GAAA,QAAA;IACA,OACA,cAAA,CAAA,MAAA,KAAA,MAAA,IACA,OAAA,cAAA,CAAA,KAAA,KAAA,QAAA,IACA,cAAA,CAAA,KAAA,CAAA,WAAA,EAAA,CAAA,QAAA,CAAA,WAAA;AAEA;AAEA;;CAEA,GACA,SAAA,yBAAA,CAAA,KAAA,EAAA;IACA,OACA,KAAA,KAAA,IAAA,IACA,OAAA,KAAA,KAAA,QAAA,IACA,MAAA,IAAA,KAAA,IACA,OAAA,KAAA,CAAA,IAAA,KAAA,QAAA,IACA,KAAA,CAAA,IAAA,CAAA,UAAA,CAAA,WAAA;AAEA;AAEA;;CAEA,GACA,SAAA,qBAAA,CAAA,KAAA,EAAA;IACA,OACA,KAAA,KAAA,IAAA,IACA,OAAA,KAAA,KAAA,QAAA,IACA,QAAA,IAAA,KAAA,IACA,KAAA,CAAA,MAAA,KAAA;AAEA;AAEA;;CAEA,GACA,SAAA,2BAAA,CACA,IAAA,EACA,QAAA,EACA,aAAA;IAEA,2BAAA,CAAA,IAAA,EAAA,QAAA,CAAA,EAAA,EAAA,QAAA,CAAA,KAAA,EAAA,QAAA,CAAA,OAAA,CAAA;IACA,IAAA,QAAA,CAAA,KAAA,EAAA;QACA,uBAAA,CACA,IAAA,EACA,QAAA,CAAA,KAAA,CAAA,aAAA,EACA,QAAA,CAAA,KAAA,CAAA,iBAAA,EACA,QAAA,CAAA,KAAA,CAAA,YAAA;IAEA;IACA,IAAA,KAAA,CAAA,OAAA,CAAA,QAAA,CAAA,OAAA,CAAA,EAAA;QACA,MAAA,aAAA,GAAA,QAAA,CAAA,OAAA,CACA,GAAA,EAAA,MAAA,GAAA,MAAA,CAAA,aAAA,EACA,MAAA,CAAA,CAAA,MAAA,GAAA,MAAA,KAAA,IAAA,CAAA;QACA,IAAA,aAAA,CAAA,MAAA,GAAA,CAAA,EAAA;YACA,IAAA,CAAA,aAAA,CAAA;gBACA,CAAA,4SAAA,CAAA,EAAA,IAAA,CAAA,SAAA,CAAA,aAAA,CAAA;YACA,CAAA,CAAA;QACA;QAEA,sEAAA;QACA,IAAA,aAAA,EAAA;YACA,MAAA,SAAA,GAAA,QAAA,CAAA,OAAA,CACA,GAAA,EAAA,MAAA,GAAA,MAAA,CAAA,OAAA,EAAA,UAAA,EACA,MAAA,EAAA,KAAA,GAAA,KAAA,CAAA,OAAA,CAAA,KAAA,CAAA,IAAA,KAAA,CAAA,MAAA,GAAA,CAAA,EACA,IAAA,EAAA;YAEA,IAAA,SAAA,CAAA,MAAA,GAAA,CAAA,EAAA;gBACA,IAAA,CAAA,aAAA,CAAA;oBACA,CAAA,wSAAA,CAAA,EAAA,IAAA,CAAA,SAAA,CAAA,SAAA,CAAA;gBACA,CAAA,CAAA;YACA;QACA;IACA;AACA;AAEA;;CAEA,GACA,SAAA,yBAAA,CAAA,IAAA,EAAA,QAAA,EAAA,aAAA,EAAA;IACA,2BAAA,CAAA,IAAA,EAAA,QAAA,CAAA,EAAA,EAAA,QAAA,CAAA,KAAA,EAAA,QAAA,CAAA,UAAA,CAAA;IACA,IAAA,QAAA,CAAA,MAAA,EAAA;QACA,IAAA,CAAA,aAAA,CAAA;YACA,CAAA,4SAAA,CAAA,EAAA,IAAA,CAAA,SAAA,CAAA;gBAAA,QAAA,CAAA,MAAA;aAAA,CAAA;QACA,CAAA,CAAA;IACA;IACA,IAAA,QAAA,CAAA,KAAA,EAAA;QACA,uBAAA,CACA,IAAA,EACA,QAAA,CAAA,KAAA,CAAA,YAAA,EACA,QAAA,CAAA,KAAA,CAAA,aAAA,EACA,QAAA,CAAA,KAAA,CAAA,YAAA;IAEA;IAEA,qEAAA;IACA,IAAA,aAAA,EAAA;QACA,MAAA,kBAAA,GAAA,QAAA;QACA,IAAA,KAAA,CAAA,OAAA,CAAA,kBAAA,CAAA,MAAA,CAAA,IAAA,kBAAA,CAAA,MAAA,CAAA,MAAA,GAAA,CAAA,EAAA;YACA,4DAAA;YACA,MAAA,aAAA,GAAA,kBAAA,CAAA,MAAA,CAAA,MAAA,CACA,CAAA,IAAA,GACA,OAAA,IAAA,KAAA,QAAA,IAAA,IAAA,KAAA,IAAA,IAAA,IAAA,CAAA,IAAA,KAAA,eAAA;YAGA,IAAA,aAAA,CAAA,MAAA,GAAA,CAAA,EAAA;gBACA,IAAA,CAAA,aAAA,CAAA;oBACA,CAAA,wSAAA,CAAA,EAAA,IAAA,CAAA,SAAA,CAAA,aAAA,CAAA;gBACA,CAAA,CAAA;YACA;QACA;IACA;AACA;AAEA;;CAEA,GACA,SAAA,uBAAA,CAAA,IAAA,EAAA,QAAA,EAAA;IACA,IAAA,CAAA,aAAA,CAAA;QACA,CAAA,mSAAA,CAAA,EAAA,QAAA,CAAA,KAAA;QACA,CAAA,mSAAA,CAAA,EAAA,QAAA,CAAA,KAAA;IACA,CAAA,CAAA;IAEA,IAAA,QAAA,CAAA,KAAA,EAAA;QACA,uBAAA,CAAA,IAAA,EAAA,QAAA,CAAA,KAAA,CAAA,aAAA,EAAA,SAAA,EAAA,QAAA,CAAA,KAAA,CAAA,YAAA,CAAA;IACA;AACA;AAEA;;;;;;CAMA,GACA,SAAA,uBAAA,CACA,IAAA,EACA,YAAA,EACA,gBAAA,EACA,WAAA;IAEA,IAAA,YAAA,KAAA,SAAA,EAAA;QACA,IAAA,CAAA,aAAA,CAAA;YACA,CAAA,wSAAA,CAAA,EAAA,YAAA;YACA,CAAA,uSAAA,CAAA,EAAA,YAAA;QACA,CAAA,CAAA;IACA;IACA,IAAA,gBAAA,KAAA,SAAA,EAAA;QACA,IAAA,CAAA,aAAA,CAAA;YACA,CAAA,4SAAA,CAAA,EAAA,gBAAA;YACA,CAAA,wSAAA,CAAA,EAAA,gBAAA;QACA,CAAA,CAAA;IACA;IACA,IAAA,WAAA,KAAA,SAAA,EAAA;QACA,IAAA,CAAA,aAAA,CAAA;YACA,CAAA,uSAAA,CAAA,EAAA,WAAA;QACA,CAAA,CAAA;IACA;AACA;AAEA;;;;;;CAMA,GACA,SAAA,2BAAA,CAAA,IAAA,EAAA,EAAA,EAAA,KAAA,EAAA,SAAA,EAAA;IACA,IAAA,CAAA,aAAA,CAAA;QACA,CAAA,gSAAA,CAAA,EAAA,EAAA;QACA,CAAA,gSAAA,CAAA,EAAA,EAAA;IACA,CAAA,CAAA;IACA,IAAA,CAAA,aAAA,CAAA;QACA,CAAA,mSAAA,CAAA,EAAA,KAAA;QACA,CAAA,mSAAA,CAAA,EAAA,KAAA;IACA,CAAA,CAAA;IACA,IAAA,CAAA,aAAA,CAAA;QACA,CAAA,uSAAA,CAAA,EAAA,IAAA,IAAA,CAAA,SAAA,GAAA,IAAA,CAAA,CAAA,WAAA,EAAA;IACA,CAAA,CAAA;AACA"}},
    {"offset": {"line": 2771, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/openai/streaming.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/openai/streaming.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport type { Span } from '../../types-hoist/span';\nimport {\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_STREAMING_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { RESPONSE_EVENT_TYPES } from './constants';\nimport type { OpenAIResponseObject } from './types';\nimport {\n  type ChatCompletionChunk,\n  type ChatCompletionToolCall,\n  type ResponseFunctionCall,\n  type ResponseStreamingEvent,\n} from './types';\nimport {\n  isChatCompletionChunk,\n  isResponsesApiStreamEvent,\n  setCommonResponseAttributes,\n  setTokenUsageAttributes,\n} from './utils';\n\n/**\n * State object used to accumulate information from a stream of OpenAI events/chunks.\n */\ninterface StreamingState {\n  /** Types of events encountered in the stream. */\n  eventTypes: string[];\n  /** Collected response text fragments (for output recording). */\n  responseTexts: string[];\n  /** Reasons for finishing the response, as reported by the API. */\n  finishReasons: string[];\n  /** The response ID. */\n  responseId: string;\n  /** The model name. */\n  responseModel: string;\n  /** The timestamp of the response. */\n  responseTimestamp: number;\n  /** Number of prompt/input tokens used. */\n  promptTokens: number | undefined;\n  /** Number of completion/output tokens used. */\n  completionTokens: number | undefined;\n  /** Total number of tokens used (prompt + completion). */\n  totalTokens: number | undefined;\n  /**\n   * Accumulated tool calls from Chat Completion streaming, indexed by tool call index.\n   * @see https://platform.openai.com/docs/guides/function-calling?api-mode=chat#streaming\n   */\n  chatCompletionToolCalls: Record<number, ChatCompletionToolCall>;\n  /**\n   * Accumulated function calls from Responses API streaming.\n   * @see https://platform.openai.com/docs/guides/function-calling?api-mode=responses#streaming\n   */\n  responsesApiToolCalls: Array<ResponseFunctionCall | unknown>;\n}\n\n/**\n * Processes tool calls from a chat completion chunk delta.\n * Follows the pattern: accumulate by index, then convert to array at the end.\n *\n * @param toolCalls - Array of tool calls from the delta.\n * @param state - The current streaming state to update.\n *\n *  @see https://platform.openai.com/docs/guides/function-calling#streaming\n */\nfunction processChatCompletionToolCalls(toolCalls: ChatCompletionToolCall[], state: StreamingState): void {\n  for (const toolCall of toolCalls) {\n    const index = toolCall.index;\n    if (index === undefined || !toolCall.function) continue;\n\n    // Initialize tool call if this is the first chunk for this index\n    if (!(index in state.chatCompletionToolCalls)) {\n      state.chatCompletionToolCalls[index] = {\n        ...toolCall,\n        function: {\n          name: toolCall.function.name,\n          arguments: toolCall.function.arguments || '',\n        },\n      };\n    } else {\n      // Accumulate function arguments from subsequent chunks\n      const existingToolCall = state.chatCompletionToolCalls[index];\n      if (toolCall.function.arguments && existingToolCall?.function) {\n        existingToolCall.function.arguments += toolCall.function.arguments;\n      }\n    }\n  }\n}\n\n/**\n * Processes a single OpenAI ChatCompletionChunk event, updating the streaming state.\n *\n * @param chunk - The ChatCompletionChunk event to process.\n * @param state - The current streaming state to update.\n * @param recordOutputs - Whether to record output text fragments.\n */\nfunction processChatCompletionChunk(chunk: ChatCompletionChunk, state: StreamingState, recordOutputs: boolean): void {\n  state.responseId = chunk.id ?? state.responseId;\n  state.responseModel = chunk.model ?? state.responseModel;\n  state.responseTimestamp = chunk.created ?? state.responseTimestamp;\n\n  if (chunk.usage) {\n    // For stream responses, the input tokens remain constant across all events in the stream.\n    // Output tokens, however, are only finalized in the last event.\n    // Since we can't guarantee that the last event will include usage data or even be a typed event,\n    // we update the output token values on every event that includes them.\n    // This ensures that output token usage is always set, even if the final event lacks it.\n    state.promptTokens = chunk.usage.prompt_tokens;\n    state.completionTokens = chunk.usage.completion_tokens;\n    state.totalTokens = chunk.usage.total_tokens;\n  }\n\n  for (const choice of chunk.choices ?? []) {\n    if (recordOutputs) {\n      if (choice.delta?.content) {\n        state.responseTexts.push(choice.delta.content);\n      }\n\n      // Handle tool calls from delta\n      if (choice.delta?.tool_calls) {\n        processChatCompletionToolCalls(choice.delta.tool_calls, state);\n      }\n    }\n    if (choice.finish_reason) {\n      state.finishReasons.push(choice.finish_reason);\n    }\n  }\n}\n\n/**\n * Processes a single OpenAI Responses API streaming event, updating the streaming state and span.\n *\n * @param streamEvent - The event to process (may be an error or unknown object).\n * @param state - The current streaming state to update.\n * @param recordOutputs - Whether to record output text fragments.\n * @param span - The span to update with error status if needed.\n */\nfunction processResponsesApiEvent(\n  streamEvent: ResponseStreamingEvent | unknown | Error,\n  state: StreamingState,\n  recordOutputs: boolean,\n  span: Span,\n): void {\n  if (!(streamEvent && typeof streamEvent === 'object')) {\n    state.eventTypes.push('unknown:non-object');\n    return;\n  }\n  if (streamEvent instanceof Error) {\n    span.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n    captureException(streamEvent, {\n      mechanism: {\n        handled: false,\n        type: 'auto.ai.openai.stream-response',\n      },\n    });\n    return;\n  }\n\n  if (!('type' in streamEvent)) return;\n  const event = streamEvent as ResponseStreamingEvent;\n\n  if (!RESPONSE_EVENT_TYPES.includes(event.type)) {\n    state.eventTypes.push(event.type);\n    return;\n  }\n\n  // Handle output text delta\n  if (recordOutputs) {\n    // Handle tool call events for Responses API\n    if (event.type === 'response.output_item.done' && 'item' in event) {\n      state.responsesApiToolCalls.push(event.item);\n    }\n\n    if (event.type === 'response.output_text.delta' && 'delta' in event && event.delta) {\n      state.responseTexts.push(event.delta);\n      return;\n    }\n  }\n\n  if ('response' in event) {\n    const { response } = event as { response: OpenAIResponseObject };\n    state.responseId = response.id ?? state.responseId;\n    state.responseModel = response.model ?? state.responseModel;\n    state.responseTimestamp = response.created_at ?? state.responseTimestamp;\n\n    if (response.usage) {\n      // For stream responses, the input tokens remain constant across all events in the stream.\n      // Output tokens, however, are only finalized in the last event.\n      // Since we can't guarantee that the last event will include usage data or even be a typed event,\n      // we update the output token values on every event that includes them.\n      // This ensures that output token usage is always set, even if the final event lacks it.\n      state.promptTokens = response.usage.input_tokens;\n      state.completionTokens = response.usage.output_tokens;\n      state.totalTokens = response.usage.total_tokens;\n    }\n\n    if (response.status) {\n      state.finishReasons.push(response.status);\n    }\n\n    if (recordOutputs && response.output_text) {\n      state.responseTexts.push(response.output_text);\n    }\n  }\n}\n\n/**\n * Instruments a stream of OpenAI events, updating the provided span with relevant attributes and\n * optionally recording output text. This function yields each event from the input stream as it is processed.\n *\n * @template T - The type of events in the stream.\n * @param stream - The async iterable stream of events to instrument.\n * @param span - The span to add attributes to and to finish at the end of the stream.\n * @param recordOutputs - Whether to record output text fragments in the span.\n * @returns An async generator yielding each event from the input stream.\n */\nexport async function* instrumentStream<T>(\n  stream: AsyncIterable<T>,\n  span: Span,\n  recordOutputs: boolean,\n): AsyncGenerator<T, void, unknown> {\n  const state: StreamingState = {\n    eventTypes: [],\n    responseTexts: [],\n    finishReasons: [],\n    responseId: '',\n    responseModel: '',\n    responseTimestamp: 0,\n    promptTokens: undefined,\n    completionTokens: undefined,\n    totalTokens: undefined,\n    chatCompletionToolCalls: {},\n    responsesApiToolCalls: [],\n  };\n\n  try {\n    for await (const event of stream) {\n      if (isChatCompletionChunk(event)) {\n        processChatCompletionChunk(event as ChatCompletionChunk, state, recordOutputs);\n      } else if (isResponsesApiStreamEvent(event)) {\n        processResponsesApiEvent(event as ResponseStreamingEvent, state, recordOutputs, span);\n      }\n      yield event;\n    }\n  } finally {\n    setCommonResponseAttributes(span, state.responseId, state.responseModel, state.responseTimestamp);\n    setTokenUsageAttributes(span, state.promptTokens, state.completionTokens, state.totalTokens);\n\n    span.setAttributes({\n      [GEN_AI_RESPONSE_STREAMING_ATTRIBUTE]: true,\n    });\n\n    if (state.finishReasons.length) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(state.finishReasons),\n      });\n    }\n\n    if (recordOutputs && state.responseTexts.length) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: state.responseTexts.join(''),\n      });\n    }\n\n    // Set tool calls attribute if any were accumulated\n    const chatCompletionToolCallsArray = Object.values(state.chatCompletionToolCalls);\n    const allToolCalls = [...chatCompletionToolCallsArray, ...state.responsesApiToolCalls];\n\n    if (allToolCalls.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE]: JSON.stringify(allToolCalls),\n      });\n    }\n\n    span.end();\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAwBA;;CAEA,GAgCA;;;;;;;;CAQA,GACA,SAAS,8BAA8B,CAAC,SAAS,EAA4B,KAAK,EAAwB;IACxG,KAAK,MAAM,QAAA,IAAY,SAAS,CAAE;QAChC,MAAM,KAAA,GAAQ,QAAQ,CAAC,KAAK;QAC5B,IAAI,KAAA,KAAU,SAAA,IAAa,CAAC,QAAQ,CAAC,QAAQ,EAAE;QAEnD,iEAAA;QACI,IAAI,CAAA,CAAE,KAAA,IAAS,KAAK,CAAC,uBAAuB,CAAC,EAAE;YAC7C,KAAK,CAAC,uBAAuB,CAAC,KAAK,CAAA,GAAI;gBACrC,GAAG,QAAQ;gBACX,QAAQ,EAAE;oBACR,IAAI,EAAE,QAAQ,CAAC,QAAQ,CAAC,IAAI;oBAC5B,SAAS,EAAE,QAAQ,CAAC,QAAQ,CAAC,SAAA,IAAa,EAAE;gBACtD,CAAS;YACT,CAAO;QACH,OAAO;YACX,uDAAA;YACM,MAAM,mBAAmB,KAAK,CAAC,uBAAuB,CAAC,KAAK,CAAC;YAC7D,IAAI,QAAQ,CAAC,QAAQ,CAAC,SAAA,IAAa,gBAAgB,EAAE,QAAQ,EAAE;gBAC7D,gBAAgB,CAAC,QAAQ,CAAC,SAAA,IAAa,QAAQ,CAAC,QAAQ,CAAC,SAAS;YACpE;QACF;IACF;AACF;AAEA;;;;;;CAMA,GACA,SAAS,0BAA0B,CAAC,KAAK,EAAuB,KAAK,EAAkB,aAAa,EAAiB;IACnH,KAAK,CAAC,UAAA,GAAa,KAAK,CAAC,EAAA,IAAM,KAAK,CAAC,UAAU;IAC/C,KAAK,CAAC,aAAA,GAAgB,KAAK,CAAC,KAAA,IAAS,KAAK,CAAC,aAAa;IACxD,KAAK,CAAC,iBAAA,GAAoB,KAAK,CAAC,OAAA,IAAW,KAAK,CAAC,iBAAiB;IAElE,IAAI,KAAK,CAAC,KAAK,EAAE;QACnB,0FAAA;QACA,gEAAA;QACA,iGAAA;QACA,uEAAA;QACA,wFAAA;QACI,KAAK,CAAC,YAAA,GAAe,KAAK,CAAC,KAAK,CAAC,aAAa;QAC9C,KAAK,CAAC,gBAAA,GAAmB,KAAK,CAAC,KAAK,CAAC,iBAAiB;QACtD,KAAK,CAAC,WAAA,GAAc,KAAK,CAAC,KAAK,CAAC,YAAY;IAC9C;IAEA,KAAK,MAAM,MAAA,IAAU,KAAK,CAAC,OAAA,IAAW,EAAE,CAAE;QACxC,IAAI,aAAa,EAAE;YACjB,IAAI,MAAM,CAAC,KAAK,EAAE,OAAO,EAAE;gBACzB,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,OAAO,CAAC;YAChD;YAEN,+BAAA;YACM,IAAI,MAAM,CAAC,KAAK,EAAE,UAAU,EAAE;gBAC5B,8BAA8B,CAAC,MAAM,CAAC,KAAK,CAAC,UAAU,EAAE,KAAK,CAAC;YAChE;QACF;QACA,IAAI,MAAM,CAAC,aAAa,EAAE;YACxB,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC;QAChD;IACF;AACF;AAEA;;;;;;;CAOA,GACA,SAAS,wBAAwB,CAC/B,WAAW,EACX,KAAK,EACL,aAAa,EACb,IAAI;IAEJ,IAAI,CAAA,CAAE,WAAA,IAAe,OAAO,WAAA,KAAgB,QAAQ,CAAC,EAAE;QACrD,KAAK,CAAC,UAAU,CAAC,IAAI,CAAC,oBAAoB,CAAC;QAC3C;IACF;IACA,IAAI,WAAA,YAAuB,KAAK,EAAE;QAChC,IAAI,CAAC,SAAS,CAAC;YAAE,IAAI,EAAE,kQAAiB;YAAE,OAAO,EAAE,gBAAA;QAAA,CAAkB,CAAC;YACtE,mPAAgB,EAAC,WAAW,EAAE;YAC5B,SAAS,EAAE;gBACT,OAAO,EAAE,KAAK;gBACd,IAAI,EAAE,gCAAgC;YAC9C,CAAO;QACP,CAAK,CAAC;QACF;IACF;IAEA,IAAI,CAAA,CAAE,UAAU,WAAW,CAAC,EAAE;IAC9B,MAAM,KAAA,GAAQ,WAAA;IAEd,IAAI,CAAC,8QAAoB,CAAC,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE;QAC9C,KAAK,CAAC,UAAU,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;QACjC;IACF;IAEF,2BAAA;IACE,IAAI,aAAa,EAAE;QACrB,4CAAA;QACI,IAAI,KAAK,CAAC,IAAA,KAAS,2BAAA,IAA+B,MAAA,IAAU,KAAK,EAAE;YACjE,KAAK,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;QAC9C;QAEA,IAAI,KAAK,CAAC,IAAA,KAAS,4BAAA,IAAgC,OAAA,IAAW,KAAA,IAAS,KAAK,CAAC,KAAK,EAAE;YAClF,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC;YACrC;QACF;IACF;IAEA,IAAI,UAAA,IAAc,KAAK,EAAE;QACvB,MAAM,EAAE,QAAA,EAAS,GAAI,KAAA;QACrB,KAAK,CAAC,UAAA,GAAa,QAAQ,CAAC,EAAA,IAAM,KAAK,CAAC,UAAU;QAClD,KAAK,CAAC,aAAA,GAAgB,QAAQ,CAAC,KAAA,IAAS,KAAK,CAAC,aAAa;QAC3D,KAAK,CAAC,iBAAA,GAAoB,QAAQ,CAAC,UAAA,IAAc,KAAK,CAAC,iBAAiB;QAExE,IAAI,QAAQ,CAAC,KAAK,EAAE;YACxB,0FAAA;YACA,gEAAA;YACA,iGAAA;YACA,uEAAA;YACA,wFAAA;YACM,KAAK,CAAC,YAAA,GAAe,QAAQ,CAAC,KAAK,CAAC,YAAY;YAChD,KAAK,CAAC,gBAAA,GAAmB,QAAQ,CAAC,KAAK,CAAC,aAAa;YACrD,KAAK,CAAC,WAAA,GAAc,QAAQ,CAAC,KAAK,CAAC,YAAY;QACjD;QAEA,IAAI,QAAQ,CAAC,MAAM,EAAE;YACnB,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC;QAC3C;QAEA,IAAI,aAAA,IAAiB,QAAQ,CAAC,WAAW,EAAE;YACzC,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC;QAChD;IACF;AACF;AAEA;;;;;;;;;CASA,GACO,gBAAgB,gBAAgB,CACrC,MAAM,EACN,IAAI,EACJ,aAAa;IAEb,MAAM,KAAK,GAAmB;QAC5B,UAAU,EAAE,EAAE;QACd,aAAa,EAAE,EAAE;QACjB,aAAa,EAAE,EAAE;QACjB,UAAU,EAAE,EAAE;QACd,aAAa,EAAE,EAAE;QACjB,iBAAiB,EAAE,CAAC;QACpB,YAAY,EAAE,SAAS;QACvB,gBAAgB,EAAE,SAAS;QAC3B,WAAW,EAAE,SAAS;QACtB,uBAAuB,EAAE,CAAA,CAAE;QAC3B,qBAAqB,EAAE,EAAE;IAC7B,CAAG;IAED,IAAI;QACF,WAAW,MAAM,KAAA,IAAS,MAAM,CAAE;YAChC,QAAI,2QAAqB,EAAC,KAAK,CAAC,EAAE;gBAChC,0BAA0B,CAAC,KAAA,EAA8B,KAAK,EAAE,aAAa,CAAC;YAChF,CAAA,MAAO,QAAI,+QAAyB,EAAC,KAAK,CAAC,EAAE;gBAC3C,wBAAwB,CAAC,KAAA,EAAiC,KAAK,EAAE,aAAa,EAAE,IAAI,CAAC;YACvF;YACA,MAAM,KAAK;QACb;IACF,SAAU;YACR,iRAA2B,EAAC,IAAI,EAAE,KAAK,CAAC,UAAU,EAAE,KAAK,CAAC,aAAa,EAAE,KAAK,CAAC,iBAAiB,CAAC;YACjG,6QAAuB,EAAC,IAAI,EAAE,KAAK,CAAC,YAAY,EAAE,KAAK,CAAC,gBAAgB,EAAE,KAAK,CAAC,WAAW,CAAC;QAE5F,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,uSAAmC,CAAA,EAAG,IAAI;QACjD,CAAK,CAAC;QAEF,IAAI,KAAK,CAAC,aAAa,CAAC,MAAM,EAAE;YAC9B,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,4SAAwC,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,aAAa,CAAC;YACvF,CAAO,CAAC;QACJ;QAEA,IAAI,aAAA,IAAiB,KAAK,CAAC,aAAa,CAAC,MAAM,EAAE;YAC/C,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,kSAA8B,CAAA,EAAG,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,EAAE,CAAC;YACtE,CAAO,CAAC;QACJ;QAEJ,mDAAA;QACI,MAAM,4BAAA,GAA+B,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,uBAAuB,CAAC;QACjF,MAAM,YAAA,GAAe,CAAC;eAAG,4BAA4B,EAAE;eAAG,KAAK,CAAC,qBAAqB;SAAC;QAEtF,IAAI,YAAY,CAAC,MAAA,GAAS,CAAC,EAAE;YAC3B,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,wSAAoC,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC;YAC5E,CAAO,CAAC;QACJ;QAEA,IAAI,CAAC,GAAG,EAAE;IACZ;AACF"}},
    {"offset": {"line": 2985, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/openai/index.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/openai/index.ts"],"sourcesContent":["import { getCurrentScope } from '../../currentScopes';\nimport { captureException } from '../../exports';\nimport { SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN } from '../../semanticAttributes';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport { startSpan, startSpanManual } from '../../tracing/trace';\nimport type { Span, SpanAttributeValue } from '../../types-hoist/span';\nimport {\n  GEN_AI_OPERATION_NAME_ATTRIBUTE,\n  GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE,\n  GEN_AI_REQUEST_DIMENSIONS_ATTRIBUTE,\n  GEN_AI_REQUEST_ENCODING_FORMAT_ATTRIBUTE,\n  GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_MESSAGES_ATTRIBUTE,\n  GEN_AI_REQUEST_MODEL_ATTRIBUTE,\n  GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_STREAM_ATTRIBUTE,\n  GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_P_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_SYSTEM_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { getTruncatedJsonString } from '../ai/utils';\nimport { OPENAI_INTEGRATION_NAME } from './constants';\nimport { instrumentStream } from './streaming';\nimport type {\n  ChatCompletionChunk,\n  InstrumentedMethod,\n  OpenAiIntegration,\n  OpenAiOptions,\n  OpenAiResponse,\n  OpenAIStream,\n  ResponseStreamingEvent,\n} from './types';\nimport {\n  addChatCompletionAttributes,\n  addEmbeddingsAttributes,\n  addResponsesApiAttributes,\n  buildMethodPath,\n  getOperationName,\n  getSpanOperation,\n  isChatCompletionResponse,\n  isEmbeddingsResponse,\n  isResponsesApiResponse,\n  shouldInstrument,\n} from './utils';\n\n/**\n * Extract request attributes from method arguments\n */\nfunction extractRequestAttributes(args: unknown[], methodPath: string): Record<string, unknown> {\n  const attributes: Record<string, unknown> = {\n    [GEN_AI_SYSTEM_ATTRIBUTE]: 'openai',\n    [GEN_AI_OPERATION_NAME_ATTRIBUTE]: getOperationName(methodPath),\n    [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: 'auto.ai.openai',\n  };\n\n  // Chat completion API accepts web_search_options and tools as parameters\n  // we append web search options to the available tools to capture all tool calls\n  if (args.length > 0 && typeof args[0] === 'object' && args[0] !== null) {\n    const params = args[0] as Record<string, unknown>;\n\n    const tools = Array.isArray(params.tools) ? params.tools : [];\n    const hasWebSearchOptions = params.web_search_options && typeof params.web_search_options === 'object';\n    const webSearchOptions = hasWebSearchOptions\n      ? [{ type: 'web_search_options', ...(params.web_search_options as Record<string, unknown>) }]\n      : [];\n\n    const availableTools = [...tools, ...webSearchOptions];\n\n    if (availableTools.length > 0) {\n      attributes[GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE] = JSON.stringify(availableTools);\n    }\n  }\n\n  if (args.length > 0 && typeof args[0] === 'object' && args[0] !== null) {\n    const params = args[0] as Record<string, unknown>;\n\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = params.model ?? 'unknown';\n    if ('temperature' in params) attributes[GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE] = params.temperature;\n    if ('top_p' in params) attributes[GEN_AI_REQUEST_TOP_P_ATTRIBUTE] = params.top_p;\n    if ('frequency_penalty' in params)\n      attributes[GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE] = params.frequency_penalty;\n    if ('presence_penalty' in params) attributes[GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE] = params.presence_penalty;\n    if ('stream' in params) attributes[GEN_AI_REQUEST_STREAM_ATTRIBUTE] = params.stream;\n    if ('encoding_format' in params) attributes[GEN_AI_REQUEST_ENCODING_FORMAT_ATTRIBUTE] = params.encoding_format;\n    if ('dimensions' in params) attributes[GEN_AI_REQUEST_DIMENSIONS_ATTRIBUTE] = params.dimensions;\n  } else {\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = 'unknown';\n  }\n\n  return attributes;\n}\n\n/**\n * Add response attributes to spans\n * This currently supports both Chat Completion and Responses API responses\n */\nfunction addResponseAttributes(span: Span, result: unknown, recordOutputs?: boolean): void {\n  if (!result || typeof result !== 'object') return;\n\n  const response = result as OpenAiResponse;\n\n  if (isChatCompletionResponse(response)) {\n    addChatCompletionAttributes(span, response, recordOutputs);\n    if (recordOutputs && response.choices?.length) {\n      const responseTexts = response.choices.map(choice => choice.message?.content || '');\n      span.setAttributes({ [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: JSON.stringify(responseTexts) });\n    }\n  } else if (isResponsesApiResponse(response)) {\n    addResponsesApiAttributes(span, response, recordOutputs);\n    if (recordOutputs && response.output_text) {\n      span.setAttributes({ [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: response.output_text });\n    }\n  } else if (isEmbeddingsResponse(response)) {\n    addEmbeddingsAttributes(span, response);\n  }\n}\n\n// Extract and record AI request inputs, if present. This is intentionally separate from response attributes.\nfunction addRequestAttributes(span: Span, params: Record<string, unknown>): void {\n  if ('messages' in params) {\n    const truncatedMessages = getTruncatedJsonString(params.messages);\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: truncatedMessages });\n  }\n  if ('input' in params) {\n    const truncatedInput = getTruncatedJsonString(params.input);\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: truncatedInput });\n  }\n}\n\nfunction getOptionsFromIntegration(): OpenAiOptions {\n  const scope = getCurrentScope();\n  const client = scope.getClient();\n  const integration = client?.getIntegrationByName<OpenAiIntegration>(OPENAI_INTEGRATION_NAME);\n  const shouldRecordInputsAndOutputs = integration ? Boolean(client?.getOptions().sendDefaultPii) : false;\n\n  return {\n    recordInputs: integration?.options?.recordInputs ?? shouldRecordInputsAndOutputs,\n    recordOutputs: integration?.options?.recordOutputs ?? shouldRecordInputsAndOutputs,\n  };\n}\n\n/**\n * Instrument a method with Sentry spans\n * Following Sentry AI Agents Manual Instrumentation conventions\n * @see https://docs.sentry.io/platforms/javascript/guides/node/tracing/instrumentation/ai-agents-module/#manual-instrumentation\n */\nfunction instrumentMethod<T extends unknown[], R>(\n  originalMethod: (...args: T) => Promise<R>,\n  methodPath: InstrumentedMethod,\n  context: unknown,\n  options?: OpenAiOptions,\n): (...args: T) => Promise<R> {\n  return async function instrumentedMethod(...args: T): Promise<R> {\n    const finalOptions = options || getOptionsFromIntegration();\n    const requestAttributes = extractRequestAttributes(args, methodPath);\n    const model = (requestAttributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] as string) || 'unknown';\n    const operationName = getOperationName(methodPath);\n\n    const params = args[0] as Record<string, unknown> | undefined;\n    const isStreamRequested = params && typeof params === 'object' && params.stream === true;\n\n    if (isStreamRequested) {\n      // For streaming responses, use manual span management to properly handle the async generator lifecycle\n      return startSpanManual(\n        {\n          name: `${operationName} ${model} stream-response`,\n          op: getSpanOperation(methodPath),\n          attributes: requestAttributes as Record<string, SpanAttributeValue>,\n        },\n        async (span: Span) => {\n          try {\n            if (finalOptions.recordInputs && args[0] && typeof args[0] === 'object') {\n              addRequestAttributes(span, args[0] as Record<string, unknown>);\n            }\n\n            const result = await originalMethod.apply(context, args);\n\n            return instrumentStream(\n              result as OpenAIStream<ChatCompletionChunk | ResponseStreamingEvent>,\n              span,\n              finalOptions.recordOutputs ?? false,\n            ) as unknown as R;\n          } catch (error) {\n            // For streaming requests that fail before stream creation, we still want to record\n            // them as streaming requests but end the span gracefully\n            span.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n            captureException(error, {\n              mechanism: {\n                handled: false,\n                type: 'auto.ai.openai.stream',\n                data: {\n                  function: methodPath,\n                },\n              },\n            });\n            span.end();\n            throw error;\n          }\n        },\n      );\n    } else {\n      //  Non-streaming responses\n      return startSpan(\n        {\n          name: `${operationName} ${model}`,\n          op: getSpanOperation(methodPath),\n          attributes: requestAttributes as Record<string, SpanAttributeValue>,\n        },\n        async (span: Span) => {\n          try {\n            if (finalOptions.recordInputs && args[0] && typeof args[0] === 'object') {\n              addRequestAttributes(span, args[0] as Record<string, unknown>);\n            }\n\n            const result = await originalMethod.apply(context, args);\n            addResponseAttributes(span, result, finalOptions.recordOutputs);\n            return result;\n          } catch (error) {\n            captureException(error, {\n              mechanism: {\n                handled: false,\n                type: 'auto.ai.openai',\n                data: {\n                  function: methodPath,\n                },\n              },\n            });\n            throw error;\n          }\n        },\n      );\n    }\n  };\n}\n\n/**\n * Create a deep proxy for OpenAI client instrumentation\n */\nfunction createDeepProxy<T extends object>(target: T, currentPath = '', options?: OpenAiOptions): T {\n  return new Proxy(target, {\n    get(obj: object, prop: string): unknown {\n      const value = (obj as Record<string, unknown>)[prop];\n      const methodPath = buildMethodPath(currentPath, String(prop));\n\n      if (typeof value === 'function' && shouldInstrument(methodPath)) {\n        return instrumentMethod(value as (...args: unknown[]) => Promise<unknown>, methodPath, obj, options);\n      }\n\n      if (typeof value === 'function') {\n        // Bind non-instrumented functions to preserve the original `this` context,\n        // which is required for accessing private class fields (e.g. #baseURL) in OpenAI SDK v5.\n        return value.bind(obj);\n      }\n\n      if (value && typeof value === 'object') {\n        return createDeepProxy(value, methodPath, options);\n      }\n\n      return value;\n    },\n  }) as T;\n}\n\n/**\n * Instrument an OpenAI client with Sentry tracing\n * Can be used across Node.js, Cloudflare Workers, and Vercel Edge\n */\nexport function instrumentOpenAiClient<T extends object>(client: T, options?: OpenAiOptions): T {\n  return createDeepProxy(client, '', options);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;AA8CA;;CAEA,GACA,SAAS,wBAAwB,CAAC,IAAI,EAAa,UAAU,EAAmC;IAC9F,MAAM,UAAU,GAA4B;QAC1C,CAAC,2RAAuB,CAAA,EAAG,QAAQ;QACnC,CAAC,mSAA+B,CAAA,MAAG,sQAAgB,EAAC,UAAU,CAAC;QAC/D,CAAC,8QAAgC,CAAA,EAAG,gBAAgB;IACxD,CAAG;IAEH,yEAAA;IACA,gFAAA;IACE,IAAI,IAAI,CAAC,MAAA,GAAS,CAAA,IAAK,OAAO,IAAI,CAAC,CAAC,CAAA,KAAM,YAAY,IAAI,CAAC,CAAC,CAAA,KAAM,IAAI,EAAE;QACtE,MAAM,MAAA,GAAS,IAAI,CAAC,CAAC,CAAA;QAErB,MAAM,KAAA,GAAQ,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,KAAK,IAAI,MAAM,CAAC,KAAA,GAAQ,EAAE;QAC7D,MAAM,mBAAA,GAAsB,MAAM,CAAC,kBAAA,IAAsB,OAAO,MAAM,CAAC,kBAAA,KAAuB,QAAQ;QACtG,MAAM,mBAAmB,sBACrB;YAAC;gBAAE,IAAI,EAAE,oBAAoB;gBAAE,GAAI,MAAM,CAAC,kBAAA;YAAA,CAAgD;SAAA,GAC1F,EAAE;QAEN,MAAM,iBAAiB,CAAC;eAAG,KAAK,EAAE;eAAG,gBAAgB;SAAC;QAEtD,IAAI,cAAc,CAAC,MAAA,GAAS,CAAC,EAAE;YAC7B,UAAU,CAAC,4SAAwC,CAAA,GAAI,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC;QACvF;IACF;IAEA,IAAI,IAAI,CAAC,MAAA,GAAS,CAAA,IAAK,OAAO,IAAI,CAAC,CAAC,CAAA,KAAM,YAAY,IAAI,CAAC,CAAC,CAAA,KAAM,IAAI,EAAE;QACtE,MAAM,MAAA,GAAS,IAAI,CAAC,CAAC,CAAA;QAErB,UAAU,CAAC,kSAA8B,CAAA,GAAI,MAAM,CAAC,KAAA,IAAS,SAAS;QACtE,IAAI,aAAA,IAAiB,MAAM,EAAE,UAAU,CAAC,wSAAoC,CAAA,GAAI,MAAM,CAAC,WAAW;QAClG,IAAI,OAAA,IAAW,MAAM,EAAE,UAAU,CAAC,kSAA8B,CAAA,GAAI,MAAM,CAAC,KAAK;QAChF,IAAI,mBAAA,IAAuB,MAAM,EAC/B,UAAU,CAAC,8SAA0C,CAAA,GAAI,MAAM,CAAC,iBAAiB;QACnF,IAAI,kBAAA,IAAsB,MAAM,EAAE,UAAU,CAAC,6SAAyC,CAAA,GAAI,MAAM,CAAC,gBAAgB;QACjH,IAAI,QAAA,IAAY,MAAM,EAAE,UAAU,CAAC,mSAA+B,CAAA,GAAI,MAAM,CAAC,MAAM;QACnF,IAAI,iBAAA,IAAqB,MAAM,EAAE,UAAU,CAAC,4SAAwC,CAAA,GAAI,MAAM,CAAC,eAAe;QAC9G,IAAI,YAAA,IAAgB,MAAM,EAAE,UAAU,CAAC,uSAAmC,CAAA,GAAI,MAAM,CAAC,UAAU;IACjG,OAAO;QACL,UAAU,CAAC,kSAA8B,CAAA,GAAI,SAAS;IACxD;IAEA,OAAO,UAAU;AACnB;AAEA;;;CAGA,GACA,SAAS,qBAAqB,CAAC,IAAI,EAAQ,MAAM,EAAW,aAAa,EAAkB;IACzF,IAAI,CAAC,MAAA,IAAU,OAAO,MAAA,KAAW,QAAQ,EAAE;IAE3C,MAAM,QAAA,GAAW,MAAA;IAEjB,QAAI,8QAAwB,EAAC,QAAQ,CAAC,EAAE;YACtC,iRAA2B,EAAC,IAAI,EAAE,QAAQ,EAAE,aAAa,CAAC;QAC1D,IAAI,aAAA,IAAiB,QAAQ,CAAC,OAAO,EAAE,MAAM,EAAE;YAC7C,MAAM,aAAA,GAAgB,QAAQ,CAAC,OAAO,CAAC,GAAG,EAAC,MAAA,GAAU,MAAM,CAAC,OAAO,EAAE,OAAA,IAAW,EAAE,CAAC;YACnF,IAAI,CAAC,aAAa,CAAC;gBAAE,CAAC,kSAA8B,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,aAAa,CAAA;YAAA,CAAG,CAAC;QACzF;IACF,CAAA,MAAO,QAAI,4QAAsB,EAAC,QAAQ,CAAC,EAAE;YAC3C,+QAAyB,EAAC,IAAI,EAAE,QAAQ,EAAE,aAAa,CAAC;QACxD,IAAI,aAAA,IAAiB,QAAQ,CAAC,WAAW,EAAE;YACzC,IAAI,CAAC,aAAa,CAAC;gBAAE,CAAC,kSAA8B,CAAA,EAAG,QAAQ,CAAC,WAAA;YAAA,CAAa,CAAC;QAChF;IACF,CAAA,MAAO,QAAI,0QAAoB,EAAC,QAAQ,CAAC,EAAE;YACzC,6QAAuB,EAAC,IAAI,EAAE,QAAQ,CAAC;IACzC;AACF;AAEA,6GAAA;AACA,SAAS,oBAAoB,CAAC,IAAI,EAAQ,MAAM,EAAiC;IAC/E,IAAI,UAAA,IAAc,MAAM,EAAE;QACxB,MAAM,wBAAoB,wQAAsB,EAAC,MAAM,CAAC,QAAQ,CAAC;QACjE,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,qSAAiC,CAAA,EAAG,iBAAA;QAAA,CAAmB,CAAC;IAChF;IACA,IAAI,OAAA,IAAW,MAAM,EAAE;QACrB,MAAM,qBAAiB,wQAAsB,EAAC,MAAM,CAAC,KAAK,CAAC;QAC3D,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,qSAAiC,CAAA,EAAG,cAAA;QAAA,CAAgB,CAAC;IAC7E;AACF;AAEA,SAAS,yBAAyB,GAAkB;IAClD,MAAM,KAAA,OAAQ,wPAAe,EAAE;IAC/B,MAAM,MAAA,GAAS,KAAK,CAAC,SAAS,EAAE;IAChC,MAAM,cAAc,MAAM,EAAE,oBAAoB,CAAoB,iRAAuB,CAAC;IAC5F,MAAM,4BAAA,GAA+B,WAAA,GAAc,OAAO,CAAC,MAAM,EAAE,UAAU,EAAE,CAAC,cAAc,CAAA,GAAI,KAAK;IAEvG,OAAO;QACL,YAAY,EAAE,WAAW,EAAE,OAAO,EAAE,YAAA,IAAgB,4BAA4B;QAChF,aAAa,EAAE,WAAW,EAAE,OAAO,EAAE,aAAA,IAAiB,4BAA4B;IACtF,CAAG;AACH;AAEA;;;;CAIA,GACA,SAAS,gBAAgB,CACvB,cAAc,EACd,UAAU,EACV,OAAO,EACP,OAAO;IAEP,OAAO,eAAe,kBAAkB,CAAC,GAAG,IAAI,EAAiB;QAC/D,MAAM,YAAA,GAAe,WAAW,yBAAyB,EAAE;QAC3D,MAAM,oBAAoB,wBAAwB,CAAC,IAAI,EAAE,UAAU,CAAC;QACpE,MAAM,KAAA,GAAQ,AAAC,iBAAiB,CAAC,kSAA8B,CAAA,IAAgB,SAAS;QACxF,MAAM,aAAA,OAAgB,sQAAgB,EAAC,UAAU,CAAC;QAElD,MAAM,MAAA,GAAS,IAAI,CAAC,CAAC,CAAA;QACrB,MAAM,iBAAA,GAAoB,MAAA,IAAU,OAAO,MAAA,KAAW,QAAA,IAAY,MAAM,CAAC,MAAA,KAAW,IAAI;QAExF,IAAI,iBAAiB,EAAE;YAC3B,uGAAA;YACM,WAAO,2PAAe,EACpB;gBACE,IAAI,EAAE,CAAC,EAAA,aAAA,CAAA,CAAA,EAAA,KAAA,CAAA,gBAAA,CAAA;gBACA,EAAA,MAAA,sQAAA,EAAA,UAAA,CAAA;gBACA,UAAA,EAAA,iBAAA;YACA,CAAA,EACA,OAAA,IAAA,KAAA;gBACA,IAAA;oBACA,IAAA,YAAA,CAAA,YAAA,IAAA,IAAA,CAAA,CAAA,CAAA,IAAA,OAAA,IAAA,CAAA,CAAA,CAAA,KAAA,QAAA,EAAA;wBACA,oBAAA,CAAA,IAAA,EAAA,IAAA,CAAA,CAAA,CAAA,EAAA;oBACA;oBAEA,MAAA,MAAA,GAAA,MAAA,cAAA,CAAA,KAAA,CAAA,OAAA,EAAA,IAAA,CAAA;oBAEA,WAAA,0QAAA,EACA,MAAA,EACA,IAAA,EACA,YAAA,CAAA,aAAA,IAAA,KAAA;gBAEA,CAAA,CAAA,OAAA,KAAA,EAAA;oBACA,mFAAA;oBACA,yDAAA;oBACA,IAAA,CAAA,SAAA,CAAA;wBAAA,IAAA,EAAA,kQAAA;wBAAA,OAAA,EAAA,gBAAA;oBAAA,CAAA,CAAA;wBACA,mPAAA,EAAA,KAAA,EAAA;wBACA,SAAA,EAAA;4BACA,OAAA,EAAA,KAAA;4BACA,IAAA,EAAA,uBAAA;4BACA,IAAA,EAAA;gCACA,QAAA,EAAA,UAAA;4BACA,CAAA;wBACA,CAAA;oBACA,CAAA,CAAA;oBACA,IAAA,CAAA,GAAA,EAAA;oBACA,MAAA,KAAA;gBACA;YACA,CAAA;QAEA,CAAA,MAAA;YACA,2BAAA;YACA,WAAA,qPAAA,EACA;gBACA,IAAA,EAAA,CAAA,EAAA,aAAA,CAAA,CAAA,EAAA,KAAA,CAAA,CAAA;gBACA,EAAA,MAAA,sQAAA,EAAA,UAAA,CAAA;gBACA,UAAA,EAAA,iBAAA;YACA,CAAA,EACA,OAAA,IAAA,KAAA;gBACA,IAAA;oBACA,IAAA,YAAA,CAAA,YAAA,IAAA,IAAA,CAAA,CAAA,CAAA,IAAA,OAAA,IAAA,CAAA,CAAA,CAAA,KAAA,QAAA,EAAA;wBACA,oBAAA,CAAA,IAAA,EAAA,IAAA,CAAA,CAAA,CAAA,EAAA;oBACA;oBAEA,MAAA,MAAA,GAAA,MAAA,cAAA,CAAA,KAAA,CAAA,OAAA,EAAA,IAAA,CAAA;oBACA,qBAAA,CAAA,IAAA,EAAA,MAAA,EAAA,YAAA,CAAA,aAAA,CAAA;oBACA,OAAA,MAAA;gBACA,CAAA,CAAA,OAAA,KAAA,EAAA;wBACA,mPAAA,EAAA,KAAA,EAAA;wBACA,SAAA,EAAA;4BACA,OAAA,EAAA,KAAA;4BACA,IAAA,EAAA,gBAAA;4BACA,IAAA,EAAA;gCACA,QAAA,EAAA,UAAA;4BACA,CAAA;wBACA,CAAA;oBACA,CAAA,CAAA;oBACA,MAAA,KAAA;gBACA;YACA,CAAA;QAEA;IACA,CAAA;AACA;AAEA;;CAEA,GACA,SAAA,eAAA,CAAA,MAAA,EAAA,WAAA,GAAA,EAAA,EAAA,OAAA,EAAA;IACA,OAAA,IAAA,KAAA,CAAA,MAAA,EAAA;QACA,GAAA,EAAA,GAAA,EAAA,IAAA,EAAA;YACA,MAAA,KAAA,GAAA,GAAA,CAAA,IAAA,CAAA;YACA,MAAA,UAAA,OAAA,qQAAA,EAAA,WAAA,EAAA,MAAA,CAAA,IAAA,CAAA,CAAA;YAEA,IAAA,OAAA,KAAA,KAAA,UAAA,QAAA,sQAAA,EAAA,UAAA,CAAA,EAAA;gBACA,OAAA,gBAAA,CAAA,KAAA,EAAA,UAAA,EAAA,GAAA,EAAA,OAAA,CAAA;YACA;YAEA,IAAA,OAAA,KAAA,KAAA,UAAA,EAAA;gBACA,2EAAA;gBACA,yFAAA;gBACA,OAAA,KAAA,CAAA,IAAA,CAAA,GAAA,CAAA;YACA;YAEA,IAAA,KAAA,IAAA,OAAA,KAAA,KAAA,QAAA,EAAA;gBACA,OAAA,eAAA,CAAA,KAAA,EAAA,UAAA,EAAA,OAAA,CAAA;YACA;YAEA,OAAA,KAAA;QACA,CAAA;IACA,CAAA,CAAA;AACA;AAEA;;;CAGA,GACA,SAAA,sBAAA,CAAA,MAAA,EAAA,OAAA,EAAA;IACA,OAAA,eAAA,CAAA,MAAA,EAAA,EAAA,EAAA,OAAA,CAAA;AACA"}},
    {"offset": {"line": 3211, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/anthropic-ai/constants.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/anthropic-ai/constants.ts"],"sourcesContent":["export const ANTHROPIC_AI_INTEGRATION_NAME = 'Anthropic_AI';\n\n// https://docs.anthropic.com/en/api/messages\n// https://docs.anthropic.com/en/api/models-list\nexport const ANTHROPIC_AI_INSTRUMENTED_METHODS = [\n  'messages.create',\n  'messages.stream',\n  'messages.countTokens',\n  'models.get',\n  'completions.create',\n  'models.retrieve',\n  'beta.messages.create',\n] as const;\n"],"names":[],"mappings":";;;;;;AAAO,MAAM,6BAAA,GAAgC;AAE7C,6CAAA;AACA,gDAAA;AACO,MAAM,oCAAoC;IAC/C,iBAAiB;IACjB,iBAAiB;IACjB,sBAAsB;IACtB,YAAY;IACZ,oBAAoB;IACpB,iBAAiB;IACjB,sBAAsB;CACxB"}},
    {"offset": {"line": 3235, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/anthropic-ai/streaming.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/anthropic-ai/streaming.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport type { Span } from '../../types-hoist/span';\nimport {\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_STREAMING_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { setTokenUsageAttributes } from '../ai/utils';\nimport type { AnthropicAiStreamingEvent } from './types';\n\n/**\n * State object used to accumulate information from a stream of Anthropic AI events.\n */\ninterface StreamingState {\n  /** Collected response text fragments (for output recording). */\n  responseTexts: string[];\n  /** Reasons for finishing the response, as reported by the API. */\n  finishReasons: string[];\n  /** The response ID. */\n  responseId: string;\n  /** The model name. */\n  responseModel: string;\n  /** Number of prompt/input tokens used. */\n  promptTokens: number | undefined;\n  /** Number of completion/output tokens used. */\n  completionTokens: number | undefined;\n  /** Number of cache creation input tokens used. */\n  cacheCreationInputTokens: number | undefined;\n  /** Number of cache read input tokens used. */\n  cacheReadInputTokens: number | undefined;\n  /** Accumulated tool calls (finalized) */\n  toolCalls: Array<Record<string, unknown>>;\n  /** In-progress tool call blocks keyed by index */\n  activeToolBlocks: Record<\n    number,\n    {\n      id?: string;\n      name?: string;\n      inputJsonParts: string[];\n    }\n  >;\n}\n\n/**\n * Checks if an event is an error event\n * @param event - The event to process\n * @param state - The state of the streaming process\n * @param recordOutputs - Whether to record outputs\n * @param span - The span to update\n * @returns Whether an error occurred\n */\n\nfunction isErrorEvent(event: AnthropicAiStreamingEvent, span: Span): boolean {\n  if ('type' in event && typeof event.type === 'string') {\n    // If the event is an error, set the span status and capture the error\n    // These error events are not rejected by the API by default, but are sent as metadata of the response\n    if (event.type === 'error') {\n      span.setStatus({ code: SPAN_STATUS_ERROR, message: event.error?.type ?? 'internal_error' });\n      captureException(event.error, {\n        mechanism: {\n          handled: false,\n          type: 'auto.ai.anthropic.anthropic_error',\n        },\n      });\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Processes the message metadata of an event\n * @param event - The event to process\n * @param state - The state of the streaming process\n */\n\nfunction handleMessageMetadata(event: AnthropicAiStreamingEvent, state: StreamingState): void {\n  // The token counts shown in the usage field of the message_delta event are cumulative.\n  // @see https://docs.anthropic.com/en/docs/build-with-claude/streaming#event-types\n  if (event.type === 'message_delta' && event.usage) {\n    if ('output_tokens' in event.usage && typeof event.usage.output_tokens === 'number') {\n      state.completionTokens = event.usage.output_tokens;\n    }\n  }\n\n  if (event.message) {\n    const message = event.message;\n\n    if (message.id) state.responseId = message.id;\n    if (message.model) state.responseModel = message.model;\n    if (message.stop_reason) state.finishReasons.push(message.stop_reason);\n\n    if (message.usage) {\n      if (typeof message.usage.input_tokens === 'number') state.promptTokens = message.usage.input_tokens;\n      if (typeof message.usage.cache_creation_input_tokens === 'number')\n        state.cacheCreationInputTokens = message.usage.cache_creation_input_tokens;\n      if (typeof message.usage.cache_read_input_tokens === 'number')\n        state.cacheReadInputTokens = message.usage.cache_read_input_tokens;\n    }\n  }\n}\n\n/**\n * Handle start of a content block (e.g., tool_use)\n */\nfunction handleContentBlockStart(event: AnthropicAiStreamingEvent, state: StreamingState): void {\n  if (event.type !== 'content_block_start' || typeof event.index !== 'number' || !event.content_block) return;\n  if (event.content_block.type === 'tool_use' || event.content_block.type === 'server_tool_use') {\n    state.activeToolBlocks[event.index] = {\n      id: event.content_block.id,\n      name: event.content_block.name,\n      inputJsonParts: [],\n    };\n  }\n}\n\n/**\n * Handle deltas of a content block, including input_json_delta for tool_use\n */\nfunction handleContentBlockDelta(\n  event: AnthropicAiStreamingEvent,\n  state: StreamingState,\n  recordOutputs: boolean,\n): void {\n  if (event.type !== 'content_block_delta' || !event.delta) return;\n\n  // Accumulate tool_use input JSON deltas only when we have an index and an active tool block\n  if (\n    typeof event.index === 'number' &&\n    'partial_json' in event.delta &&\n    typeof event.delta.partial_json === 'string'\n  ) {\n    const active = state.activeToolBlocks[event.index];\n    if (active) {\n      active.inputJsonParts.push(event.delta.partial_json);\n    }\n  }\n\n  // Accumulate streamed response text regardless of index\n  if (recordOutputs && typeof event.delta.text === 'string') {\n    state.responseTexts.push(event.delta.text);\n  }\n}\n\n/**\n * Handle stop of a content block; finalize tool_use entries\n */\nfunction handleContentBlockStop(event: AnthropicAiStreamingEvent, state: StreamingState): void {\n  if (event.type !== 'content_block_stop' || typeof event.index !== 'number') return;\n\n  const active = state.activeToolBlocks[event.index];\n  if (!active) return;\n\n  const raw = active.inputJsonParts.join('');\n  let parsedInput: unknown;\n\n  try {\n    parsedInput = raw ? JSON.parse(raw) : {};\n  } catch {\n    parsedInput = { __unparsed: raw };\n  }\n\n  state.toolCalls.push({\n    type: 'tool_use',\n    id: active.id,\n    name: active.name,\n    input: parsedInput,\n  });\n\n  // eslint-disable-next-line @typescript-eslint/no-dynamic-delete\n  delete state.activeToolBlocks[event.index];\n}\n\n/**\n * Processes an event\n * @param event - The event to process\n * @param state - The state of the streaming process\n * @param recordOutputs - Whether to record outputs\n * @param span - The span to update\n */\nfunction processEvent(\n  event: AnthropicAiStreamingEvent,\n  state: StreamingState,\n  recordOutputs: boolean,\n  span: Span,\n): void {\n  if (!(event && typeof event === 'object')) {\n    return;\n  }\n\n  const isError = isErrorEvent(event, span);\n  if (isError) return;\n\n  handleMessageMetadata(event, state);\n\n  // Tool call events are sent via 3 separate events:\n  // - content_block_start (start of the tool call)\n  // - content_block_delta (delta aka input of the tool call)\n  // - content_block_stop (end of the tool call)\n  // We need to handle them all to capture the full tool call.\n  handleContentBlockStart(event, state);\n  handleContentBlockDelta(event, state, recordOutputs);\n  handleContentBlockStop(event, state);\n}\n\n/**\n * Finalizes span attributes when stream processing completes\n */\nfunction finalizeStreamSpan(state: StreamingState, span: Span, recordOutputs: boolean): void {\n  if (!span.isRecording()) {\n    return;\n  }\n\n  // Set common response attributes if available\n  if (state.responseId) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_ID_ATTRIBUTE]: state.responseId,\n    });\n  }\n  if (state.responseModel) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: state.responseModel,\n    });\n  }\n\n  setTokenUsageAttributes(\n    span,\n    state.promptTokens,\n    state.completionTokens,\n    state.cacheCreationInputTokens,\n    state.cacheReadInputTokens,\n  );\n\n  span.setAttributes({\n    [GEN_AI_RESPONSE_STREAMING_ATTRIBUTE]: true,\n  });\n\n  if (state.finishReasons.length > 0) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(state.finishReasons),\n    });\n  }\n\n  if (recordOutputs && state.responseTexts.length > 0) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: state.responseTexts.join(''),\n    });\n  }\n\n  // Set tool calls if any were captured\n  if (recordOutputs && state.toolCalls.length > 0) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE]: JSON.stringify(state.toolCalls),\n    });\n  }\n\n  span.end();\n}\n\n/**\n * Instruments an async iterable stream of Anthropic events, updates the span with\n * streaming attributes and (optionally) the aggregated output text, and yields\n * each event from the input stream unchanged.\n */\nexport async function* instrumentAsyncIterableStream(\n  stream: AsyncIterable<AnthropicAiStreamingEvent>,\n  span: Span,\n  recordOutputs: boolean,\n): AsyncGenerator<AnthropicAiStreamingEvent, void, unknown> {\n  const state: StreamingState = {\n    responseTexts: [],\n    finishReasons: [],\n    responseId: '',\n    responseModel: '',\n    promptTokens: undefined,\n    completionTokens: undefined,\n    cacheCreationInputTokens: undefined,\n    cacheReadInputTokens: undefined,\n    toolCalls: [],\n    activeToolBlocks: {},\n  };\n\n  try {\n    for await (const event of stream) {\n      processEvent(event, state, recordOutputs, span);\n      yield event;\n    }\n  } finally {\n    // Set common response attributes if available\n    if (state.responseId) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_ID_ATTRIBUTE]: state.responseId,\n      });\n    }\n    if (state.responseModel) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: state.responseModel,\n      });\n    }\n\n    setTokenUsageAttributes(\n      span,\n      state.promptTokens,\n      state.completionTokens,\n      state.cacheCreationInputTokens,\n      state.cacheReadInputTokens,\n    );\n\n    span.setAttributes({\n      [GEN_AI_RESPONSE_STREAMING_ATTRIBUTE]: true,\n    });\n\n    if (state.finishReasons.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(state.finishReasons),\n      });\n    }\n\n    if (recordOutputs && state.responseTexts.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: state.responseTexts.join(''),\n      });\n    }\n\n    // Set tool calls if any were captured\n    if (recordOutputs && state.toolCalls.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE]: JSON.stringify(state.toolCalls),\n      });\n    }\n\n    span.end();\n  }\n}\n\n/**\n * Instruments a MessageStream by registering event handlers and preserving the original stream API.\n */\nexport function instrumentMessageStream<R extends { on: (...args: unknown[]) => void }>(\n  stream: R,\n  span: Span,\n  recordOutputs: boolean,\n): R {\n  const state: StreamingState = {\n    responseTexts: [],\n    finishReasons: [],\n    responseId: '',\n    responseModel: '',\n    promptTokens: undefined,\n    completionTokens: undefined,\n    cacheCreationInputTokens: undefined,\n    cacheReadInputTokens: undefined,\n    toolCalls: [],\n    activeToolBlocks: {},\n  };\n\n  stream.on('streamEvent', (event: unknown) => {\n    processEvent(event as AnthropicAiStreamingEvent, state, recordOutputs, span);\n  });\n\n  // The event fired when a message is done being streamed by the API. Corresponds to the message_stop SSE event.\n  // @see https://github.com/anthropics/anthropic-sdk-typescript/blob/d3be31f5a4e6ebb4c0a2f65dbb8f381ae73a9166/helpers.md?plain=1#L42-L44\n  stream.on('message', () => {\n    finalizeStreamSpan(state, span, recordOutputs);\n  });\n\n  stream.on('error', (error: unknown) => {\n    captureException(error, {\n      mechanism: {\n        handled: false,\n        type: 'auto.ai.anthropic.stream_error',\n      },\n    });\n\n    if (span.isRecording()) {\n      span.setStatus({ code: SPAN_STATUS_ERROR, message: 'stream_error' });\n      span.end();\n    }\n  });\n\n  return stream;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAcA;;CAEA,GA+BA;;;;;;;CAOA,GAEA,SAAS,YAAY,CAAC,KAAK,EAA6B,IAAI,EAAiB;IAC3E,IAAI,MAAA,IAAU,KAAA,IAAS,OAAO,KAAK,CAAC,IAAA,KAAS,QAAQ,EAAE;QACzD,sEAAA;QACA,sGAAA;QACI,IAAI,KAAK,CAAC,IAAA,KAAS,OAAO,EAAE;YAC1B,IAAI,CAAC,SAAS,CAAC;gBAAE,IAAI,EAAE,kQAAiB;gBAAE,OAAO,EAAE,KAAK,CAAC,KAAK,EAAE,QAAQ,gBAAA;YAAA,CAAkB,CAAC;gBAC3F,mPAAgB,EAAC,KAAK,CAAC,KAAK,EAAE;gBAC5B,SAAS,EAAE;oBACT,OAAO,EAAE,KAAK;oBACd,IAAI,EAAE,mCAAmC;gBACnD,CAAS;YACT,CAAO,CAAC;YACF,OAAO,IAAI;QACb;IACF;IACA,OAAO,KAAK;AACd;AAEA;;;;CAIA,GAEA,SAAS,qBAAqB,CAAC,KAAK,EAA6B,KAAK,EAAwB;IAC9F,uFAAA;IACA,kFAAA;IACE,IAAI,KAAK,CAAC,IAAA,KAAS,eAAA,IAAmB,KAAK,CAAC,KAAK,EAAE;QACjD,IAAI,eAAA,IAAmB,KAAK,CAAC,KAAA,IAAS,OAAO,KAAK,CAAC,KAAK,CAAC,aAAA,KAAkB,QAAQ,EAAE;YACnF,KAAK,CAAC,gBAAA,GAAmB,KAAK,CAAC,KAAK,CAAC,aAAa;QACpD;IACF;IAEA,IAAI,KAAK,CAAC,OAAO,EAAE;QACjB,MAAM,OAAA,GAAU,KAAK,CAAC,OAAO;QAE7B,IAAI,OAAO,CAAC,EAAE,EAAE,KAAK,CAAC,UAAA,GAAa,OAAO,CAAC,EAAE;QAC7C,IAAI,OAAO,CAAC,KAAK,EAAE,KAAK,CAAC,aAAA,GAAgB,OAAO,CAAC,KAAK;QACtD,IAAI,OAAO,CAAC,WAAW,EAAE,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,OAAO,CAAC,WAAW,CAAC;QAEtE,IAAI,OAAO,CAAC,KAAK,EAAE;YACjB,IAAI,OAAO,OAAO,CAAC,KAAK,CAAC,YAAA,KAAiB,QAAQ,EAAE,KAAK,CAAC,YAAA,GAAe,OAAO,CAAC,KAAK,CAAC,YAAY;YACnG,IAAI,OAAO,OAAO,CAAC,KAAK,CAAC,2BAAA,KAAgC,QAAQ,EAC/D,KAAK,CAAC,wBAAA,GAA2B,OAAO,CAAC,KAAK,CAAC,2BAA2B;YAC5E,IAAI,OAAO,OAAO,CAAC,KAAK,CAAC,uBAAA,KAA4B,QAAQ,EAC3D,KAAK,CAAC,oBAAA,GAAuB,OAAO,CAAC,KAAK,CAAC,uBAAuB;QACtE;IACF;AACF;AAEA;;CAEA,GACA,SAAS,uBAAuB,CAAC,KAAK,EAA6B,KAAK,EAAwB;IAC9F,IAAI,KAAK,CAAC,IAAA,KAAS,qBAAA,IAAyB,OAAO,KAAK,CAAC,KAAA,KAAU,YAAY,CAAC,KAAK,CAAC,aAAa,EAAE;IACrG,IAAI,KAAK,CAAC,aAAa,CAAC,IAAA,KAAS,UAAA,IAAc,KAAK,CAAC,aAAa,CAAC,IAAA,KAAS,iBAAiB,EAAE;QAC7F,KAAK,CAAC,gBAAgB,CAAC,KAAK,CAAC,KAAK,CAAA,GAAI;YACpC,EAAE,EAAE,KAAK,CAAC,aAAa,CAAC,EAAE;YAC1B,IAAI,EAAE,KAAK,CAAC,aAAa,CAAC,IAAI;YAC9B,cAAc,EAAE,EAAE;QACxB,CAAK;IACH;AACF;AAEA;;CAEA,GACA,SAAS,uBAAuB,CAC9B,KAAK,EACL,KAAK,EACL,aAAa;IAEb,IAAI,KAAK,CAAC,IAAA,KAAS,qBAAA,IAAyB,CAAC,KAAK,CAAC,KAAK,EAAE;IAE5D,4FAAA;IACE,IACE,OAAO,KAAK,CAAC,KAAA,KAAU,QAAA,IACvB,cAAA,IAAkB,KAAK,CAAC,KAAA,IACxB,OAAO,KAAK,CAAC,KAAK,CAAC,YAAA,KAAiB,UACpC;QACA,MAAM,MAAA,GAAS,KAAK,CAAC,gBAAgB,CAAC,KAAK,CAAC,KAAK,CAAC;QAClD,IAAI,MAAM,EAAE;YACV,MAAM,CAAC,cAAc,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,YAAY,CAAC;QACtD;IACF;IAEF,wDAAA;IACE,IAAI,aAAA,IAAiB,OAAO,KAAK,CAAC,KAAK,CAAC,IAAA,KAAS,QAAQ,EAAE;QACzD,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC;IAC5C;AACF;AAEA;;CAEA,GACA,SAAS,sBAAsB,CAAC,KAAK,EAA6B,KAAK,EAAwB;IAC7F,IAAI,KAAK,CAAC,IAAA,KAAS,oBAAA,IAAwB,OAAO,KAAK,CAAC,KAAA,KAAU,QAAQ,EAAE;IAE5E,MAAM,MAAA,GAAS,KAAK,CAAC,gBAAgB,CAAC,KAAK,CAAC,KAAK,CAAC;IAClD,IAAI,CAAC,MAAM,EAAE;IAEb,MAAM,GAAA,GAAM,MAAM,CAAC,cAAc,CAAC,IAAI,CAAC,EAAE,CAAC;IAC1C,IAAI,WAAW;IAEf,IAAI;QACF,WAAA,GAAc,GAAA,GAAM,IAAI,CAAC,KAAK,CAAC,GAAG,CAAA,GAAI,CAAA,CAAE;IAC1C,EAAE,OAAM;QACN,cAAc;YAAE,UAAU,EAAE;QAAA,CAAK;IACnC;IAEA,KAAK,CAAC,SAAS,CAAC,IAAI,CAAC;QACnB,IAAI,EAAE,UAAU;QAChB,EAAE,EAAE,MAAM,CAAC,EAAE;QACb,IAAI,EAAE,MAAM,CAAC,IAAI;QACjB,KAAK,EAAE,WAAW;IACtB,CAAG,CAAC;IAEJ,gEAAA;IACE,OAAO,KAAK,CAAC,gBAAgB,CAAC,KAAK,CAAC,KAAK,CAAC;AAC5C;AAEA;;;;;;CAMA,GACA,SAAS,YAAY,CACnB,KAAK,EACL,KAAK,EACL,aAAa,EACb,IAAI;IAEJ,IAAI,CAAA,CAAE,KAAA,IAAS,OAAO,KAAA,KAAU,QAAQ,CAAC,EAAE;QACzC;IACF;IAEA,MAAM,UAAU,YAAY,CAAC,KAAK,EAAE,IAAI,CAAC;IACzC,IAAI,OAAO,EAAE;IAEb,qBAAqB,CAAC,KAAK,EAAE,KAAK,CAAC;IAErC,mDAAA;IACA,iDAAA;IACA,2DAAA;IACA,8CAAA;IACA,4DAAA;IACE,uBAAuB,CAAC,KAAK,EAAE,KAAK,CAAC;IACrC,uBAAuB,CAAC,KAAK,EAAE,KAAK,EAAE,aAAa,CAAC;IACpD,sBAAsB,CAAC,KAAK,EAAE,KAAK,CAAC;AACtC;AAEA;;CAEA,GACA,SAAS,kBAAkB,CAAC,KAAK,EAAkB,IAAI,EAAQ,aAAa,EAAiB;IAC3F,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE,EAAE;QACvB;IACF;IAEF,8CAAA;IACE,IAAI,KAAK,CAAC,UAAU,EAAE;QACpB,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,gSAA4B,CAAA,EAAG,KAAK,CAAC,UAAU;QACtD,CAAK,CAAC;IACJ;IACA,IAAI,KAAK,CAAC,aAAa,EAAE;QACvB,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,mSAA+B,CAAA,EAAG,KAAK,CAAC,aAAa;QAC5D,CAAK,CAAC;IACJ;QAEA,yQAAuB,EACrB,IAAI,EACJ,KAAK,CAAC,YAAY,EAClB,KAAK,CAAC,gBAAgB,EACtB,KAAK,CAAC,wBAAwB,EAC9B,KAAK,CAAC,oBAAoB;IAG5B,IAAI,CAAC,aAAa,CAAC;QACjB,CAAC,uSAAmC,CAAA,EAAG,IAAI;IAC/C,CAAG,CAAC;IAEF,IAAI,KAAK,CAAC,aAAa,CAAC,MAAA,GAAS,CAAC,EAAE;QAClC,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,4SAAwC,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,aAAa,CAAC;QACrF,CAAK,CAAC;IACJ;IAEA,IAAI,aAAA,IAAiB,KAAK,CAAC,aAAa,CAAC,MAAA,GAAS,CAAC,EAAE;QACnD,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,kSAA8B,CAAA,EAAG,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,EAAE,CAAC;QACpE,CAAK,CAAC;IACJ;IAEF,sCAAA;IACE,IAAI,aAAA,IAAiB,KAAK,CAAC,SAAS,CAAC,MAAA,GAAS,CAAC,EAAE;QAC/C,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,wSAAoC,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,SAAS,CAAC;QAC7E,CAAK,CAAC;IACJ;IAEA,IAAI,CAAC,GAAG,EAAE;AACZ;AAEA;;;;CAIA,GACO,gBAAgB,6BAA6B,CAClD,MAAM,EACN,IAAI,EACJ,aAAa;IAEb,MAAM,KAAK,GAAmB;QAC5B,aAAa,EAAE,EAAE;QACjB,aAAa,EAAE,EAAE;QACjB,UAAU,EAAE,EAAE;QACd,aAAa,EAAE,EAAE;QACjB,YAAY,EAAE,SAAS;QACvB,gBAAgB,EAAE,SAAS;QAC3B,wBAAwB,EAAE,SAAS;QACnC,oBAAoB,EAAE,SAAS;QAC/B,SAAS,EAAE,EAAE;QACb,gBAAgB,EAAE,CAAA,CAAE;IACxB,CAAG;IAED,IAAI;QACF,WAAW,MAAM,KAAA,IAAS,MAAM,CAAE;YAChC,YAAY,CAAC,KAAK,EAAE,KAAK,EAAE,aAAa,EAAE,IAAI,CAAC;YAC/C,MAAM,KAAK;QACb;IACF,SAAU;QACZ,8CAAA;QACI,IAAI,KAAK,CAAC,UAAU,EAAE;YACpB,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,gSAA4B,CAAA,EAAG,KAAK,CAAC,UAAU;YACxD,CAAO,CAAC;QACJ;QACA,IAAI,KAAK,CAAC,aAAa,EAAE;YACvB,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,mSAA+B,CAAA,EAAG,KAAK,CAAC,aAAa;YAC9D,CAAO,CAAC;QACJ;YAEA,yQAAuB,EACrB,IAAI,EACJ,KAAK,CAAC,YAAY,EAClB,KAAK,CAAC,gBAAgB,EACtB,KAAK,CAAC,wBAAwB,EAC9B,KAAK,CAAC,oBAAoB;QAG5B,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,uSAAmC,CAAA,EAAG,IAAI;QACjD,CAAK,CAAC;QAEF,IAAI,KAAK,CAAC,aAAa,CAAC,MAAA,GAAS,CAAC,EAAE;YAClC,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,4SAAwC,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,aAAa,CAAC;YACvF,CAAO,CAAC;QACJ;QAEA,IAAI,aAAA,IAAiB,KAAK,CAAC,aAAa,CAAC,MAAA,GAAS,CAAC,EAAE;YACnD,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,kSAA8B,CAAA,EAAG,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,EAAE,CAAC;YACtE,CAAO,CAAC;QACJ;QAEJ,sCAAA;QACI,IAAI,aAAA,IAAiB,KAAK,CAAC,SAAS,CAAC,MAAA,GAAS,CAAC,EAAE;YAC/C,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,wSAAoC,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,SAAS,CAAC;YAC/E,CAAO,CAAC;QACJ;QAEA,IAAI,CAAC,GAAG,EAAE;IACZ;AACF;AAEA;;CAEA,GACO,SAAS,uBAAuB,CACrC,MAAM,EACN,IAAI,EACJ,aAAa;IAEb,MAAM,KAAK,GAAmB;QAC5B,aAAa,EAAE,EAAE;QACjB,aAAa,EAAE,EAAE;QACjB,UAAU,EAAE,EAAE;QACd,aAAa,EAAE,EAAE;QACjB,YAAY,EAAE,SAAS;QACvB,gBAAgB,EAAE,SAAS;QAC3B,wBAAwB,EAAE,SAAS;QACnC,oBAAoB,EAAE,SAAS;QAC/B,SAAS,EAAE,EAAE;QACb,gBAAgB,EAAE,CAAA,CAAE;IACxB,CAAG;IAED,MAAM,CAAC,EAAE,CAAC,aAAa,EAAE,CAAC,KAAK,KAAc;QAC3C,YAAY,CAAC,KAAA,EAAoC,KAAK,EAAE,aAAa,EAAE,IAAI,CAAC;IAC9E,CAAC,CAAC;IAEJ,+GAAA;IACA,uIAAA;IACE,MAAM,CAAC,EAAE,CAAC,SAAS,EAAE,MAAM;QACzB,kBAAkB,CAAC,KAAK,EAAE,IAAI,EAAE,aAAa,CAAC;IAChD,CAAC,CAAC;IAEF,MAAM,CAAC,EAAE,CAAC,OAAO,EAAE,CAAC,KAAK,KAAc;YACrC,mPAAgB,EAAC,KAAK,EAAE;YACtB,SAAS,EAAE;gBACT,OAAO,EAAE,KAAK;gBACd,IAAI,EAAE,gCAAgC;YAC9C,CAAO;QACP,CAAK,CAAC;QAEF,IAAI,IAAI,CAAC,WAAW,EAAE,EAAE;YACtB,IAAI,CAAC,SAAS,CAAC;gBAAE,IAAI,EAAE,kQAAiB;gBAAE,OAAO,EAAE,cAAA;YAAA,CAAgB,CAAC;YACpE,IAAI,CAAC,GAAG,EAAE;QACZ;IACF,CAAC,CAAC;IAEF,OAAO,MAAM;AACf"}},
    {"offset": {"line": 3518, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/anthropic-ai/utils.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/anthropic-ai/utils.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport type { Span } from '../../types-hoist/span';\nimport { ANTHROPIC_AI_INSTRUMENTED_METHODS } from './constants';\nimport type { AnthropicAiInstrumentedMethod, AnthropicAiResponse } from './types';\n\n/**\n * Check if a method path should be instrumented\n */\nexport function shouldInstrument(methodPath: string): methodPath is AnthropicAiInstrumentedMethod {\n  return ANTHROPIC_AI_INSTRUMENTED_METHODS.includes(methodPath as AnthropicAiInstrumentedMethod);\n}\n\n/**\n * Capture error information from the response\n * @see https://docs.anthropic.com/en/api/errors#error-shapes\n */\nexport function handleResponseError(span: Span, response: AnthropicAiResponse): void {\n  if (response.error) {\n    span.setStatus({ code: SPAN_STATUS_ERROR, message: response.error.type || 'internal_error' });\n\n    captureException(response.error, {\n      mechanism: {\n        handled: false,\n        type: 'auto.ai.anthropic.anthropic_error',\n      },\n    });\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAMA;;CAEA,GACO,SAAS,gBAAgB,CAAC,UAAU,EAAuD;IAChG,OAAO,oSAAiC,CAAC,QAAQ,CAAC,YAA4C;AAChG;AAEA;;;CAGA,GACO,SAAS,mBAAmB,CAAC,IAAI,EAAQ,QAAQ,EAA6B;IACnF,IAAI,QAAQ,CAAC,KAAK,EAAE;QAClB,IAAI,CAAC,SAAS,CAAC;YAAE,IAAI,EAAE,kQAAiB;YAAE,OAAO,EAAE,QAAQ,CAAC,KAAK,CAAC,IAAA,IAAQ,gBAAA;QAAA,CAAkB,CAAC;YAE7F,mPAAgB,EAAC,QAAQ,CAAC,KAAK,EAAE;YAC/B,SAAS,EAAE;gBACT,OAAO,EAAE,KAAK;gBACd,IAAI,EAAE,mCAAmC;YACjD,CAAO;QACP,CAAK,CAAC;IACJ;AACF"}},
    {"offset": {"line": 3558, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/anthropic-ai/index.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/anthropic-ai/index.ts"],"sourcesContent":["import { getClient } from '../../currentScopes';\nimport { captureException } from '../../exports';\nimport { SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN } from '../../semanticAttributes';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport { startSpan, startSpanManual } from '../../tracing/trace';\nimport type { Span, SpanAttributeValue } from '../../types-hoist/span';\nimport { handleCallbackErrors } from '../../utils/handleCallbackErrors';\nimport {\n  ANTHROPIC_AI_RESPONSE_TIMESTAMP_ATTRIBUTE,\n  GEN_AI_OPERATION_NAME_ATTRIBUTE,\n  GEN_AI_PROMPT_ATTRIBUTE,\n  GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE,\n  GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE,\n  GEN_AI_REQUEST_MESSAGES_ATTRIBUTE,\n  GEN_AI_REQUEST_MODEL_ATTRIBUTE,\n  GEN_AI_REQUEST_STREAM_ATTRIBUTE,\n  GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_K_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_P_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  GEN_AI_SYSTEM_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport {\n  buildMethodPath,\n  getFinalOperationName,\n  getSpanOperation,\n  getTruncatedJsonString,\n  setTokenUsageAttributes,\n} from '../ai/utils';\nimport { instrumentAsyncIterableStream, instrumentMessageStream } from './streaming';\nimport type {\n  AnthropicAiInstrumentedMethod,\n  AnthropicAiOptions,\n  AnthropicAiResponse,\n  AnthropicAiStreamingEvent,\n  ContentBlock,\n} from './types';\nimport { handleResponseError, shouldInstrument } from './utils';\n\n/**\n * Extract request attributes from method arguments\n */\nfunction extractRequestAttributes(args: unknown[], methodPath: string): Record<string, unknown> {\n  const attributes: Record<string, unknown> = {\n    [GEN_AI_SYSTEM_ATTRIBUTE]: 'anthropic',\n    [GEN_AI_OPERATION_NAME_ATTRIBUTE]: getFinalOperationName(methodPath),\n    [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: 'auto.ai.anthropic',\n  };\n\n  if (args.length > 0 && typeof args[0] === 'object' && args[0] !== null) {\n    const params = args[0] as Record<string, unknown>;\n    if (params.tools && Array.isArray(params.tools)) {\n      attributes[GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE] = JSON.stringify(params.tools);\n    }\n\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = params.model ?? 'unknown';\n    if ('temperature' in params) attributes[GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE] = params.temperature;\n    if ('top_p' in params) attributes[GEN_AI_REQUEST_TOP_P_ATTRIBUTE] = params.top_p;\n    if ('stream' in params) attributes[GEN_AI_REQUEST_STREAM_ATTRIBUTE] = params.stream;\n    if ('top_k' in params) attributes[GEN_AI_REQUEST_TOP_K_ATTRIBUTE] = params.top_k;\n    if ('frequency_penalty' in params)\n      attributes[GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE] = params.frequency_penalty;\n    if ('max_tokens' in params) attributes[GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE] = params.max_tokens;\n  } else {\n    if (methodPath === 'models.retrieve' || methodPath === 'models.get') {\n      // models.retrieve(model-id) and models.get(model-id)\n      attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = args[0];\n    } else {\n      attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = 'unknown';\n    }\n  }\n\n  return attributes;\n}\n\n/**\n * Add private request attributes to spans.\n * This is only recorded if recordInputs is true.\n */\nfunction addPrivateRequestAttributes(span: Span, params: Record<string, unknown>): void {\n  if ('messages' in params) {\n    const truncatedMessages = getTruncatedJsonString(params.messages);\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: truncatedMessages });\n  }\n  if ('input' in params) {\n    const truncatedInput = getTruncatedJsonString(params.input);\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: truncatedInput });\n  }\n\n  if ('prompt' in params) {\n    span.setAttributes({ [GEN_AI_PROMPT_ATTRIBUTE]: JSON.stringify(params.prompt) });\n  }\n}\n\n/**\n * Add content attributes when recordOutputs is enabled\n */\nfunction addContentAttributes(span: Span, response: AnthropicAiResponse): void {\n  // Messages.create\n  if ('content' in response) {\n    if (Array.isArray(response.content)) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: response.content\n          .map((item: ContentBlock) => item.text)\n          .filter(text => !!text)\n          .join(''),\n      });\n\n      const toolCalls: Array<ContentBlock> = [];\n\n      for (const item of response.content) {\n        if (item.type === 'tool_use' || item.type === 'server_tool_use') {\n          toolCalls.push(item);\n        }\n      }\n      if (toolCalls.length > 0) {\n        span.setAttributes({ [GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE]: JSON.stringify(toolCalls) });\n      }\n    }\n  }\n  // Completions.create\n  if ('completion' in response) {\n    span.setAttributes({ [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: response.completion });\n  }\n  // Models.countTokens\n  if ('input_tokens' in response) {\n    span.setAttributes({ [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: JSON.stringify(response.input_tokens) });\n  }\n}\n\n/**\n * Add basic metadata attributes from the response\n */\nfunction addMetadataAttributes(span: Span, response: AnthropicAiResponse): void {\n  if ('id' in response && 'model' in response) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_ID_ATTRIBUTE]: response.id,\n      [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: response.model,\n    });\n\n    if ('created' in response && typeof response.created === 'number') {\n      span.setAttributes({\n        [ANTHROPIC_AI_RESPONSE_TIMESTAMP_ATTRIBUTE]: new Date(response.created * 1000).toISOString(),\n      });\n    }\n    if ('created_at' in response && typeof response.created_at === 'number') {\n      span.setAttributes({\n        [ANTHROPIC_AI_RESPONSE_TIMESTAMP_ATTRIBUTE]: new Date(response.created_at * 1000).toISOString(),\n      });\n    }\n\n    if ('usage' in response && response.usage) {\n      setTokenUsageAttributes(\n        span,\n        response.usage.input_tokens,\n        response.usage.output_tokens,\n        response.usage.cache_creation_input_tokens,\n        response.usage.cache_read_input_tokens,\n      );\n    }\n  }\n}\n\n/**\n * Add response attributes to spans\n */\nfunction addResponseAttributes(span: Span, response: AnthropicAiResponse, recordOutputs?: boolean): void {\n  if (!response || typeof response !== 'object') return;\n\n  // capture error, do not add attributes if error (they shouldn't exist)\n  if ('type' in response && response.type === 'error') {\n    handleResponseError(span, response);\n    return;\n  }\n\n  // Private response attributes that are only recorded if recordOutputs is true.\n  if (recordOutputs) {\n    addContentAttributes(span, response);\n  }\n\n  // Add basic metadata attributes\n  addMetadataAttributes(span, response);\n}\n\n/**\n * Handle common error catching and reporting for streaming requests\n */\nfunction handleStreamingError(error: unknown, span: Span, methodPath: string): never {\n  captureException(error, {\n    mechanism: { handled: false, type: 'auto.ai.anthropic', data: { function: methodPath } },\n  });\n\n  if (span.isRecording()) {\n    span.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n    span.end();\n  }\n  throw error;\n}\n\n/**\n * Handle streaming cases with common logic\n */\nfunction handleStreamingRequest<T extends unknown[], R>(\n  originalMethod: (...args: T) => R | Promise<R>,\n  target: (...args: T) => R | Promise<R>,\n  context: unknown,\n  args: T,\n  requestAttributes: Record<string, unknown>,\n  operationName: string,\n  methodPath: string,\n  params: Record<string, unknown> | undefined,\n  options: AnthropicAiOptions,\n  isStreamRequested: boolean,\n  isStreamingMethod: boolean,\n): R | Promise<R> {\n  const model = requestAttributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] ?? 'unknown';\n  const spanConfig = {\n    name: `${operationName} ${model} stream-response`,\n    op: getSpanOperation(methodPath),\n    attributes: requestAttributes as Record<string, SpanAttributeValue>,\n  };\n\n  // messages.stream() always returns a sync MessageStream, even with stream: true param\n  if (isStreamRequested && !isStreamingMethod) {\n    return startSpanManual(spanConfig, async span => {\n      try {\n        if (options.recordInputs && params) {\n          addPrivateRequestAttributes(span, params);\n        }\n        const result = await originalMethod.apply(context, args);\n        return instrumentAsyncIterableStream(\n          result as AsyncIterable<AnthropicAiStreamingEvent>,\n          span,\n          options.recordOutputs ?? false,\n        ) as unknown as R;\n      } catch (error) {\n        return handleStreamingError(error, span, methodPath);\n      }\n    });\n  } else {\n    return startSpanManual(spanConfig, span => {\n      try {\n        if (options.recordInputs && params) {\n          addPrivateRequestAttributes(span, params);\n        }\n        const messageStream = target.apply(context, args);\n        return instrumentMessageStream(messageStream, span, options.recordOutputs ?? false);\n      } catch (error) {\n        return handleStreamingError(error, span, methodPath);\n      }\n    });\n  }\n}\n\n/**\n * Instrument a method with Sentry spans\n * Following Sentry AI Agents Manual Instrumentation conventions\n * @see https://docs.sentry.io/platforms/javascript/guides/node/tracing/instrumentation/ai-agents-module/#manual-instrumentation\n */\nfunction instrumentMethod<T extends unknown[], R>(\n  originalMethod: (...args: T) => R | Promise<R>,\n  methodPath: AnthropicAiInstrumentedMethod,\n  context: unknown,\n  options: AnthropicAiOptions,\n): (...args: T) => R | Promise<R> {\n  return new Proxy(originalMethod, {\n    apply(target, thisArg, args: T): R | Promise<R> {\n      const requestAttributes = extractRequestAttributes(args, methodPath);\n      const model = requestAttributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] ?? 'unknown';\n      const operationName = getFinalOperationName(methodPath);\n\n      const params = typeof args[0] === 'object' ? (args[0] as Record<string, unknown>) : undefined;\n      const isStreamRequested = Boolean(params?.stream);\n      const isStreamingMethod = methodPath === 'messages.stream';\n\n      if (isStreamRequested || isStreamingMethod) {\n        return handleStreamingRequest(\n          originalMethod,\n          target,\n          context,\n          args,\n          requestAttributes,\n          operationName,\n          methodPath,\n          params,\n          options,\n          isStreamRequested,\n          isStreamingMethod,\n        );\n      }\n\n      return startSpan(\n        {\n          name: `${operationName} ${model}`,\n          op: getSpanOperation(methodPath),\n          attributes: requestAttributes as Record<string, SpanAttributeValue>,\n        },\n        span => {\n          if (options.recordInputs && params) {\n            addPrivateRequestAttributes(span, params);\n          }\n\n          return handleCallbackErrors(\n            () => target.apply(context, args),\n            error => {\n              captureException(error, {\n                mechanism: {\n                  handled: false,\n                  type: 'auto.ai.anthropic',\n                  data: {\n                    function: methodPath,\n                  },\n                },\n              });\n            },\n            () => {},\n            result => addResponseAttributes(span, result as AnthropicAiResponse, options.recordOutputs),\n          );\n        },\n      );\n    },\n  }) as (...args: T) => R | Promise<R>;\n}\n\n/**\n * Create a deep proxy for Anthropic AI client instrumentation\n */\nfunction createDeepProxy<T extends object>(target: T, currentPath = '', options: AnthropicAiOptions): T {\n  return new Proxy(target, {\n    get(obj: object, prop: string): unknown {\n      const value = (obj as Record<string, unknown>)[prop];\n      const methodPath = buildMethodPath(currentPath, String(prop));\n\n      if (typeof value === 'function' && shouldInstrument(methodPath)) {\n        return instrumentMethod(value as (...args: unknown[]) => unknown | Promise<unknown>, methodPath, obj, options);\n      }\n\n      if (typeof value === 'function') {\n        // Bind non-instrumented functions to preserve the original `this` context,\n        return value.bind(obj);\n      }\n\n      if (value && typeof value === 'object') {\n        return createDeepProxy(value, methodPath, options);\n      }\n\n      return value;\n    },\n  }) as T;\n}\n\n/**\n * Instrument an Anthropic AI client with Sentry tracing\n * Can be used across Node.js, Cloudflare Workers, and Vercel Edge\n *\n * @template T - The type of the client that extends object\n * @param client - The Anthropic AI client to instrument\n * @param options - Optional configuration for recording inputs and outputs\n * @returns The instrumented client with the same type as the input\n */\nexport function instrumentAnthropicAiClient<T extends object>(anthropicAiClient: T, options?: AnthropicAiOptions): T {\n  const sendDefaultPii = Boolean(getClient()?.getOptions().sendDefaultPii);\n\n  const _options = {\n    recordInputs: sendDefaultPii,\n    recordOutputs: sendDefaultPii,\n    ...options,\n  };\n  return createDeepProxy(anthropicAiClient, '', _options);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;AA2CA;;CAEA,GACA,SAAS,wBAAwB,CAAC,IAAI,EAAa,UAAU,EAAmC;IAC9F,MAAM,UAAU,GAA4B;QAC1C,CAAC,2RAAuB,CAAA,EAAG,WAAW;QACtC,CAAC,mSAA+B,CAAA,MAAG,uQAAqB,EAAC,UAAU,CAAC;QACpE,CAAC,8QAAgC,CAAA,EAAG,mBAAmB;IAC3D,CAAG;IAED,IAAI,IAAI,CAAC,MAAA,GAAS,CAAA,IAAK,OAAO,IAAI,CAAC,CAAC,CAAA,KAAM,YAAY,IAAI,CAAC,CAAC,CAAA,KAAM,IAAI,EAAE;QACtE,MAAM,MAAA,GAAS,IAAI,CAAC,CAAC,CAAA;QACrB,IAAI,MAAM,CAAC,KAAA,IAAS,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE;YAC/C,UAAU,CAAC,4SAAwC,CAAA,GAAI,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,KAAK,CAAC;QACrF;QAEA,UAAU,CAAC,kSAA8B,CAAA,GAAI,MAAM,CAAC,KAAA,IAAS,SAAS;QACtE,IAAI,aAAA,IAAiB,MAAM,EAAE,UAAU,CAAC,wSAAoC,CAAA,GAAI,MAAM,CAAC,WAAW;QAClG,IAAI,OAAA,IAAW,MAAM,EAAE,UAAU,CAAC,kSAA8B,CAAA,GAAI,MAAM,CAAC,KAAK;QAChF,IAAI,QAAA,IAAY,MAAM,EAAE,UAAU,CAAC,mSAA+B,CAAA,GAAI,MAAM,CAAC,MAAM;QACnF,IAAI,OAAA,IAAW,MAAM,EAAE,UAAU,CAAC,kSAA8B,CAAA,GAAI,MAAM,CAAC,KAAK;QAChF,IAAI,mBAAA,IAAuB,MAAM,EAC/B,UAAU,CAAC,8SAA0C,CAAA,GAAI,MAAM,CAAC,iBAAiB;QACnF,IAAI,YAAA,IAAgB,MAAM,EAAE,UAAU,CAAC,uSAAmC,CAAA,GAAI,MAAM,CAAC,UAAU;IACjG,OAAO;QACL,IAAI,UAAA,KAAe,qBAAqB,UAAA,KAAe,YAAY,EAAE;YACzE,qDAAA;YACM,UAAU,CAAC,kSAA8B,CAAA,GAAI,IAAI,CAAC,CAAC,CAAC;QACtD,OAAO;YACL,UAAU,CAAC,kSAA8B,CAAA,GAAI,SAAS;QACxD;IACF;IAEA,OAAO,UAAU;AACnB;AAEA;;;CAGA,GACA,SAAS,2BAA2B,CAAC,IAAI,EAAQ,MAAM,EAAiC;IACtF,IAAI,UAAA,IAAc,MAAM,EAAE;QACxB,MAAM,wBAAoB,wQAAsB,EAAC,MAAM,CAAC,QAAQ,CAAC;QACjE,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,qSAAiC,CAAA,EAAG,iBAAA;QAAA,CAAmB,CAAC;IAChF;IACA,IAAI,OAAA,IAAW,MAAM,EAAE;QACrB,MAAM,qBAAiB,wQAAsB,EAAC,MAAM,CAAC,KAAK,CAAC;QAC3D,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,qSAAiC,CAAA,EAAG,cAAA;QAAA,CAAgB,CAAC;IAC7E;IAEA,IAAI,QAAA,IAAY,MAAM,EAAE;QACtB,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,2RAAuB,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,MAAM,CAAA;QAAA,CAAG,CAAC;IAClF;AACF;AAEA;;CAEA,GACA,SAAS,oBAAoB,CAAC,IAAI,EAAQ,QAAQ,EAA6B;IAC/E,kBAAA;IACE,IAAI,SAAA,IAAa,QAAQ,EAAE;QACzB,IAAI,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,OAAO,CAAC,EAAE;YACnC,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,kSAA8B,CAAA,EAAG,QAAQ,CAAC,OAAA,CACxC,GAAG,CAAC,CAAC,IAAI,GAAmB,IAAI,CAAC,IAAI,EACrC,MAAM,EAAC,OAAQ,CAAC,CAAC,IAAI,EACrB,IAAI,CAAC,EAAE,CAAC;YACnB,CAAO,CAAC;YAEF,MAAM,SAAS,GAAwB,EAAE;YAEzC,KAAK,MAAM,IAAA,IAAQ,QAAQ,CAAC,OAAO,CAAE;gBACnC,IAAI,IAAI,CAAC,IAAA,KAAS,UAAA,IAAc,IAAI,CAAC,IAAA,KAAS,iBAAiB,EAAE;oBAC/D,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC;gBACtB;YACF;YACA,IAAI,SAAS,CAAC,MAAA,GAAS,CAAC,EAAE;gBACxB,IAAI,CAAC,aAAa,CAAC;oBAAE,CAAC,wSAAoC,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,SAAS,CAAA;gBAAA,CAAG,CAAC;YAC3F;QACF;IACF;IACF,qBAAA;IACE,IAAI,YAAA,IAAgB,QAAQ,EAAE;QAC5B,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,kSAA8B,CAAA,EAAG,QAAQ,CAAC,UAAA;QAAA,CAAY,CAAC;IAC/E;IACF,qBAAA;IACE,IAAI,cAAA,IAAkB,QAAQ,EAAE;QAC9B,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,kSAA8B,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,YAAY,CAAA;QAAA,CAAG,CAAC;IACjG;AACF;AAEA;;CAEA,GACA,SAAS,qBAAqB,CAAC,IAAI,EAAQ,QAAQ,EAA6B;IAC9E,IAAI,IAAA,IAAQ,YAAY,OAAA,IAAW,QAAQ,EAAE;QAC3C,IAAI,CAAC,aAAa,CAAC;YACjB,CAAC,gSAA4B,CAAA,EAAG,QAAQ,CAAC,EAAE;YAC3C,CAAC,mSAA+B,CAAA,EAAG,QAAQ,CAAC,KAAK;QACvD,CAAK,CAAC;QAEF,IAAI,SAAA,IAAa,QAAA,IAAY,OAAO,QAAQ,CAAC,OAAA,KAAY,QAAQ,EAAE;YACjE,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,6SAAyC,CAAA,EAAG,IAAI,IAAI,CAAC,QAAQ,CAAC,OAAA,GAAU,IAAI,CAAC,CAAC,WAAW,EAAE;YACpG,CAAO,CAAC;QACJ;QACA,IAAI,YAAA,IAAgB,QAAA,IAAY,OAAO,QAAQ,CAAC,UAAA,KAAe,QAAQ,EAAE;YACvE,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,6SAAyC,CAAA,EAAG,IAAI,IAAI,CAAC,QAAQ,CAAC,UAAA,GAAa,IAAI,CAAC,CAAC,WAAW,EAAE;YACvG,CAAO,CAAC;QACJ;QAEA,IAAI,OAAA,IAAW,YAAY,QAAQ,CAAC,KAAK,EAAE;gBACzC,yQAAuB,EACrB,IAAI,EACJ,QAAQ,CAAC,KAAK,CAAC,YAAY,EAC3B,QAAQ,CAAC,KAAK,CAAC,aAAa,EAC5B,QAAQ,CAAC,KAAK,CAAC,2BAA2B,EAC1C,QAAQ,CAAC,KAAK,CAAC,uBAAuB;QAE1C;IACF;AACF;AAEA;;CAEA,GACA,SAAS,qBAAqB,CAAC,IAAI,EAAQ,QAAQ,EAAuB,aAAa,EAAkB;IACvG,IAAI,CAAC,QAAA,IAAY,OAAO,QAAA,KAAa,QAAQ,EAAE;IAEjD,uEAAA;IACE,IAAI,MAAA,IAAU,QAAA,IAAY,QAAQ,CAAC,IAAA,KAAS,OAAO,EAAE;YACnD,kRAAmB,EAAC,IAAI,EAAE,QAAQ,CAAC;QACnC;IACF;IAEF,+EAAA;IACE,IAAI,aAAa,EAAE;QACjB,oBAAoB,CAAC,IAAI,EAAE,QAAQ,CAAC;IACtC;IAEF,gCAAA;IACE,qBAAqB,CAAC,IAAI,EAAE,QAAQ,CAAC;AACvC;AAEA;;CAEA,GACA,SAAS,oBAAoB,CAAC,KAAK,EAAW,IAAI,EAAQ,UAAU,EAAiB;QACnF,mPAAgB,EAAC,KAAK,EAAE;QACtB,SAAS,EAAE;YAAE,OAAO,EAAE,KAAK;YAAE,IAAI,EAAE,mBAAmB;YAAE,IAAI,EAAE;gBAAE,QAAQ,EAAE,UAAA;YAAA;QAAA,CAAc;IAC5F,CAAG,CAAC;IAEF,IAAI,IAAI,CAAC,WAAW,EAAE,EAAE;QACtB,IAAI,CAAC,SAAS,CAAC;YAAE,IAAI,EAAE,kQAAiB;YAAE,OAAO,EAAE,gBAAA;QAAA,CAAkB,CAAC;QACtE,IAAI,CAAC,GAAG,EAAE;IACZ;IACA,MAAM,KAAK;AACb;AAEA;;CAEA,GACA,SAAS,sBAAsB,CAC7B,cAAc,EACd,MAAM,EACN,OAAO,EACP,IAAI,EACJ,iBAAiB,EACjB,aAAa,EACb,UAAU,EACV,MAAM,EACN,OAAO,EACP,iBAAiB,EACjB,iBAAiB;IAEjB,MAAM,QAAQ,iBAAiB,CAAC,kSAA8B,CAAA,IAAK,SAAS;IAC5E,MAAM,aAAa;QACjB,IAAI,EAAE,CAAC,EAAA,aAAA,CAAA,CAAA,EAAA,KAAA,CAAA,gBAAA,CAAA;QACA,EAAA,MAAA,kQAAA,EAAA,UAAA,CAAA;QACA,UAAA,EAAA,iBAAA;IACA,CAAA;IAEA,sFAAA;IACA,IAAA,iBAAA,IAAA,CAAA,iBAAA,EAAA;QACA,WAAA,2PAAA,EAAA,UAAA,EAAA,OAAA,IAAA,IAAA;YACA,IAAA;gBACA,IAAA,OAAA,CAAA,YAAA,IAAA,MAAA,EAAA;oBACA,2BAAA,CAAA,IAAA,EAAA,MAAA,CAAA;gBACA;gBACA,MAAA,MAAA,GAAA,MAAA,cAAA,CAAA,KAAA,CAAA,OAAA,EAAA,IAAA,CAAA;gBACA,WAAA,gSAAA,EACA,MAAA,EACA,IAAA,EACA,OAAA,CAAA,aAAA,IAAA,KAAA;YAEA,CAAA,CAAA,OAAA,KAAA,EAAA;gBACA,OAAA,oBAAA,CAAA,KAAA,EAAA,IAAA,EAAA,UAAA,CAAA;YACA;QACA,CAAA,CAAA;IACA,CAAA,MAAA;QACA,WAAA,2PAAA,EAAA,UAAA,GAAA,IAAA,IAAA;YACA,IAAA;gBACA,IAAA,OAAA,CAAA,YAAA,IAAA,MAAA,EAAA;oBACA,2BAAA,CAAA,IAAA,EAAA,MAAA,CAAA;gBACA;gBACA,MAAA,aAAA,GAAA,MAAA,CAAA,KAAA,CAAA,OAAA,EAAA,IAAA,CAAA;gBACA,WAAA,0RAAA,EAAA,aAAA,EAAA,IAAA,EAAA,OAAA,CAAA,aAAA,IAAA,KAAA,CAAA;YACA,CAAA,CAAA,OAAA,KAAA,EAAA;gBACA,OAAA,oBAAA,CAAA,KAAA,EAAA,IAAA,EAAA,UAAA,CAAA;YACA;QACA,CAAA,CAAA;IACA;AACA;AAEA;;;;CAIA,GACA,SAAA,gBAAA,CACA,cAAA,EACA,UAAA,EACA,OAAA,EACA,OAAA;IAEA,OAAA,IAAA,KAAA,CAAA,cAAA,EAAA;QACA,KAAA,EAAA,MAAA,EAAA,OAAA,EAAA,IAAA,EAAA;YACA,MAAA,iBAAA,GAAA,wBAAA,CAAA,IAAA,EAAA,UAAA,CAAA;YACA,MAAA,KAAA,GAAA,iBAAA,CAAA,kSAAA,CAAA,IAAA,SAAA;YACA,MAAA,aAAA,OAAA,uQAAA,EAAA,UAAA,CAAA;YAEA,MAAA,MAAA,GAAA,OAAA,IAAA,CAAA,CAAA,CAAA,KAAA,QAAA,GAAA,IAAA,CAAA,CAAA,CAAA,GAAA,SAAA;YACA,MAAA,iBAAA,GAAA,OAAA,CAAA,MAAA,EAAA,MAAA,CAAA;YACA,MAAA,iBAAA,GAAA,UAAA,KAAA,iBAAA;YAEA,IAAA,iBAAA,IAAA,iBAAA,EAAA;gBACA,OAAA,sBAAA,CACA,cAAA,EACA,MAAA,EACA,OAAA,EACA,IAAA,EACA,iBAAA,EACA,aAAA,EACA,UAAA,EACA,MAAA,EACA,OAAA,EACA,iBAAA,EACA,iBAAA;YAEA;YAEA,WAAA,qPAAA,EACA;gBACA,IAAA,EAAA,CAAA,EAAA,aAAA,CAAA,CAAA,EAAA,KAAA,CAAA,CAAA;gBACA,EAAA,MAAA,kQAAA,EAAA,UAAA,CAAA;gBACA,UAAA,EAAA,iBAAA;YACA,CAAA,GACA,IAAA,IAAA;gBACA,IAAA,OAAA,CAAA,YAAA,IAAA,MAAA,EAAA;oBACA,2BAAA,CAAA,IAAA,EAAA,MAAA,CAAA;gBACA;gBAEA,WAAA,6QAAA,EACA,IAAA,MAAA,CAAA,KAAA,CAAA,OAAA,EAAA,IAAA,CAAA,GACA,KAAA,IAAA;wBACA,mPAAA,EAAA,KAAA,EAAA;wBACA,SAAA,EAAA;4BACA,OAAA,EAAA,KAAA;4BACA,IAAA,EAAA,mBAAA;4BACA,IAAA,EAAA;gCACA,QAAA,EAAA,UAAA;4BACA,CAAA;wBACA,CAAA;oBACA,CAAA,CAAA;gBACA,CAAA,EACA,KAAA,CAAA,GACA,MAAA,GAAA,qBAAA,CAAA,IAAA,EAAA,MAAA,EAAA,OAAA,CAAA,aAAA,CAAA;YAEA,CAAA;QAEA,CAAA;IACA,CAAA,CAAA;AACA;AAEA;;CAEA,GACA,SAAA,eAAA,CAAA,MAAA,EAAA,WAAA,GAAA,EAAA,EAAA,OAAA,EAAA;IACA,OAAA,IAAA,KAAA,CAAA,MAAA,EAAA;QACA,GAAA,EAAA,GAAA,EAAA,IAAA,EAAA;YACA,MAAA,KAAA,GAAA,GAAA,CAAA,IAAA,CAAA;YACA,MAAA,UAAA,OAAA,iQAAA,EAAA,WAAA,EAAA,MAAA,CAAA,IAAA,CAAA,CAAA;YAEA,IAAA,OAAA,KAAA,KAAA,UAAA,QAAA,+QAAA,EAAA,UAAA,CAAA,EAAA;gBACA,OAAA,gBAAA,CAAA,KAAA,EAAA,UAAA,EAAA,GAAA,EAAA,OAAA,CAAA;YACA;YAEA,IAAA,OAAA,KAAA,KAAA,UAAA,EAAA;gBACA,2EAAA;gBACA,OAAA,KAAA,CAAA,IAAA,CAAA,GAAA,CAAA;YACA;YAEA,IAAA,KAAA,IAAA,OAAA,KAAA,KAAA,QAAA,EAAA;gBACA,OAAA,eAAA,CAAA,KAAA,EAAA,UAAA,EAAA,OAAA,CAAA;YACA;YAEA,OAAA,KAAA;QACA,CAAA;IACA,CAAA,CAAA;AACA;AAEA;;;;;;;;CAQA,GACA,SAAA,2BAAA,CAAA,iBAAA,EAAA,OAAA,EAAA;IACA,MAAA,cAAA,GAAA,OAAA,KAAA,kPAAA,EAAA,GAAA,UAAA,EAAA,CAAA,cAAA,CAAA;IAEA,MAAA,QAAA,GAAA;QACA,YAAA,EAAA,cAAA;QACA,aAAA,EAAA,cAAA;QACA,GAAA,OAAA;IACA,CAAA;IACA,OAAA,eAAA,CAAA,iBAAA,EAAA,EAAA,EAAA,QAAA,CAAA;AACA"}},
    {"offset": {"line": 3848, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/google-genai/constants.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/google-genai/constants.ts"],"sourcesContent":["export const GOOGLE_GENAI_INTEGRATION_NAME = 'Google_GenAI';\n\n// https://ai.google.dev/api/rest/v1/models/generateContent\n// https://ai.google.dev/api/rest/v1/chats/sendMessage\n// https://googleapis.github.io/js-genai/release_docs/classes/models.Models.html#generatecontentstream\n// https://googleapis.github.io/js-genai/release_docs/classes/chats.Chat.html#sendmessagestream\nexport const GOOGLE_GENAI_INSTRUMENTED_METHODS = [\n  'models.generateContent',\n  'models.generateContentStream',\n  'chats.create',\n  'sendMessage',\n  'sendMessageStream',\n] as const;\n\n// Constants for internal use\nexport const GOOGLE_GENAI_SYSTEM_NAME = 'google_genai';\nexport const CHATS_CREATE_METHOD = 'chats.create';\nexport const CHAT_PATH = 'chat';\n"],"names":[],"mappings":";;;;;;;;;;;;AAAO,MAAM,6BAAA,GAAgC;AAE7C,2DAAA;AACA,sDAAA;AACA,sGAAA;AACA,+FAAA;AACO,MAAM,oCAAoC;IAC/C,wBAAwB;IACxB,8BAA8B;IAC9B,cAAc;IACd,aAAa;IACb,mBAAmB;CACrB;AAEA,6BAAA;AACO,MAAM,wBAAA,GAA2B;AACjC,MAAM,mBAAA,GAAsB;AAC5B,MAAM,SAAA,GAAY"}},
    {"offset": {"line": 3882, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/google-genai/streaming.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/google-genai/streaming.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport type { Span, SpanAttributeValue } from '../../types-hoist/span';\nimport {\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_STREAMING_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport type { GoogleGenAIResponse } from './types';\n\n/**\n * State object used to accumulate information from a stream of Google GenAI events.\n */\ninterface StreamingState {\n  /** Collected response text fragments (for output recording). */\n  responseTexts: string[];\n  /** Reasons for finishing the response, as reported by the API. */\n  finishReasons: string[];\n  /** The response ID. */\n  responseId?: string;\n  /** The model name. */\n  responseModel?: string;\n  /** Number of prompt/input tokens used. */\n  promptTokens?: number;\n  /** Number of completion/output tokens used. */\n  completionTokens?: number;\n  /** Number of total tokens used. */\n  totalTokens?: number;\n  /** Accumulated tool calls (finalized) */\n  toolCalls: Array<Record<string, unknown>>;\n}\n\n/**\n * Checks if a response chunk contains an error\n * @param chunk - The response chunk to check\n * @param span - The span to update if error is found\n * @returns Whether an error occurred\n */\nfunction isErrorChunk(chunk: GoogleGenAIResponse, span: Span): boolean {\n  const feedback = chunk?.promptFeedback;\n  if (feedback?.blockReason) {\n    const message = feedback.blockReasonMessage ?? feedback.blockReason;\n    span.setStatus({ code: SPAN_STATUS_ERROR, message: `Content blocked: ${message}` });\n    captureException(`Content blocked: ${message}`, {\n      mechanism: { handled: false, type: 'auto.ai.google_genai' },\n    });\n    return true;\n  }\n  return false;\n}\n\n/**\n * Processes response metadata from a chunk\n * @param chunk - The response chunk to process\n * @param state - The state of the streaming process\n */\nfunction handleResponseMetadata(chunk: GoogleGenAIResponse, state: StreamingState): void {\n  if (typeof chunk.responseId === 'string') state.responseId = chunk.responseId;\n  if (typeof chunk.modelVersion === 'string') state.responseModel = chunk.modelVersion;\n\n  const usage = chunk.usageMetadata;\n  if (usage) {\n    if (typeof usage.promptTokenCount === 'number') state.promptTokens = usage.promptTokenCount;\n    if (typeof usage.candidatesTokenCount === 'number') state.completionTokens = usage.candidatesTokenCount;\n    if (typeof usage.totalTokenCount === 'number') state.totalTokens = usage.totalTokenCount;\n  }\n}\n\n/**\n * Processes candidate content from a response chunk\n * @param chunk - The response chunk to process\n * @param state - The state of the streaming process\n * @param recordOutputs - Whether to record outputs\n */\nfunction handleCandidateContent(chunk: GoogleGenAIResponse, state: StreamingState, recordOutputs: boolean): void {\n  if (Array.isArray(chunk.functionCalls)) {\n    state.toolCalls.push(...chunk.functionCalls);\n  }\n\n  for (const candidate of chunk.candidates ?? []) {\n    if (candidate?.finishReason && !state.finishReasons.includes(candidate.finishReason)) {\n      state.finishReasons.push(candidate.finishReason);\n    }\n\n    for (const part of candidate?.content?.parts ?? []) {\n      if (recordOutputs && part.text) state.responseTexts.push(part.text);\n      if (part.functionCall) {\n        state.toolCalls.push({\n          type: 'function',\n          id: part.functionCall.id,\n          name: part.functionCall.name,\n          arguments: part.functionCall.args,\n        });\n      }\n    }\n  }\n}\n\n/**\n * Processes a single chunk from the Google GenAI stream\n * @param chunk - The chunk to process\n * @param state - The state of the streaming process\n * @param recordOutputs - Whether to record outputs\n * @param span - The span to update\n */\nfunction processChunk(chunk: GoogleGenAIResponse, state: StreamingState, recordOutputs: boolean, span: Span): void {\n  if (!chunk || isErrorChunk(chunk, span)) return;\n  handleResponseMetadata(chunk, state);\n  handleCandidateContent(chunk, state, recordOutputs);\n}\n\n/**\n * Instruments an async iterable stream of Google GenAI response chunks, updates the span with\n * streaming attributes and (optionally) the aggregated output text, and yields\n * each chunk from the input stream unchanged.\n */\nexport async function* instrumentStream(\n  stream: AsyncIterable<GoogleGenAIResponse>,\n  span: Span,\n  recordOutputs: boolean,\n): AsyncGenerator<GoogleGenAIResponse, void, unknown> {\n  const state: StreamingState = {\n    responseTexts: [],\n    finishReasons: [],\n    toolCalls: [],\n  };\n\n  try {\n    for await (const chunk of stream) {\n      processChunk(chunk, state, recordOutputs, span);\n      yield chunk;\n    }\n  } finally {\n    const attrs: Record<string, SpanAttributeValue> = {\n      [GEN_AI_RESPONSE_STREAMING_ATTRIBUTE]: true,\n    };\n\n    if (state.responseId) attrs[GEN_AI_RESPONSE_ID_ATTRIBUTE] = state.responseId;\n    if (state.responseModel) attrs[GEN_AI_RESPONSE_MODEL_ATTRIBUTE] = state.responseModel;\n    if (state.promptTokens !== undefined) attrs[GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE] = state.promptTokens;\n    if (state.completionTokens !== undefined) attrs[GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE] = state.completionTokens;\n    if (state.totalTokens !== undefined) attrs[GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE] = state.totalTokens;\n\n    if (state.finishReasons.length) {\n      attrs[GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE] = JSON.stringify(state.finishReasons);\n    }\n    if (recordOutputs && state.responseTexts.length) {\n      attrs[GEN_AI_RESPONSE_TEXT_ATTRIBUTE] = state.responseTexts.join('');\n    }\n    if (recordOutputs && state.toolCalls.length) {\n      attrs[GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE] = JSON.stringify(state.toolCalls);\n    }\n\n    span.setAttributes(attrs);\n    span.end();\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;AAgBA;;CAEA,GAoBA;;;;;CAKA,GACA,SAAS,YAAY,CAAC,KAAK,EAAuB,IAAI,EAAiB;IACrE,MAAM,QAAA,GAAW,KAAK,EAAE,cAAc;IACtC,IAAI,QAAQ,EAAE,WAAW,EAAE;QACzB,MAAM,UAAU,QAAQ,CAAC,kBAAA,IAAsB,QAAQ,CAAC,WAAW;QACnE,IAAI,CAAC,SAAS,CAAC;YAAE,IAAI,EAAE,kQAAiB;YAAE,OAAO,EAAE,CAAC,iBAAiB,EAAE,OAAO,CAAC,CAAA;QAAA,CAAA,CAAA;YACA,mPAAA,EAAA,CAAA,iBAAA,EAAA,OAAA,CAAA,CAAA,EAAA;YACA,SAAA,EAAA;gBAAA,OAAA,EAAA,KAAA;gBAAA,IAAA,EAAA,sBAAA;YAAA,CAAA;QACA,CAAA,CAAA;QACA,OAAA,IAAA;IACA;IACA,OAAA,KAAA;AACA;AAEA;;;;CAIA,GACA,SAAA,sBAAA,CAAA,KAAA,EAAA,KAAA,EAAA;IACA,IAAA,OAAA,KAAA,CAAA,UAAA,KAAA,QAAA,EAAA,KAAA,CAAA,UAAA,GAAA,KAAA,CAAA,UAAA;IACA,IAAA,OAAA,KAAA,CAAA,YAAA,KAAA,QAAA,EAAA,KAAA,CAAA,aAAA,GAAA,KAAA,CAAA,YAAA;IAEA,MAAA,KAAA,GAAA,KAAA,CAAA,aAAA;IACA,IAAA,KAAA,EAAA;QACA,IAAA,OAAA,KAAA,CAAA,gBAAA,KAAA,QAAA,EAAA,KAAA,CAAA,YAAA,GAAA,KAAA,CAAA,gBAAA;QACA,IAAA,OAAA,KAAA,CAAA,oBAAA,KAAA,QAAA,EAAA,KAAA,CAAA,gBAAA,GAAA,KAAA,CAAA,oBAAA;QACA,IAAA,OAAA,KAAA,CAAA,eAAA,KAAA,QAAA,EAAA,KAAA,CAAA,WAAA,GAAA,KAAA,CAAA,eAAA;IACA;AACA;AAEA;;;;;CAKA,GACA,SAAA,sBAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,EAAA;IACA,IAAA,KAAA,CAAA,OAAA,CAAA,KAAA,CAAA,aAAA,CAAA,EAAA;QACA,KAAA,CAAA,SAAA,CAAA,IAAA,CAAA,GAAA,KAAA,CAAA,aAAA,CAAA;IACA;IAEA,KAAA,MAAA,SAAA,IAAA,KAAA,CAAA,UAAA,IAAA,EAAA,CAAA;QACA,IAAA,SAAA,EAAA,YAAA,IAAA,CAAA,KAAA,CAAA,aAAA,CAAA,QAAA,CAAA,SAAA,CAAA,YAAA,CAAA,EAAA;YACA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,SAAA,CAAA,YAAA,CAAA;QACA;QAEA,KAAA,MAAA,IAAA,IAAA,SAAA,EAAA,OAAA,EAAA,KAAA,IAAA,EAAA,CAAA;YACA,IAAA,aAAA,IAAA,IAAA,CAAA,IAAA,EAAA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,IAAA,CAAA,IAAA,CAAA;YACA,IAAA,IAAA,CAAA,YAAA,EAAA;gBACA,KAAA,CAAA,SAAA,CAAA,IAAA,CAAA;oBACA,IAAA,EAAA,UAAA;oBACA,EAAA,EAAA,IAAA,CAAA,YAAA,CAAA,EAAA;oBACA,IAAA,EAAA,IAAA,CAAA,YAAA,CAAA,IAAA;oBACA,SAAA,EAAA,IAAA,CAAA,YAAA,CAAA,IAAA;gBACA,CAAA,CAAA;YACA;QACA;IACA;AACA;AAEA;;;;;;CAMA,GACA,SAAA,YAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,EAAA,IAAA,EAAA;IACA,IAAA,CAAA,KAAA,IAAA,YAAA,CAAA,KAAA,EAAA,IAAA,CAAA,EAAA;IACA,sBAAA,CAAA,KAAA,EAAA,KAAA,CAAA;IACA,sBAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,CAAA;AACA;AAEA;;;;CAIA,GACA,gBAAA,gBAAA,CACA,MAAA,EACA,IAAA,EACA,aAAA;IAEA,MAAA,KAAA,GAAA;QACA,aAAA,EAAA,EAAA;QACA,aAAA,EAAA,EAAA;QACA,SAAA,EAAA,EAAA;IACA,CAAA;IAEA,IAAA;QACA,WAAA,MAAA,KAAA,IAAA,MAAA,CAAA;YACA,YAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,EAAA,IAAA,CAAA;YACA,MAAA,KAAA;QACA;IACA,CAAA,QAAA;QACA,MAAA,KAAA,GAAA;YACA,CAAA,uSAAA,CAAA,EAAA,IAAA;QACA,CAAA;QAEA,IAAA,KAAA,CAAA,UAAA,EAAA,KAAA,CAAA,gSAAA,CAAA,GAAA,KAAA,CAAA,UAAA;QACA,IAAA,KAAA,CAAA,aAAA,EAAA,KAAA,CAAA,mSAAA,CAAA,GAAA,KAAA,CAAA,aAAA;QACA,IAAA,KAAA,CAAA,YAAA,KAAA,SAAA,EAAA,KAAA,CAAA,uSAAA,CAAA,GAAA,KAAA,CAAA,YAAA;QACA,IAAA,KAAA,CAAA,gBAAA,KAAA,SAAA,EAAA,KAAA,CAAA,wSAAA,CAAA,GAAA,KAAA,CAAA,gBAAA;QACA,IAAA,KAAA,CAAA,WAAA,KAAA,SAAA,EAAA,KAAA,CAAA,uSAAA,CAAA,GAAA,KAAA,CAAA,WAAA;QAEA,IAAA,KAAA,CAAA,aAAA,CAAA,MAAA,EAAA;YACA,KAAA,CAAA,4SAAA,CAAA,GAAA,IAAA,CAAA,SAAA,CAAA,KAAA,CAAA,aAAA,CAAA;QACA;QACA,IAAA,aAAA,IAAA,KAAA,CAAA,aAAA,CAAA,MAAA,EAAA;YACA,KAAA,CAAA,kSAAA,CAAA,GAAA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,EAAA,CAAA;QACA;QACA,IAAA,aAAA,IAAA,KAAA,CAAA,SAAA,CAAA,MAAA,EAAA;YACA,KAAA,CAAA,wSAAA,CAAA,GAAA,IAAA,CAAA,SAAA,CAAA,KAAA,CAAA,SAAA,CAAA;QACA;QAEA,IAAA,CAAA,aAAA,CAAA,KAAA,CAAA;QACA,IAAA,CAAA,GAAA,EAAA;IACA;AACA"}},
    {"offset": {"line": 4011, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/google-genai/utils.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/google-genai/utils.ts"],"sourcesContent":["import { GOOGLE_GENAI_INSTRUMENTED_METHODS } from './constants';\nimport type { GoogleGenAIIstrumentedMethod } from './types';\n\n/**\n * Check if a method path should be instrumented\n */\nexport function shouldInstrument(methodPath: string): methodPath is GoogleGenAIIstrumentedMethod {\n  // Check for exact matches first (like 'models.generateContent')\n  if (GOOGLE_GENAI_INSTRUMENTED_METHODS.includes(methodPath as GoogleGenAIIstrumentedMethod)) {\n    return true;\n  }\n\n  // Check for method name matches (like 'sendMessage' from chat instances)\n  const methodName = methodPath.split('.').pop();\n  return GOOGLE_GENAI_INSTRUMENTED_METHODS.includes(methodName as GoogleGenAIIstrumentedMethod);\n}\n\n/**\n * Check if a method is a streaming method\n */\nexport function isStreamingMethod(methodPath: string): boolean {\n  return (\n    methodPath.includes('Stream') ||\n    methodPath.endsWith('generateContentStream') ||\n    methodPath.endsWith('sendMessageStream')\n  );\n}\n"],"names":[],"mappings":";;;;;;;;AAGA;;CAEA,GACO,SAAS,gBAAgB,CAAC,UAAU,EAAsD;IACjG,gEAAA;IACE,IAAI,oSAAiC,CAAC,QAAQ,CAAC,UAAA,EAA2C,CAAE;QAC1F,OAAO,IAAI;IACb;IAEF,yEAAA;IACE,MAAM,UAAA,GAAa,UAAU,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE;IAC9C,OAAO,oSAAiC,CAAC,QAAQ,CAAC,YAA2C;AAC/F;AAEA;;CAEA,GACO,SAAS,iBAAiB,CAAC,UAAU,EAAmB;IAC7D,OACE,UAAU,CAAC,QAAQ,CAAC,QAAQ,CAAA,IAC5B,UAAU,CAAC,QAAQ,CAAC,uBAAuB,CAAA,IAC3C,UAAU,CAAC,QAAQ,CAAC,mBAAmB;AAE3C"}},
    {"offset": {"line": 4041, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/google-genai/index.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/google-genai/index.ts"],"sourcesContent":["import { getClient } from '../../currentScopes';\nimport { captureException } from '../../exports';\nimport { SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN } from '../../semanticAttributes';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport { startSpan, startSpanManual } from '../../tracing/trace';\nimport type { Span, SpanAttributeValue } from '../../types-hoist/span';\nimport { handleCallbackErrors } from '../../utils/handleCallbackErrors';\nimport {\n  GEN_AI_OPERATION_NAME_ATTRIBUTE,\n  GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE,\n  GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE,\n  GEN_AI_REQUEST_MESSAGES_ATTRIBUTE,\n  GEN_AI_REQUEST_MODEL_ATTRIBUTE,\n  GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_K_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_P_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  GEN_AI_SYSTEM_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { buildMethodPath, getFinalOperationName, getSpanOperation, getTruncatedJsonString } from '../ai/utils';\nimport { CHAT_PATH, CHATS_CREATE_METHOD, GOOGLE_GENAI_SYSTEM_NAME } from './constants';\nimport { instrumentStream } from './streaming';\nimport type {\n  Candidate,\n  ContentPart,\n  GoogleGenAIIstrumentedMethod,\n  GoogleGenAIOptions,\n  GoogleGenAIResponse,\n} from './types';\nimport { isStreamingMethod, shouldInstrument } from './utils';\n\n/**\n * Extract model from parameters or chat context object\n * For chat instances, the model is available on the chat object as 'model' (older versions) or 'modelVersion' (newer versions)\n */\nexport function extractModel(params: Record<string, unknown>, context?: unknown): string {\n  if ('model' in params && typeof params.model === 'string') {\n    return params.model;\n  }\n\n  // Try to get model from chat context object (chat instance has model property)\n  if (context && typeof context === 'object') {\n    const contextObj = context as Record<string, unknown>;\n\n    // Check for 'model' property (older versions, and streaming)\n    if ('model' in contextObj && typeof contextObj.model === 'string') {\n      return contextObj.model;\n    }\n\n    // Check for 'modelVersion' property (newer versions)\n    if ('modelVersion' in contextObj && typeof contextObj.modelVersion === 'string') {\n      return contextObj.modelVersion;\n    }\n  }\n\n  return 'unknown';\n}\n\n/**\n * Extract generation config parameters\n */\nfunction extractConfigAttributes(config: Record<string, unknown>): Record<string, SpanAttributeValue> {\n  const attributes: Record<string, SpanAttributeValue> = {};\n\n  if ('temperature' in config && typeof config.temperature === 'number') {\n    attributes[GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE] = config.temperature;\n  }\n  if ('topP' in config && typeof config.topP === 'number') {\n    attributes[GEN_AI_REQUEST_TOP_P_ATTRIBUTE] = config.topP;\n  }\n  if ('topK' in config && typeof config.topK === 'number') {\n    attributes[GEN_AI_REQUEST_TOP_K_ATTRIBUTE] = config.topK;\n  }\n  if ('maxOutputTokens' in config && typeof config.maxOutputTokens === 'number') {\n    attributes[GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE] = config.maxOutputTokens;\n  }\n  if ('frequencyPenalty' in config && typeof config.frequencyPenalty === 'number') {\n    attributes[GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE] = config.frequencyPenalty;\n  }\n  if ('presencePenalty' in config && typeof config.presencePenalty === 'number') {\n    attributes[GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE] = config.presencePenalty;\n  }\n\n  return attributes;\n}\n\n/**\n * Extract request attributes from method arguments\n * Builds the base attributes for span creation including system info, model, and config\n */\nfunction extractRequestAttributes(\n  methodPath: string,\n  params?: Record<string, unknown>,\n  context?: unknown,\n): Record<string, SpanAttributeValue> {\n  const attributes: Record<string, SpanAttributeValue> = {\n    [GEN_AI_SYSTEM_ATTRIBUTE]: GOOGLE_GENAI_SYSTEM_NAME,\n    [GEN_AI_OPERATION_NAME_ATTRIBUTE]: getFinalOperationName(methodPath),\n    [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: 'auto.ai.google_genai',\n  };\n\n  if (params) {\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = extractModel(params, context);\n\n    // Extract generation config parameters\n    if ('config' in params && typeof params.config === 'object' && params.config) {\n      const config = params.config as Record<string, unknown>;\n      Object.assign(attributes, extractConfigAttributes(config));\n\n      // Extract available tools from config\n      if ('tools' in config && Array.isArray(config.tools)) {\n        const functionDeclarations = config.tools.flatMap(\n          (tool: { functionDeclarations: unknown[] }) => tool.functionDeclarations,\n        );\n        attributes[GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE] = JSON.stringify(functionDeclarations);\n      }\n    }\n  } else {\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = extractModel({}, context);\n  }\n\n  return attributes;\n}\n\n/**\n * Add private request attributes to spans.\n * This is only recorded if recordInputs is true.\n * Handles different parameter formats for different Google GenAI methods.\n */\nfunction addPrivateRequestAttributes(span: Span, params: Record<string, unknown>): void {\n  // For models.generateContent: ContentListUnion: Content | Content[] | PartUnion | PartUnion[]\n  if ('contents' in params) {\n    const contents = params.contents;\n    // For models.generateContent: ContentListUnion: Content | Content[] | PartUnion | PartUnion[]\n    const truncatedContents = getTruncatedJsonString(contents);\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: truncatedContents });\n  }\n\n  // For chat.sendMessage: message can be string or Part[]\n  if ('message' in params) {\n    const message = params.message;\n    const truncatedMessage = getTruncatedJsonString(message);\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: truncatedMessage });\n  }\n\n  // For chats.create: history contains the conversation history\n  if ('history' in params) {\n    const history = params.history;\n    const truncatedHistory = getTruncatedJsonString(history);\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: truncatedHistory });\n  }\n}\n\n/**\n * Add response attributes from the Google GenAI response\n * @see https://github.com/googleapis/js-genai/blob/v1.19.0/src/types.ts#L2313\n */\nfunction addResponseAttributes(span: Span, response: GoogleGenAIResponse, recordOutputs?: boolean): void {\n  if (!response || typeof response !== 'object') return;\n\n  // Add usage metadata if present\n  if (response.usageMetadata && typeof response.usageMetadata === 'object') {\n    const usage = response.usageMetadata;\n    if (typeof usage.promptTokenCount === 'number') {\n      span.setAttributes({\n        [GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE]: usage.promptTokenCount,\n      });\n    }\n    if (typeof usage.candidatesTokenCount === 'number') {\n      span.setAttributes({\n        [GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE]: usage.candidatesTokenCount,\n      });\n    }\n    if (typeof usage.totalTokenCount === 'number') {\n      span.setAttributes({\n        [GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE]: usage.totalTokenCount,\n      });\n    }\n  }\n\n  // Add response text if recordOutputs is enabled\n  if (recordOutputs && Array.isArray(response.candidates) && response.candidates.length > 0) {\n    const responseTexts = response.candidates\n      .map((candidate: Candidate) => {\n        if (candidate.content?.parts && Array.isArray(candidate.content.parts)) {\n          return candidate.content.parts\n            .map((part: ContentPart) => (typeof part.text === 'string' ? part.text : ''))\n            .filter((text: string) => text.length > 0)\n            .join('');\n        }\n        return '';\n      })\n      .filter((text: string) => text.length > 0);\n\n    if (responseTexts.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: responseTexts.join(''),\n      });\n    }\n  }\n\n  // Add tool calls if recordOutputs is enabled\n  if (recordOutputs && response.functionCalls) {\n    const functionCalls = response.functionCalls;\n    if (Array.isArray(functionCalls) && functionCalls.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE]: JSON.stringify(functionCalls),\n      });\n    }\n  }\n}\n\n/**\n * Instrument any async or synchronous genai method with Sentry spans\n * Handles operations like models.generateContent and chat.sendMessage and chats.create\n * @see https://docs.sentry.io/platforms/javascript/guides/node/tracing/instrumentation/ai-agents-module/#manual-instrumentation\n */\nfunction instrumentMethod<T extends unknown[], R>(\n  originalMethod: (...args: T) => R | Promise<R>,\n  methodPath: GoogleGenAIIstrumentedMethod,\n  context: unknown,\n  options: GoogleGenAIOptions,\n): (...args: T) => R | Promise<R> {\n  const isSyncCreate = methodPath === CHATS_CREATE_METHOD;\n\n  return new Proxy(originalMethod, {\n    apply(target, _, args: T): R | Promise<R> {\n      const params = args[0] as Record<string, unknown> | undefined;\n      const requestAttributes = extractRequestAttributes(methodPath, params, context);\n      const model = requestAttributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] ?? 'unknown';\n      const operationName = getFinalOperationName(methodPath);\n\n      // Check if this is a streaming method\n      if (isStreamingMethod(methodPath)) {\n        // Use startSpanManual for streaming methods to control span lifecycle\n        return startSpanManual(\n          {\n            name: `${operationName} ${model} stream-response`,\n            op: getSpanOperation(methodPath),\n            attributes: requestAttributes,\n          },\n          async (span: Span) => {\n            try {\n              if (options.recordInputs && params) {\n                addPrivateRequestAttributes(span, params);\n              }\n              const stream = await target.apply(context, args);\n              return instrumentStream(stream, span, Boolean(options.recordOutputs)) as R;\n            } catch (error) {\n              span.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n              captureException(error, {\n                mechanism: {\n                  handled: false,\n                  type: 'auto.ai.google_genai',\n                  data: { function: methodPath },\n                },\n              });\n              span.end();\n              throw error;\n            }\n          },\n        );\n      }\n      // Single span for both sync and async operations\n      return startSpan(\n        {\n          name: isSyncCreate ? `${operationName} ${model} create` : `${operationName} ${model}`,\n          op: getSpanOperation(methodPath),\n          attributes: requestAttributes,\n        },\n        (span: Span) => {\n          if (options.recordInputs && params) {\n            addPrivateRequestAttributes(span, params);\n          }\n\n          return handleCallbackErrors(\n            () => target.apply(context, args),\n            error => {\n              captureException(error, {\n                mechanism: { handled: false, type: 'auto.ai.google_genai', data: { function: methodPath } },\n              });\n            },\n            () => {},\n            result => {\n              // Only add response attributes for content-producing methods, not for chats.create\n              if (!isSyncCreate) {\n                addResponseAttributes(span, result, options.recordOutputs);\n              }\n            },\n          );\n        },\n      );\n    },\n  }) as (...args: T) => R | Promise<R>;\n}\n\n/**\n * Create a deep proxy for Google GenAI client instrumentation\n * Recursively instruments methods and handles special cases like chats.create\n */\nfunction createDeepProxy<T extends object>(target: T, currentPath = '', options: GoogleGenAIOptions): T {\n  return new Proxy(target, {\n    get: (t, prop, receiver) => {\n      const value = Reflect.get(t, prop, receiver);\n      const methodPath = buildMethodPath(currentPath, String(prop));\n\n      if (typeof value === 'function' && shouldInstrument(methodPath)) {\n        // Special case: chats.create is synchronous but needs both instrumentation AND result proxying\n        if (methodPath === CHATS_CREATE_METHOD) {\n          const instrumentedMethod = instrumentMethod(value as (...args: unknown[]) => unknown, methodPath, t, options);\n          return function instrumentedAndProxiedCreate(...args: unknown[]): unknown {\n            const result = instrumentedMethod(...args);\n            // If the result is an object (like a chat instance), proxy it too\n            if (result && typeof result === 'object') {\n              return createDeepProxy(result, CHAT_PATH, options);\n            }\n            return result;\n          };\n        }\n\n        return instrumentMethod(value as (...args: unknown[]) => Promise<unknown>, methodPath, t, options);\n      }\n\n      if (typeof value === 'function') {\n        // Bind non-instrumented functions to preserve the original `this` context\n        return value.bind(t);\n      }\n\n      if (value && typeof value === 'object') {\n        return createDeepProxy(value, methodPath, options);\n      }\n\n      return value;\n    },\n  });\n}\n\n/**\n * Instrument a Google GenAI client with Sentry tracing\n * Can be used across Node.js, Cloudflare Workers, and Vercel Edge\n *\n * @template T - The type of the client that extends client object\n * @param client - The Google GenAI client to instrument\n * @param options - Optional configuration for recording inputs and outputs\n * @returns The instrumented client with the same type as the input\n *\n * @example\n * ```typescript\n * import { GoogleGenAI } from '@google/genai';\n * import { instrumentGoogleGenAIClient } from '@sentry/core';\n *\n * const genAI = new GoogleGenAI({ apiKey: process.env.GOOGLE_GENAI_API_KEY });\n * const instrumentedClient = instrumentGoogleGenAIClient(genAI);\n *\n * // Now both chats.create and sendMessage will be instrumented\n * const chat = instrumentedClient.chats.create({ model: 'gemini-1.5-pro' });\n * const response = await chat.sendMessage({ message: 'Hello' });\n * ```\n */\nexport function instrumentGoogleGenAIClient<T extends object>(client: T, options?: GoogleGenAIOptions): T {\n  const sendDefaultPii = Boolean(getClient()?.getOptions().sendDefaultPii);\n\n  const _options = {\n    recordInputs: sendDefaultPii,\n    recordOutputs: sendDefaultPii,\n    ...options,\n  };\n  return createDeepProxy(client, '', _options);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAqCA;;;CAGA,GACO,SAAS,YAAY,CAAC,MAAM,EAA2B,OAAO,EAAoB;IACvF,IAAI,OAAA,IAAW,MAAA,IAAU,OAAO,MAAM,CAAC,KAAA,KAAU,QAAQ,EAAE;QACzD,OAAO,MAAM,CAAC,KAAK;IACrB;IAEF,+EAAA;IACE,IAAI,OAAA,IAAW,OAAO,OAAA,KAAY,QAAQ,EAAE;QAC1C,MAAM,UAAA,GAAa,OAAA;QAEvB,6DAAA;QACI,IAAI,OAAA,IAAW,UAAA,IAAc,OAAO,UAAU,CAAC,KAAA,KAAU,QAAQ,EAAE;YACjE,OAAO,UAAU,CAAC,KAAK;QACzB;QAEJ,qDAAA;QACI,IAAI,cAAA,IAAkB,UAAA,IAAc,OAAO,UAAU,CAAC,YAAA,KAAiB,QAAQ,EAAE;YAC/E,OAAO,UAAU,CAAC,YAAY;QAChC;IACF;IAEA,OAAO,SAAS;AAClB;AAEA;;CAEA,GACA,SAAS,uBAAuB,CAAC,MAAM,EAA+D;IACpG,MAAM,UAAU,GAAuC,CAAA,CAAE;IAEzD,IAAI,aAAA,IAAiB,MAAA,IAAU,OAAO,MAAM,CAAC,WAAA,KAAgB,QAAQ,EAAE;QACrE,UAAU,CAAC,wSAAoC,CAAA,GAAI,MAAM,CAAC,WAAW;IACvE;IACA,IAAI,MAAA,IAAU,MAAA,IAAU,OAAO,MAAM,CAAC,IAAA,KAAS,QAAQ,EAAE;QACvD,UAAU,CAAC,kSAA8B,CAAA,GAAI,MAAM,CAAC,IAAI;IAC1D;IACA,IAAI,MAAA,IAAU,MAAA,IAAU,OAAO,MAAM,CAAC,IAAA,KAAS,QAAQ,EAAE;QACvD,UAAU,CAAC,kSAA8B,CAAA,GAAI,MAAM,CAAC,IAAI;IAC1D;IACA,IAAI,iBAAA,IAAqB,MAAA,IAAU,OAAO,MAAM,CAAC,eAAA,KAAoB,QAAQ,EAAE;QAC7E,UAAU,CAAC,uSAAmC,CAAA,GAAI,MAAM,CAAC,eAAe;IAC1E;IACA,IAAI,kBAAA,IAAsB,MAAA,IAAU,OAAO,MAAM,CAAC,gBAAA,KAAqB,QAAQ,EAAE;QAC/E,UAAU,CAAC,8SAA0C,CAAA,GAAI,MAAM,CAAC,gBAAgB;IAClF;IACA,IAAI,iBAAA,IAAqB,MAAA,IAAU,OAAO,MAAM,CAAC,eAAA,KAAoB,QAAQ,EAAE;QAC7E,UAAU,CAAC,6SAAyC,CAAA,GAAI,MAAM,CAAC,eAAe;IAChF;IAEA,OAAO,UAAU;AACnB;AAEA;;;CAGA,GACA,SAAS,wBAAwB,CAC/B,UAAU,EACV,MAAM,EACN,OAAO;IAEP,MAAM,UAAU,GAAuC;QACrD,CAAC,2RAAuB,CAAA,EAAG,2RAAwB;QACnD,CAAC,mSAA+B,CAAA,MAAG,uQAAqB,EAAC,UAAU,CAAC;QACpE,CAAC,8QAAgC,CAAA,EAAG,sBAAsB;IAC9D,CAAG;IAED,IAAI,MAAM,EAAE;QACV,UAAU,CAAC,kSAA8B,CAAA,GAAI,YAAY,CAAC,MAAM,EAAE,OAAO,CAAC;QAE9E,uCAAA;QACI,IAAI,QAAA,IAAY,MAAA,IAAU,OAAO,MAAM,CAAC,MAAA,KAAW,QAAA,IAAY,MAAM,CAAC,MAAM,EAAE;YAC5E,MAAM,MAAA,GAAS,MAAM,CAAC,MAAA;YACtB,MAAM,CAAC,MAAM,CAAC,UAAU,EAAE,uBAAuB,CAAC,MAAM,CAAC,CAAC;YAEhE,sCAAA;YACM,IAAI,OAAA,IAAW,UAAU,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE;gBACpD,MAAM,oBAAA,GAAuB,MAAM,CAAC,KAAK,CAAC,OAAO,CAC/C,CAAC,IAAI,GAA0C,IAAI,CAAC,oBAAoB;gBAE1E,UAAU,CAAC,4SAAwC,CAAA,GAAI,IAAI,CAAC,SAAS,CAAC,oBAAoB,CAAC;YAC7F;QACF;IACF,OAAO;QACL,UAAU,CAAC,kSAA8B,CAAA,GAAI,YAAY,CAAC,CAAA,CAAE,EAAE,OAAO,CAAC;IACxE;IAEA,OAAO,UAAU;AACnB;AAEA;;;;CAIA,GACA,SAAS,2BAA2B,CAAC,IAAI,EAAQ,MAAM,EAAiC;IACxF,8FAAA;IACE,IAAI,UAAA,IAAc,MAAM,EAAE;QACxB,MAAM,QAAA,GAAW,MAAM,CAAC,QAAQ;QACpC,8FAAA;QACI,MAAM,iBAAA,OAAoB,wQAAsB,EAAC,QAAQ,CAAC;QAC1D,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,qSAAiC,CAAA,EAAG,iBAAA;QAAA,CAAmB,CAAC;IAChF;IAEF,wDAAA;IACE,IAAI,SAAA,IAAa,MAAM,EAAE;QACvB,MAAM,OAAA,GAAU,MAAM,CAAC,OAAO;QAC9B,MAAM,gBAAA,OAAmB,wQAAsB,EAAC,OAAO,CAAC;QACxD,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,qSAAiC,CAAA,EAAG,gBAAA;QAAA,CAAkB,CAAC;IAC/E;IAEF,8DAAA;IACE,IAAI,SAAA,IAAa,MAAM,EAAE;QACvB,MAAM,OAAA,GAAU,MAAM,CAAC,OAAO;QAC9B,MAAM,gBAAA,OAAmB,wQAAsB,EAAC,OAAO,CAAC;QACxD,IAAI,CAAC,aAAa,CAAC;YAAE,CAAC,qSAAiC,CAAA,EAAG,gBAAA;QAAA,CAAkB,CAAC;IAC/E;AACF;AAEA;;;CAGA,GACA,SAAS,qBAAqB,CAAC,IAAI,EAAQ,QAAQ,EAAuB,aAAa,EAAkB;IACvG,IAAI,CAAC,QAAA,IAAY,OAAO,QAAA,KAAa,QAAQ,EAAE;IAEjD,gCAAA;IACE,IAAI,QAAQ,CAAC,aAAA,IAAiB,OAAO,QAAQ,CAAC,aAAA,KAAkB,QAAQ,EAAE;QACxE,MAAM,KAAA,GAAQ,QAAQ,CAAC,aAAa;QACpC,IAAI,OAAO,KAAK,CAAC,gBAAA,KAAqB,QAAQ,EAAE;YAC9C,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,uSAAmC,CAAA,EAAG,KAAK,CAAC,gBAAgB;YACrE,CAAO,CAAC;QACJ;QACA,IAAI,OAAO,KAAK,CAAC,oBAAA,KAAyB,QAAQ,EAAE;YAClD,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,wSAAoC,CAAA,EAAG,KAAK,CAAC,oBAAoB;YAC1E,CAAO,CAAC;QACJ;QACA,IAAI,OAAO,KAAK,CAAC,eAAA,KAAoB,QAAQ,EAAE;YAC7C,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,uSAAmC,CAAA,EAAG,KAAK,CAAC,eAAe;YACpE,CAAO,CAAC;QACJ;IACF;IAEF,gDAAA;IACE,IAAI,aAAA,IAAiB,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,UAAU,CAAA,IAAK,QAAQ,CAAC,UAAU,CAAC,MAAA,GAAS,CAAC,EAAE;QACzF,MAAM,aAAA,GAAgB,QAAQ,CAAC,UAAA,CAC5B,GAAG,CAAC,CAAC,SAAS,KAAgB;YAC7B,IAAI,SAAS,CAAC,OAAO,EAAE,SAAS,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC,OAAO,CAAC,KAAK,CAAC,EAAE;gBACtE,OAAO,SAAS,CAAC,OAAO,CAAC,KAAA,CACtB,GAAG,CAAC,CAAC,IAAI,GAAmB,OAAO,IAAI,CAAC,IAAA,KAAS,WAAW,IAAI,CAAC,IAAA,GAAO,EAAE,CAAC,CAC3E,MAAM,CAAC,CAAC,IAAI,GAAa,IAAI,CAAC,MAAA,GAAS,CAAC,EACxC,IAAI,CAAC,EAAE,CAAC;YACb;YACA,OAAO,EAAE;QACX,CAAC,EACA,MAAM,CAAC,CAAC,IAAI,GAAa,IAAI,CAAC,MAAA,GAAS,CAAC,CAAC;QAE5C,IAAI,aAAa,CAAC,MAAA,GAAS,CAAC,EAAE;YAC5B,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,kSAA8B,CAAA,EAAG,aAAa,CAAC,IAAI,CAAC,EAAE,CAAC;YAChE,CAAO,CAAC;QACJ;IACF;IAEF,6CAAA;IACE,IAAI,aAAA,IAAiB,QAAQ,CAAC,aAAa,EAAE;QAC3C,MAAM,aAAA,GAAgB,QAAQ,CAAC,aAAa;QAC5C,IAAI,KAAK,CAAC,OAAO,CAAC,aAAa,CAAA,IAAK,aAAa,CAAC,MAAA,GAAS,CAAC,EAAE;YAC5D,IAAI,CAAC,aAAa,CAAC;gBACjB,CAAC,wSAAoC,CAAA,EAAG,IAAI,CAAC,SAAS,CAAC,aAAa,CAAC;YAC7E,CAAO,CAAC;QACJ;IACF;AACF;AAEA;;;;CAIA,GACA,SAAS,gBAAgB,CACvB,cAAc,EACd,UAAU,EACV,OAAO,EACP,OAAO;IAEP,MAAM,YAAA,GAAe,UAAA,KAAe,sRAAmB;IAEvD,OAAO,IAAI,KAAK,CAAC,cAAc,EAAE;QAC/B,KAAK,EAAC,MAAM,EAAE,CAAC,EAAE,IAAI,EAAqB;YACxC,MAAM,MAAA,GAAS,IAAI,CAAC,CAAC,CAAA;YACrB,MAAM,iBAAA,GAAoB,wBAAwB,CAAC,UAAU,EAAE,MAAM,EAAE,OAAO,CAAC;YAC/E,MAAM,QAAQ,iBAAiB,CAAC,kSAA8B,CAAA,IAAK,SAAS;YAC5E,MAAM,aAAA,OAAgB,uQAAqB,EAAC,UAAU,CAAC;YAE7D,sCAAA;YACM,QAAI,gRAAiB,EAAC,UAAU,CAAC,EAAE;gBACzC,sEAAA;gBACQ,WAAO,2PAAe,EACpB;oBACE,IAAI,EAAE,CAAC,EAAA,aAAA,CAAA,CAAA,EAAA,KAAA,CAAA,gBAAA,CAAA;oBACA,EAAA,MAAA,kQAAA,EAAA,UAAA,CAAA;oBACA,UAAA,EAAA,iBAAA;gBACA,CAAA,EACA,OAAA,IAAA,KAAA;oBACA,IAAA;wBACA,IAAA,OAAA,CAAA,YAAA,IAAA,MAAA,EAAA;4BACA,2BAAA,CAAA,IAAA,EAAA,MAAA,CAAA;wBACA;wBACA,MAAA,MAAA,GAAA,MAAA,MAAA,CAAA,KAAA,CAAA,OAAA,EAAA,IAAA,CAAA;wBACA,WAAA,mRAAA,EAAA,MAAA,EAAA,IAAA,EAAA,OAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;oBACA,CAAA,CAAA,OAAA,KAAA,EAAA;wBACA,IAAA,CAAA,SAAA,CAAA;4BAAA,IAAA,EAAA,kQAAA;4BAAA,OAAA,EAAA,gBAAA;wBAAA,CAAA,CAAA;4BACA,mPAAA,EAAA,KAAA,EAAA;4BACA,SAAA,EAAA;gCACA,OAAA,EAAA,KAAA;gCACA,IAAA,EAAA,sBAAA;gCACA,IAAA,EAAA;oCAAA,QAAA,EAAA,UAAA;gCAAA,CAAA;4BACA,CAAA;wBACA,CAAA,CAAA;wBACA,IAAA,CAAA,GAAA,EAAA;wBACA,MAAA,KAAA;oBACA;gBACA,CAAA;YAEA;YACA,iDAAA;YACA,WAAA,qPAAA,EACA;gBACA,IAAA,EAAA,YAAA,GAAA,CAAA,EAAA,aAAA,CAAA,CAAA,EAAA,KAAA,CAAA,OAAA,CAAA,GAAA,CAAA,EAAA,aAAA,CAAA,CAAA,EAAA,KAAA,CAAA,CAAA;gBACA,EAAA,MAAA,kQAAA,EAAA,UAAA,CAAA;gBACA,UAAA,EAAA,iBAAA;YACA,CAAA,EACA,CAAA,IAAA,KAAA;gBACA,IAAA,OAAA,CAAA,YAAA,IAAA,MAAA,EAAA;oBACA,2BAAA,CAAA,IAAA,EAAA,MAAA,CAAA;gBACA;gBAEA,WAAA,6QAAA,EACA,IAAA,MAAA,CAAA,KAAA,CAAA,OAAA,EAAA,IAAA,CAAA,GACA,KAAA,IAAA;wBACA,mPAAA,EAAA,KAAA,EAAA;wBACA,SAAA,EAAA;4BAAA,OAAA,EAAA,KAAA;4BAAA,IAAA,EAAA,sBAAA;4BAAA,IAAA,EAAA;gCAAA,QAAA,EAAA,UAAA;4BAAA,CAAA;wBAAA,CAAA;oBACA,CAAA,CAAA;gBACA,CAAA,EACA,KAAA,CAAA,GACA,MAAA,IAAA;oBACA,mFAAA;oBACA,IAAA,CAAA,YAAA,EAAA;wBACA,qBAAA,CAAA,IAAA,EAAA,MAAA,EAAA,OAAA,CAAA,aAAA,CAAA;oBACA;gBACA,CAAA;YAEA,CAAA;QAEA,CAAA;IACA,CAAA,CAAA;AACA;AAEA;;;CAGA,GACA,SAAA,eAAA,CAAA,MAAA,EAAA,WAAA,GAAA,EAAA,EAAA,OAAA,EAAA;IACA,OAAA,IAAA,KAAA,CAAA,MAAA,EAAA;QACA,GAAA,EAAA,CAAA,CAAA,EAAA,IAAA,EAAA,QAAA,KAAA;YACA,MAAA,KAAA,GAAA,OAAA,CAAA,GAAA,CAAA,CAAA,EAAA,IAAA,EAAA,QAAA,CAAA;YACA,MAAA,UAAA,OAAA,iQAAA,EAAA,WAAA,EAAA,MAAA,CAAA,IAAA,CAAA,CAAA;YAEA,IAAA,OAAA,KAAA,KAAA,UAAA,QAAA,+QAAA,EAAA,UAAA,CAAA,EAAA;gBACA,+FAAA;gBACA,IAAA,UAAA,KAAA,sRAAA,EAAA;oBACA,MAAA,kBAAA,GAAA,gBAAA,CAAA,KAAA,EAAA,UAAA,EAAA,CAAA,EAAA,OAAA,CAAA;oBACA,OAAA,SAAA,4BAAA,CAAA,GAAA,IAAA,EAAA;wBACA,MAAA,MAAA,GAAA,kBAAA,CAAA,GAAA,IAAA,CAAA;wBACA,kEAAA;wBACA,IAAA,MAAA,IAAA,OAAA,MAAA,KAAA,QAAA,EAAA;4BACA,OAAA,eAAA,CAAA,MAAA,EAAA,4QAAA,EAAA,OAAA,CAAA;wBACA;wBACA,OAAA,MAAA;oBACA,CAAA;gBACA;gBAEA,OAAA,gBAAA,CAAA,KAAA,EAAA,UAAA,EAAA,CAAA,EAAA,OAAA,CAAA;YACA;YAEA,IAAA,OAAA,KAAA,KAAA,UAAA,EAAA;gBACA,0EAAA;gBACA,OAAA,KAAA,CAAA,IAAA,CAAA,CAAA,CAAA;YACA;YAEA,IAAA,KAAA,IAAA,OAAA,KAAA,KAAA,QAAA,EAAA;gBACA,OAAA,eAAA,CAAA,KAAA,EAAA,UAAA,EAAA,OAAA,CAAA;YACA;YAEA,OAAA,KAAA;QACA,CAAA;IACA,CAAA,CAAA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;CAqBA,GACA,SAAA,2BAAA,CAAA,MAAA,EAAA,OAAA,EAAA;IACA,MAAA,cAAA,GAAA,OAAA,KAAA,kPAAA,EAAA,GAAA,UAAA,EAAA,CAAA,cAAA,CAAA;IAEA,MAAA,QAAA,GAAA;QACA,YAAA,EAAA,cAAA;QACA,aAAA,EAAA,cAAA;QACA,GAAA,OAAA;IACA,CAAA;IACA,OAAA,eAAA,CAAA,MAAA,EAAA,EAAA,EAAA,QAAA,CAAA;AACA"}},
    {"offset": {"line": 4363, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/langchain/constants.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/langchain/constants.ts"],"sourcesContent":["export const LANGCHAIN_INTEGRATION_NAME = 'LangChain';\nexport const LANGCHAIN_ORIGIN = 'auto.ai.langchain';\n\nexport const ROLE_MAP: Record<string, string> = {\n  human: 'user',\n  ai: 'assistant',\n  assistant: 'assistant',\n  system: 'system',\n  function: 'function',\n  tool: 'tool',\n};\n"],"names":[],"mappings":";;;;;;;;AAAO,MAAM,0BAAA,GAA6B;AACnC,MAAM,gBAAA,GAAmB;AAEzB,MAAM,QAAQ,GAA2B;IAC9C,KAAK,EAAE,MAAM;IACb,EAAE,EAAE,WAAW;IACf,SAAS,EAAE,WAAW;IACtB,MAAM,EAAE,QAAQ;IAChB,QAAQ,EAAE,UAAU;IACpB,IAAI,EAAE,MAAM;AACd"}},
    {"offset": {"line": 4387, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/langchain/utils.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/langchain/utils.ts"],"sourcesContent":["import { SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN } from '../../semanticAttributes';\nimport type { SpanAttributeValue } from '../../types-hoist/span';\nimport {\n  GEN_AI_OPERATION_NAME_ATTRIBUTE,\n  GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE,\n  GEN_AI_REQUEST_MESSAGES_ATTRIBUTE,\n  GEN_AI_REQUEST_MODEL_ATTRIBUTE,\n  GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_STREAM_ATTRIBUTE,\n  GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_P_ATTRIBUTE,\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_STOP_REASON_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  GEN_AI_SYSTEM_ATTRIBUTE,\n  GEN_AI_USAGE_CACHE_CREATION_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_CACHE_READ_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { truncateGenAiMessages } from '../ai/messageTruncation';\nimport { LANGCHAIN_ORIGIN, ROLE_MAP } from './constants';\nimport type { LangChainLLMResult, LangChainMessage, LangChainSerialized } from './types';\n\n/**\n * Assigns an attribute only when the value is neither `undefined` nor `null`.\n *\n * We keep this tiny helper because call sites are repetitive and easy to miswrite.\n * It also preserves falsy-but-valid values like `0` and `\"\"`.\n */\nconst setIfDefined = (target: Record<string, SpanAttributeValue>, key: string, value: unknown): void => {\n  if (value != null) target[key] = value as SpanAttributeValue;\n};\n\n/**\n * Like `setIfDefined`, but converts the value with `Number()` and skips only when the\n * result is `NaN`. This ensures numeric 0 makes it through (unlike truthy checks).\n */\nconst setNumberIfDefined = (target: Record<string, SpanAttributeValue>, key: string, value: unknown): void => {\n  const n = Number(value);\n  if (!Number.isNaN(n)) target[key] = n;\n};\n\n/**\n * Converts a value to a string. Avoids double-quoted JSON strings where a plain\n * string is desired, but still handles objects/arrays safely.\n */\nfunction asString(v: unknown): string {\n  if (typeof v === 'string') return v;\n  try {\n    return JSON.stringify(v);\n  } catch {\n    return String(v);\n  }\n}\n\n/**\n * Normalizes a single role token to our canonical set.\n *\n * @param role Incoming role value (free-form, any casing)\n * @returns Canonical role: 'user' | 'assistant' | 'system' | 'function' | 'tool' | <passthrough>\n */\nfunction normalizeMessageRole(role: string): string {\n  const normalized = role.toLowerCase();\n  return ROLE_MAP[normalized] ?? normalized;\n}\n\n/**\n * Infers a role from a LangChain message constructor name.\n *\n * Checks for substrings like \"System\", \"Human\", \"AI\", etc.\n */\nfunction normalizeRoleNameFromCtor(name: string): string {\n  if (name.includes('System')) return 'system';\n  if (name.includes('Human')) return 'user';\n  if (name.includes('AI') || name.includes('Assistant')) return 'assistant';\n  if (name.includes('Function')) return 'function';\n  if (name.includes('Tool')) return 'tool';\n  return 'user';\n}\n\n/**\n * Returns invocation params from a LangChain `tags` object.\n *\n * LangChain often passes runtime parameters (model, temperature, etc.) via the\n * `tags.invocation_params` bag. If `tags` is an array (LangChain sometimes uses\n * string tags), we return `undefined`.\n *\n * @param tags LangChain tags (string[] or record)\n * @returns The `invocation_params` object, if present\n */\nexport function getInvocationParams(tags?: string[] | Record<string, unknown>): Record<string, unknown> | undefined {\n  if (!tags || Array.isArray(tags)) return undefined;\n  return tags.invocation_params as Record<string, unknown> | undefined;\n}\n\n/**\n * Normalizes a heterogeneous set of LangChain messages to `{ role, content }`.\n *\n * Why so many branches? LangChain messages can arrive in several shapes:\n *  - Message classes with `_getType()` (most reliable)\n *  - Classes with meaningful constructor names (e.g. `SystemMessage`)\n *  - Plain objects with `type`, or `{ role, content }`\n *  - Serialized format with `{ lc: 1, id: [...], kwargs: { content } }`\n * We preserve the prioritization to minimize behavioral drift.\n *\n * @param messages Mixed LangChain messages\n * @returns Array of normalized `{ role, content }`\n */\nexport function normalizeLangChainMessages(messages: LangChainMessage[]): Array<{ role: string; content: string }> {\n  return messages.map(message => {\n    // 1) Prefer _getType() when present\n    const maybeGetType = (message as { _getType?: () => string })._getType;\n    if (typeof maybeGetType === 'function') {\n      const messageType = maybeGetType.call(message);\n      return {\n        role: normalizeMessageRole(messageType),\n        content: asString(message.content),\n      };\n    }\n\n    // 2) Then try constructor name (SystemMessage / HumanMessage / ...)\n    const ctor = (message as { constructor?: { name?: string } }).constructor?.name;\n    if (ctor) {\n      return {\n        role: normalizeMessageRole(normalizeRoleNameFromCtor(ctor)),\n        content: asString(message.content),\n      };\n    }\n\n    // 3) Then objects with `type`\n    if (message.type) {\n      const role = String(message.type).toLowerCase();\n      return {\n        role: normalizeMessageRole(role),\n        content: asString(message.content),\n      };\n    }\n\n    // 4) Then objects with `{ role, content }`\n    if (message.role) {\n      return {\n        role: normalizeMessageRole(String(message.role)),\n        content: asString(message.content),\n      };\n    }\n\n    // 5) Serialized LangChain format (lc: 1)\n    if (message.lc === 1 && message.kwargs) {\n      const id = message.id;\n      const messageType = Array.isArray(id) && id.length > 0 ? id[id.length - 1] : '';\n      const role = typeof messageType === 'string' ? normalizeRoleNameFromCtor(messageType) : 'user';\n\n      return {\n        role: normalizeMessageRole(role),\n        content: asString(message.kwargs?.content),\n      };\n    }\n\n    // 6) Fallback: treat as user text\n    return {\n      role: 'user',\n      content: asString(message.content),\n    };\n  });\n}\n\n/**\n * Extracts request attributes common to both LLM and ChatModel invocations.\n *\n * Source precedence:\n * 1) `invocationParams` (highest)\n * 2) `langSmithMetadata`\n *\n * Numeric values are set even when 0 (e.g. `temperature: 0`), but skipped if `NaN`.\n */\nfunction extractCommonRequestAttributes(\n  serialized: LangChainSerialized,\n  invocationParams?: Record<string, unknown>,\n  langSmithMetadata?: Record<string, unknown>,\n): Record<string, SpanAttributeValue> {\n  const attrs: Record<string, SpanAttributeValue> = {};\n\n  // Get kwargs if available (from constructor type)\n  const kwargs = 'kwargs' in serialized ? serialized.kwargs : undefined;\n\n  const temperature = invocationParams?.temperature ?? langSmithMetadata?.ls_temperature ?? kwargs?.temperature;\n  setNumberIfDefined(attrs, GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE, temperature);\n\n  const maxTokens = invocationParams?.max_tokens ?? langSmithMetadata?.ls_max_tokens ?? kwargs?.max_tokens;\n  setNumberIfDefined(attrs, GEN_AI_REQUEST_MAX_TOKENS_ATTRIBUTE, maxTokens);\n\n  const topP = invocationParams?.top_p ?? kwargs?.top_p;\n  setNumberIfDefined(attrs, GEN_AI_REQUEST_TOP_P_ATTRIBUTE, topP);\n\n  const frequencyPenalty = invocationParams?.frequency_penalty;\n  setNumberIfDefined(attrs, GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE, frequencyPenalty);\n\n  const presencePenalty = invocationParams?.presence_penalty;\n  setNumberIfDefined(attrs, GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE, presencePenalty);\n\n  // LangChain uses `stream`. We only set the attribute if the key actually exists\n  // (some callbacks report `false` even on streamed requests, this stems from LangChain's callback handler).\n  if (invocationParams && 'stream' in invocationParams) {\n    setIfDefined(attrs, GEN_AI_REQUEST_STREAM_ATTRIBUTE, Boolean(invocationParams.stream));\n  }\n\n  return attrs;\n}\n\n/**\n * Small helper to assemble boilerplate attributes shared by both request extractors.\n */\nfunction baseRequestAttributes(\n  system: unknown,\n  modelName: unknown,\n  operation: 'pipeline' | 'chat',\n  serialized: LangChainSerialized,\n  invocationParams?: Record<string, unknown>,\n  langSmithMetadata?: Record<string, unknown>,\n): Record<string, SpanAttributeValue> {\n  return {\n    [GEN_AI_SYSTEM_ATTRIBUTE]: asString(system ?? 'langchain'),\n    [GEN_AI_OPERATION_NAME_ATTRIBUTE]: operation,\n    [GEN_AI_REQUEST_MODEL_ATTRIBUTE]: asString(modelName),\n    [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: LANGCHAIN_ORIGIN,\n    ...extractCommonRequestAttributes(serialized, invocationParams, langSmithMetadata),\n  };\n}\n\n/**\n * Extracts attributes for plain LLM invocations (string prompts).\n *\n * - Operation is tagged as `pipeline` to distinguish from chat-style invocations.\n * - When `recordInputs` is true, string prompts are wrapped into `{role:\"user\"}`\n *   messages to align with the chat schema used elsewhere.\n */\nexport function extractLLMRequestAttributes(\n  llm: LangChainSerialized,\n  prompts: string[],\n  recordInputs: boolean,\n  invocationParams?: Record<string, unknown>,\n  langSmithMetadata?: Record<string, unknown>,\n): Record<string, SpanAttributeValue> {\n  const system = langSmithMetadata?.ls_provider;\n  const modelName = invocationParams?.model ?? langSmithMetadata?.ls_model_name ?? 'unknown';\n\n  const attrs = baseRequestAttributes(system, modelName, 'pipeline', llm, invocationParams, langSmithMetadata);\n\n  if (recordInputs && Array.isArray(prompts) && prompts.length > 0) {\n    const messages = prompts.map(p => ({ role: 'user', content: p }));\n    setIfDefined(attrs, GEN_AI_REQUEST_MESSAGES_ATTRIBUTE, asString(messages));\n  }\n\n  return attrs;\n}\n\n/**\n * Extracts attributes for ChatModel invocations (array-of-arrays of messages).\n *\n * - Operation is tagged as `chat`.\n * - We flatten LangChain's `LangChainMessage[][]` and normalize shapes into a\n *   consistent `{ role, content }` array when `recordInputs` is true.\n * - Provider system value falls back to `serialized.id?.[2]`.\n */\nexport function extractChatModelRequestAttributes(\n  llm: LangChainSerialized,\n  langChainMessages: LangChainMessage[][],\n  recordInputs: boolean,\n  invocationParams?: Record<string, unknown>,\n  langSmithMetadata?: Record<string, unknown>,\n): Record<string, SpanAttributeValue> {\n  const system = langSmithMetadata?.ls_provider ?? llm.id?.[2];\n  const modelName = invocationParams?.model ?? langSmithMetadata?.ls_model_name ?? 'unknown';\n\n  const attrs = baseRequestAttributes(system, modelName, 'chat', llm, invocationParams, langSmithMetadata);\n\n  if (recordInputs && Array.isArray(langChainMessages) && langChainMessages.length > 0) {\n    const normalized = normalizeLangChainMessages(langChainMessages.flat());\n    const truncated = truncateGenAiMessages(normalized);\n    setIfDefined(attrs, GEN_AI_REQUEST_MESSAGES_ATTRIBUTE, asString(truncated));\n  }\n\n  return attrs;\n}\n\n/**\n * Scans generations for Anthropic-style `tool_use` items and records them.\n *\n * LangChain represents some provider messages (e.g., Anthropic) with a `message.content`\n * array that may include objects `{ type: 'tool_use', ... }`. We collect and attach\n * them as a JSON array on `gen_ai.response.tool_calls` for downstream consumers.\n */\nfunction addToolCallsAttributes(generations: LangChainMessage[][], attrs: Record<string, SpanAttributeValue>): void {\n  const toolCalls: unknown[] = [];\n  const flatGenerations = generations.flat();\n\n  for (const gen of flatGenerations) {\n    const content = gen.message?.content;\n    if (Array.isArray(content)) {\n      for (const item of content) {\n        const t = item as { type: string };\n        if (t.type === 'tool_use') toolCalls.push(t);\n      }\n    }\n  }\n\n  if (toolCalls.length > 0) {\n    setIfDefined(attrs, GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE, asString(toolCalls));\n  }\n}\n\n/**\n * Adds token usage attributes, supporting both OpenAI (`tokenUsage`) and Anthropic (`usage`) formats.\n * - Preserve zero values (0 tokens) by avoiding truthy checks.\n * - Compute a total for Anthropic when not explicitly provided.\n * - Include cache token metrics when present.\n */\nfunction addTokenUsageAttributes(\n  llmOutput: LangChainLLMResult['llmOutput'],\n  attrs: Record<string, SpanAttributeValue>,\n): void {\n  if (!llmOutput) return;\n\n  const tokenUsage = llmOutput.tokenUsage as\n    | { promptTokens?: number; completionTokens?: number; totalTokens?: number }\n    | undefined;\n  const anthropicUsage = llmOutput.usage as\n    | {\n        input_tokens?: number;\n        output_tokens?: number;\n        cache_creation_input_tokens?: number;\n        cache_read_input_tokens?: number;\n      }\n    | undefined;\n\n  if (tokenUsage) {\n    setNumberIfDefined(attrs, GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE, tokenUsage.promptTokens);\n    setNumberIfDefined(attrs, GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE, tokenUsage.completionTokens);\n    setNumberIfDefined(attrs, GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE, tokenUsage.totalTokens);\n  } else if (anthropicUsage) {\n    setNumberIfDefined(attrs, GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE, anthropicUsage.input_tokens);\n    setNumberIfDefined(attrs, GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE, anthropicUsage.output_tokens);\n\n    // Compute total when not provided by the provider.\n    const input = Number(anthropicUsage.input_tokens);\n    const output = Number(anthropicUsage.output_tokens);\n    const total = (Number.isNaN(input) ? 0 : input) + (Number.isNaN(output) ? 0 : output);\n    if (total > 0) setNumberIfDefined(attrs, GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE, total);\n\n    // Extra Anthropic cache metrics (present only when caching is enabled)\n    if (anthropicUsage.cache_creation_input_tokens !== undefined)\n      setNumberIfDefined(\n        attrs,\n        GEN_AI_USAGE_CACHE_CREATION_INPUT_TOKENS_ATTRIBUTE,\n        anthropicUsage.cache_creation_input_tokens,\n      );\n    if (anthropicUsage.cache_read_input_tokens !== undefined)\n      setNumberIfDefined(attrs, GEN_AI_USAGE_CACHE_READ_INPUT_TOKENS_ATTRIBUTE, anthropicUsage.cache_read_input_tokens);\n  }\n}\n\n/**\n * Extracts response-related attributes based on a `LangChainLLMResult`.\n *\n * - Records finish reasons when present on generations (e.g., OpenAI)\n * - When `recordOutputs` is true, captures textual response content and any\n *   tool calls.\n * - Also propagates model name (`model_name` or `model`), response `id`, and\n *   `stop_reason` (for providers that use it).\n */\nexport function extractLlmResponseAttributes(\n  llmResult: LangChainLLMResult,\n  recordOutputs: boolean,\n): Record<string, SpanAttributeValue> | undefined {\n  if (!llmResult) return;\n\n  const attrs: Record<string, SpanAttributeValue> = {};\n\n  if (Array.isArray(llmResult.generations)) {\n    const finishReasons = llmResult.generations\n      .flat()\n      .map(g => g.generation_info?.finish_reason)\n      .filter((r): r is string => typeof r === 'string');\n\n    if (finishReasons.length > 0) {\n      setIfDefined(attrs, GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE, asString(finishReasons));\n    }\n\n    // Tool calls metadata (names, IDs) are not PII, so capture them regardless of recordOutputs\n    addToolCallsAttributes(llmResult.generations as LangChainMessage[][], attrs);\n\n    if (recordOutputs) {\n      const texts = llmResult.generations\n        .flat()\n        .map(gen => gen.text ?? gen.message?.content)\n        .filter(t => typeof t === 'string');\n\n      if (texts.length > 0) {\n        setIfDefined(attrs, GEN_AI_RESPONSE_TEXT_ATTRIBUTE, asString(texts));\n      }\n    }\n  }\n\n  addTokenUsageAttributes(llmResult.llmOutput, attrs);\n\n  const llmOutput = llmResult.llmOutput as { model_name?: string; model?: string; id?: string; stop_reason?: string };\n  // Provider model identifier: `model_name` (OpenAI-style) or `model` (others)\n  const modelName = llmOutput?.model_name ?? llmOutput?.model;\n  if (modelName) setIfDefined(attrs, GEN_AI_RESPONSE_MODEL_ATTRIBUTE, modelName);\n\n  if (llmOutput?.id) {\n    setIfDefined(attrs, GEN_AI_RESPONSE_ID_ATTRIBUTE, llmOutput.id);\n  }\n\n  if (llmOutput?.stop_reason) {\n    setIfDefined(attrs, GEN_AI_RESPONSE_STOP_REASON_ATTRIBUTE, asString(llmOutput.stop_reason));\n  }\n\n  return attrs;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;AA6BA;;;;;CAKA,GACA,MAAM,YAAA,GAAe,CAAC,MAAM,EAAsC,GAAG,EAAU,KAAK,KAAoB;IACtG,IAAI,KAAA,IAAS,IAAI,EAAE,MAAM,CAAC,GAAG,CAAA,GAAI,KAAA;AACnC,CAAC;AAED;;;CAGA,GACA,MAAM,kBAAA,GAAqB,CAAC,MAAM,EAAsC,GAAG,EAAU,KAAK,KAAoB;IAC5G,MAAM,CAAA,GAAI,MAAM,CAAC,KAAK,CAAC;IACvB,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,GAAG,CAAA,GAAI,CAAC;AACvC,CAAC;AAED;;;CAGA,GACA,SAAS,QAAQ,CAAC,CAAC,EAAmB;IACpC,IAAI,OAAO,CAAA,KAAM,QAAQ,EAAE,OAAO,CAAC;IACnC,IAAI;QACF,OAAO,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC;IAC1B,EAAE,OAAM;QACN,OAAO,MAAM,CAAC,CAAC,CAAC;IAClB;AACF;AAEA;;;;;CAKA,GACA,SAAS,oBAAoB,CAAC,IAAI,EAAkB;IAClD,MAAM,UAAA,GAAa,IAAI,CAAC,WAAW,EAAE;IACrC,OAAO,qQAAQ,CAAC,UAAU,CAAA,IAAK,UAAU;AAC3C;AAEA;;;;CAIA,GACA,SAAS,yBAAyB,CAAC,IAAI,EAAkB;IACvD,IAAI,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAC,EAAE,OAAO,QAAQ;IAC5C,IAAI,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,EAAE,OAAO,MAAM;IACzC,IAAI,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAA,IAAK,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,EAAE,OAAO,WAAW;IACzE,IAAI,IAAI,CAAC,QAAQ,CAAC,UAAU,CAAC,EAAE,OAAO,UAAU;IAChD,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,EAAE,OAAO,MAAM;IACxC,OAAO,MAAM;AACf;AAEA;;;;;;;;;CASA,GACO,SAAS,mBAAmB,CAAC,IAAI,EAA4E;IAClH,IAAI,CAAC,IAAA,IAAQ,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE,OAAO,SAAS;IAClD,OAAO,IAAI,CAAC,iBAAA;AACd;AAEA;;;;;;;;;;;;CAYA,GACO,SAAS,0BAA0B,CAAC,QAAQ,EAAgE;IACjH,OAAO,QAAQ,CAAC,GAAG,EAAC,WAAW;QACjC,oCAAA;QACI,MAAM,YAAA,GAAe,AAAC,OAAA,CAAwC,QAAQ;QACtE,IAAI,OAAO,YAAA,KAAiB,UAAU,EAAE;YACtC,MAAM,cAAc,YAAY,CAAC,IAAI,CAAC,OAAO,CAAC;YAC9C,OAAO;gBACL,IAAI,EAAE,oBAAoB,CAAC,WAAW,CAAC;gBACvC,OAAO,EAAE,QAAQ,CAAC,OAAO,CAAC,OAAO,CAAC;YAC1C,CAAO;QACH;QAEJ,oEAAA;QACI,MAAM,OAAO,AAAC,QAAgD,WAAW,EAAE,IAAI;QAC/E,IAAI,IAAI,EAAE;YACR,OAAO;gBACL,IAAI,EAAE,oBAAoB,CAAC,yBAAyB,CAAC,IAAI,CAAC,CAAC;gBAC3D,OAAO,EAAE,QAAQ,CAAC,OAAO,CAAC,OAAO,CAAC;YAC1C,CAAO;QACH;QAEJ,8BAAA;QACI,IAAI,OAAO,CAAC,IAAI,EAAE;YAChB,MAAM,IAAA,GAAO,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,WAAW,EAAE;YAC/C,OAAO;gBACL,IAAI,EAAE,oBAAoB,CAAC,IAAI,CAAC;gBAChC,OAAO,EAAE,QAAQ,CAAC,OAAO,CAAC,OAAO,CAAC;YAC1C,CAAO;QACH;QAEJ,2CAAA;QACI,IAAI,OAAO,CAAC,IAAI,EAAE;YAChB,OAAO;gBACL,IAAI,EAAE,oBAAoB,CAAC,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;gBAChD,OAAO,EAAE,QAAQ,CAAC,OAAO,CAAC,OAAO,CAAC;YAC1C,CAAO;QACH;QAEJ,yCAAA;QACI,IAAI,OAAO,CAAC,EAAA,KAAO,CAAA,IAAK,OAAO,CAAC,MAAM,EAAE;YACtC,MAAM,EAAA,GAAK,OAAO,CAAC,EAAE;YACrB,MAAM,WAAA,GAAc,KAAK,CAAC,OAAO,CAAC,EAAE,CAAA,IAAK,EAAE,CAAC,MAAA,GAAS,CAAA,GAAI,EAAE,CAAC,EAAE,CAAC,MAAA,GAAS,CAAC,CAAA,GAAI,EAAE;YAC/E,MAAM,IAAA,GAAO,OAAO,WAAA,KAAgB,QAAA,GAAW,yBAAyB,CAAC,WAAW,CAAA,GAAI,MAAM;YAE9F,OAAO;gBACL,IAAI,EAAE,oBAAoB,CAAC,IAAI,CAAC;gBAChC,OAAO,EAAE,QAAQ,CAAC,OAAO,CAAC,MAAM,EAAE,OAAO,CAAC;YAClD,CAAO;QACH;QAEJ,kCAAA;QACI,OAAO;YACL,IAAI,EAAE,MAAM;YACZ,OAAO,EAAE,QAAQ,CAAC,OAAO,CAAC,OAAO,CAAC;QACxC,CAAK;IACH,CAAC,CAAC;AACJ;AAEA;;;;;;;;CAQA,GACA,SAAS,8BAA8B,CACrC,UAAU,EACV,gBAAgB,EAChB,iBAAiB;IAEjB,MAAM,KAAK,GAAuC,CAAA,CAAE;IAEtD,kDAAA;IACE,MAAM,MAAA,GAAS,QAAA,IAAY,UAAA,GAAa,UAAU,CAAC,MAAA,GAAS,SAAS;IAErE,MAAM,WAAA,GAAc,gBAAgB,EAAE,WAAA,IAAe,iBAAiB,EAAE,cAAA,IAAkB,MAAM,EAAE,WAAW;IAC7G,kBAAkB,CAAC,KAAK,EAAE,wSAAoC,EAAE,WAAW,CAAC;IAE5E,MAAM,SAAA,GAAY,gBAAgB,EAAE,UAAA,IAAc,iBAAiB,EAAE,aAAA,IAAiB,MAAM,EAAE,UAAU;IACxG,kBAAkB,CAAC,KAAK,EAAE,uSAAmC,EAAE,SAAS,CAAC;IAEzE,MAAM,OAAO,gBAAgB,EAAE,KAAA,IAAS,MAAM,EAAE,KAAK;IACrD,kBAAkB,CAAC,KAAK,EAAE,kSAA8B,EAAE,IAAI,CAAC;IAE/D,MAAM,gBAAA,GAAmB,gBAAgB,EAAE,iBAAiB;IAC5D,kBAAkB,CAAC,KAAK,EAAE,8SAA0C,EAAE,gBAAgB,CAAC;IAEvF,MAAM,eAAA,GAAkB,gBAAgB,EAAE,gBAAgB;IAC1D,kBAAkB,CAAC,KAAK,EAAE,6SAAyC,EAAE,eAAe,CAAC;IAEvF,gFAAA;IACA,2GAAA;IACE,IAAI,gBAAA,IAAoB,QAAA,IAAY,gBAAgB,EAAE;QACpD,YAAY,CAAC,KAAK,EAAE,mSAA+B,EAAE,OAAO,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC;IACxF;IAEA,OAAO,KAAK;AACd;AAEA;;CAEA,GACA,SAAS,qBAAqB,CAC5B,MAAM,EACN,SAAS,EACT,SAAS,EACT,UAAU,EACV,gBAAgB,EAChB,iBAAiB;IAEjB,OAAO;QACL,CAAC,2RAAuB,CAAA,EAAG,QAAQ,CAAC,MAAA,IAAU,WAAW,CAAC;QAC1D,CAAC,mSAA+B,CAAA,EAAG,SAAS;QAC5C,CAAC,kSAA8B,CAAA,EAAG,QAAQ,CAAC,SAAS,CAAC;QACrD,CAAC,8QAAgC,CAAA,EAAG,6QAAgB;QACpD,GAAG,8BAA8B,CAAC,UAAU,EAAE,gBAAgB,EAAE,iBAAiB,CAAC;IACtF,CAAG;AACH;AAEA;;;;;;CAMA,GACO,SAAS,2BAA2B,CACzC,GAAG,EACH,OAAO,EACP,YAAY,EACZ,gBAAgB,EAChB,iBAAiB;IAEjB,MAAM,MAAA,GAAS,iBAAiB,EAAE,WAAW;IAC7C,MAAM,SAAA,GAAY,gBAAgB,EAAE,KAAA,IAAS,iBAAiB,EAAE,aAAA,IAAiB,SAAS;IAE1F,MAAM,KAAA,GAAQ,qBAAqB,CAAC,MAAM,EAAE,SAAS,EAAE,UAAU,EAAE,GAAG,EAAE,gBAAgB,EAAE,iBAAiB,CAAC;IAE5G,IAAI,YAAA,IAAgB,KAAK,CAAC,OAAO,CAAC,OAAO,CAAA,IAAK,OAAO,CAAC,MAAA,GAAS,CAAC,EAAE;QAChE,MAAM,WAAW,OAAO,CAAC,GAAG,EAAC,IAAA,CAAM;gBAAE,IAAI,EAAE,MAAM;gBAAE,OAAO,EAAE,CAAA;YAAA,CAAG,CAAC,CAAC;QACjE,YAAY,CAAC,KAAK,EAAE,qSAAiC,EAAE,QAAQ,CAAC,QAAQ,CAAC,CAAC;IAC5E;IAEA,OAAO,KAAK;AACd;AAEA;;;;;;;CAOA,GACO,SAAS,iCAAiC,CAC/C,GAAG,EACH,iBAAiB,EACjB,YAAY,EACZ,gBAAgB,EAChB,iBAAiB;IAEjB,MAAM,MAAA,GAAS,iBAAiB,EAAE,WAAA,IAAe,GAAG,CAAC,EAAE,EAAA,CAAG,CAAC,CAAC;IAC5D,MAAM,SAAA,GAAY,gBAAgB,EAAE,KAAA,IAAS,iBAAiB,EAAE,aAAA,IAAiB,SAAS;IAE1F,MAAM,KAAA,GAAQ,qBAAqB,CAAC,MAAM,EAAE,SAAS,EAAE,MAAM,EAAE,GAAG,EAAE,gBAAgB,EAAE,iBAAiB,CAAC;IAExG,IAAI,YAAA,IAAgB,KAAK,CAAC,OAAO,CAAC,iBAAiB,CAAA,IAAK,iBAAiB,CAAC,MAAA,GAAS,CAAC,EAAE;QACpF,MAAM,UAAA,GAAa,0BAA0B,CAAC,iBAAiB,CAAC,IAAI,EAAE,CAAC;QACvE,MAAM,SAAA,OAAY,mRAAqB,EAAC,UAAU,CAAC;QACnD,YAAY,CAAC,KAAK,EAAE,qSAAiC,EAAE,QAAQ,CAAC,SAAS,CAAC,CAAC;IAC7E;IAEA,OAAO,KAAK;AACd;AAEA;;;;;;CAMA,GACA,SAAS,sBAAsB,CAAC,WAAW,EAAwB,KAAK,EAA4C;IAClH,MAAM,SAAS,GAAc,EAAE;IAC/B,MAAM,eAAA,GAAkB,WAAW,CAAC,IAAI,EAAE;IAE1C,KAAK,MAAM,GAAA,IAAO,eAAe,CAAE;QACjC,MAAM,OAAA,GAAU,GAAG,CAAC,OAAO,EAAE,OAAO;QACpC,IAAI,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE;YAC1B,KAAK,MAAM,IAAA,IAAQ,OAAO,CAAE;gBAC1B,MAAM,CAAA,GAAI,IAAA;gBACV,IAAI,CAAC,CAAC,IAAA,KAAS,UAAU,EAAE,SAAS,CAAC,IAAI,CAAC,CAAC,CAAC;YAC9C;QACF;IACF;IAEA,IAAI,SAAS,CAAC,MAAA,GAAS,CAAC,EAAE;QACxB,YAAY,CAAC,KAAK,EAAE,wSAAoC,EAAE,QAAQ,CAAC,SAAS,CAAC,CAAC;IAChF;AACF;AAEA;;;;;CAKA,GACA,SAAS,uBAAuB,CAC9B,SAAS,EACT,KAAK;IAEL,IAAI,CAAC,SAAS,EAAE;IAEhB,MAAM,UAAA,GAAa,SAAS,CAAC,UAAA;IAG7B,MAAM,cAAA,GAAiB,SAAS,CAAC,KAAA;IASjC,IAAI,UAAU,EAAE;QACd,kBAAkB,CAAC,KAAK,EAAE,uSAAmC,EAAE,UAAU,CAAC,YAAY,CAAC;QACvF,kBAAkB,CAAC,KAAK,EAAE,wSAAoC,EAAE,UAAU,CAAC,gBAAgB,CAAC;QAC5F,kBAAkB,CAAC,KAAK,EAAE,uSAAmC,EAAE,UAAU,CAAC,WAAW,CAAC;IACxF,CAAA,MAAO,IAAI,cAAc,EAAE;QACzB,kBAAkB,CAAC,KAAK,EAAE,uSAAmC,EAAE,cAAc,CAAC,YAAY,CAAC;QAC3F,kBAAkB,CAAC,KAAK,EAAE,wSAAoC,EAAE,cAAc,CAAC,aAAa,CAAC;QAEjG,mDAAA;QACI,MAAM,QAAQ,MAAM,CAAC,cAAc,CAAC,YAAY,CAAC;QACjD,MAAM,SAAS,MAAM,CAAC,cAAc,CAAC,aAAa,CAAC;QACnD,MAAM,KAAA,GAAQ,CAAC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAA,GAAI,CAAA,GAAI,KAAK,IAAA,CAAK,MAAM,CAAC,KAAK,CAAC,MAAM,CAAA,GAAI,CAAA,GAAI,MAAM,CAAC;QACrF,IAAI,KAAA,GAAQ,CAAC,EAAE,kBAAkB,CAAC,KAAK,EAAE,uSAAmC,EAAE,KAAK,CAAC;QAExF,uEAAA;QACI,IAAI,cAAc,CAAC,2BAAA,KAAgC,SAAS,EAC1D,kBAAkB,CAChB,KAAK,EACL,sTAAkD,EAClD,cAAc,CAAC,2BAA2B;QAE9C,IAAI,cAAc,CAAC,uBAAA,KAA4B,SAAS,EACtD,kBAAkB,CAAC,KAAK,EAAE,kTAA8C,EAAE,cAAc,CAAC,uBAAuB,CAAC;IACrH;AACF;AAEA;;;;;;;;CAQA,GACO,SAAS,4BAA4B,CAC1C,SAAS,EACT,aAAa;IAEb,IAAI,CAAC,SAAS,EAAE;IAEhB,MAAM,KAAK,GAAuC,CAAA,CAAE;IAEpD,IAAI,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC,WAAW,CAAC,EAAE;QACxC,MAAM,aAAA,GAAgB,SAAS,CAAC,WAAA,CAC7B,IAAI,GACJ,GAAG,EAAC,CAAA,GAAK,CAAC,CAAC,eAAe,EAAE,aAAa,EACzC,MAAM,CAAC,CAAC,CAAC,GAAkB,OAAO,CAAA,KAAM,QAAQ,CAAC;QAEpD,IAAI,aAAa,CAAC,MAAA,GAAS,CAAC,EAAE;YAC5B,YAAY,CAAC,KAAK,EAAE,4SAAwC,EAAE,QAAQ,CAAC,aAAa,CAAC,CAAC;QACxF;QAEJ,4FAAA;QACI,sBAAsB,CAAC,SAAS,CAAC,WAAA,EAAqC,KAAK,CAAC;QAE5E,IAAI,aAAa,EAAE;YACjB,MAAM,KAAA,GAAQ,SAAS,CAAC,WAAA,CACrB,IAAI,GACJ,GAAG,EAAC,GAAA,GAAO,GAAG,CAAC,IAAA,IAAQ,GAAG,CAAC,OAAO,EAAE,OAAO,EAC3C,MAAM,EAAC,CAAA,GAAK,OAAO,CAAA,KAAM,QAAQ,CAAC;YAErC,IAAI,KAAK,CAAC,MAAA,GAAS,CAAC,EAAE;gBACpB,YAAY,CAAC,KAAK,EAAE,kSAA8B,EAAE,QAAQ,CAAC,KAAK,CAAC,CAAC;YACtE;QACF;IACF;IAEA,uBAAuB,CAAC,SAAS,CAAC,SAAS,EAAE,KAAK,CAAC;IAEnD,MAAM,SAAA,GAAY,SAAS,CAAC,SAAA;IAC9B,6EAAA;IACE,MAAM,YAAY,SAAS,EAAE,UAAA,IAAc,SAAS,EAAE,KAAK;IAC3D,IAAI,SAAS,EAAE,YAAY,CAAC,KAAK,EAAE,mSAA+B,EAAE,SAAS,CAAC;IAE9E,IAAI,SAAS,EAAE,EAAE,EAAE;QACjB,YAAY,CAAC,KAAK,EAAE,gSAA4B,EAAE,SAAS,CAAC,EAAE,CAAC;IACjE;IAEA,IAAI,SAAS,EAAE,WAAW,EAAE;QAC1B,YAAY,CAAC,KAAK,EAAE,ySAAqC,EAAE,QAAQ,CAAC,SAAS,CAAC,WAAW,CAAC,CAAC;IAC7F;IAEA,OAAO,KAAK;AACd"}},
    {"offset": {"line": 4699, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/langchain/index.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/langchain/index.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SEMANTIC_ATTRIBUTE_SENTRY_OP, SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN } from '../../semanticAttributes';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport { startSpanManual } from '../../tracing/trace';\nimport type { Span, SpanAttributeValue } from '../../types-hoist/span';\nimport { GEN_AI_OPERATION_NAME_ATTRIBUTE, GEN_AI_REQUEST_MODEL_ATTRIBUTE } from '../ai/gen-ai-attributes';\nimport { LANGCHAIN_ORIGIN } from './constants';\nimport type {\n  LangChainCallbackHandler,\n  LangChainLLMResult,\n  LangChainMessage,\n  LangChainOptions,\n  LangChainSerialized,\n} from './types';\nimport {\n  extractChatModelRequestAttributes,\n  extractLLMRequestAttributes,\n  extractLlmResponseAttributes,\n  getInvocationParams,\n} from './utils';\n\n/**\n * Creates a Sentry callback handler for LangChain\n * Returns a plain object that LangChain will call via duck-typing\n *\n * This is a stateful handler that tracks spans across multiple LangChain executions.\n */\nexport function createLangChainCallbackHandler(options: LangChainOptions = {}): LangChainCallbackHandler {\n  const recordInputs = options.recordInputs ?? false;\n  const recordOutputs = options.recordOutputs ?? false;\n\n  // Internal state - single instance tracks all spans\n  const spanMap = new Map<string, Span>();\n\n  /**\n   * Exit a span and clean up\n   */\n  const exitSpan = (runId: string): void => {\n    const span = spanMap.get(runId);\n    if (span?.isRecording()) {\n      span.end();\n      spanMap.delete(runId);\n    }\n  };\n\n  /**\n   * Handler for LLM Start\n   * This handler will be called by LangChain's callback handler when an LLM event is detected.\n   */\n  const handler: LangChainCallbackHandler = {\n    // Required LangChain BaseCallbackHandler properties\n    lc_serializable: false,\n    lc_namespace: ['langchain_core', 'callbacks', 'sentry'],\n    lc_secrets: undefined,\n    lc_attributes: undefined,\n    lc_aliases: undefined,\n    lc_serializable_keys: undefined,\n    lc_id: ['langchain_core', 'callbacks', 'sentry'],\n    lc_kwargs: {},\n    name: 'SentryCallbackHandler',\n\n    // BaseCallbackHandlerInput boolean flags\n    ignoreLLM: false,\n    ignoreChain: false,\n    ignoreAgent: false,\n    ignoreRetriever: false,\n    ignoreCustomEvent: false,\n    raiseError: false,\n    awaitHandlers: true,\n\n    handleLLMStart(\n      llm: unknown,\n      prompts: string[],\n      runId: string,\n      _parentRunId?: string,\n      _extraParams?: Record<string, unknown>,\n      tags?: string[],\n      metadata?: Record<string, unknown>,\n      _runName?: string,\n    ) {\n      const invocationParams = getInvocationParams(tags);\n      const attributes = extractLLMRequestAttributes(\n        llm as LangChainSerialized,\n        prompts,\n        recordInputs,\n        invocationParams,\n        metadata,\n      );\n      const modelName = attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE];\n      const operationName = attributes[GEN_AI_OPERATION_NAME_ATTRIBUTE];\n\n      startSpanManual(\n        {\n          name: `${operationName} ${modelName}`,\n          op: 'gen_ai.pipeline',\n          attributes: {\n            ...attributes,\n            [SEMANTIC_ATTRIBUTE_SENTRY_OP]: 'gen_ai.pipeline',\n          },\n        },\n        span => {\n          spanMap.set(runId, span);\n          return span;\n        },\n      );\n    },\n\n    // Chat Model Start Handler\n    handleChatModelStart(\n      llm: unknown,\n      messages: unknown,\n      runId: string,\n      _parentRunId?: string,\n      _extraParams?: Record<string, unknown>,\n      tags?: string[],\n      metadata?: Record<string, unknown>,\n      _runName?: string,\n    ) {\n      const invocationParams = getInvocationParams(tags);\n      const attributes = extractChatModelRequestAttributes(\n        llm as LangChainSerialized,\n        messages as LangChainMessage[][],\n        recordInputs,\n        invocationParams,\n        metadata,\n      );\n      const modelName = attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE];\n      const operationName = attributes[GEN_AI_OPERATION_NAME_ATTRIBUTE];\n\n      startSpanManual(\n        {\n          name: `${operationName} ${modelName}`,\n          op: 'gen_ai.chat',\n          attributes: {\n            ...attributes,\n            [SEMANTIC_ATTRIBUTE_SENTRY_OP]: 'gen_ai.chat',\n          },\n        },\n        span => {\n          spanMap.set(runId, span);\n          return span;\n        },\n      );\n    },\n\n    // LLM End Handler - note: handleLLMEnd with capital LLM (used by both LLMs and chat models!)\n    handleLLMEnd(\n      output: unknown,\n      runId: string,\n      _parentRunId?: string,\n      _tags?: string[],\n      _extraParams?: Record<string, unknown>,\n    ) {\n      const span = spanMap.get(runId);\n      if (span?.isRecording()) {\n        const attributes = extractLlmResponseAttributes(output as LangChainLLMResult, recordOutputs);\n        if (attributes) {\n          span.setAttributes(attributes);\n        }\n        exitSpan(runId);\n      }\n    },\n\n    // LLM Error Handler - note: handleLLMError with capital LLM\n    handleLLMError(error: Error, runId: string) {\n      const span = spanMap.get(runId);\n      if (span?.isRecording()) {\n        span.setStatus({ code: SPAN_STATUS_ERROR, message: 'llm_error' });\n        exitSpan(runId);\n      }\n\n      captureException(error, {\n        mechanism: {\n          handled: false,\n          type: `${LANGCHAIN_ORIGIN}.llm_error_handler`,\n        },\n      });\n    },\n\n    // Chain Start Handler\n    handleChainStart(chain: { name?: string }, inputs: Record<string, unknown>, runId: string, _parentRunId?: string) {\n      const chainName = chain.name || 'unknown_chain';\n      const attributes: Record<string, SpanAttributeValue> = {\n        [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: 'auto.ai.langchain',\n        'langchain.chain.name': chainName,\n      };\n\n      // Add inputs if recordInputs is enabled\n      if (recordInputs) {\n        attributes['langchain.chain.inputs'] = JSON.stringify(inputs);\n      }\n\n      startSpanManual(\n        {\n          name: `chain ${chainName}`,\n          op: 'gen_ai.invoke_agent',\n          attributes: {\n            ...attributes,\n            [SEMANTIC_ATTRIBUTE_SENTRY_OP]: 'gen_ai.invoke_agent',\n          },\n        },\n        span => {\n          spanMap.set(runId, span);\n          return span;\n        },\n      );\n    },\n\n    // Chain End Handler\n    handleChainEnd(outputs: unknown, runId: string) {\n      const span = spanMap.get(runId);\n      if (span?.isRecording()) {\n        // Add outputs if recordOutputs is enabled\n        if (recordOutputs) {\n          span.setAttributes({\n            'langchain.chain.outputs': JSON.stringify(outputs),\n          });\n        }\n        exitSpan(runId);\n      }\n    },\n\n    // Chain Error Handler\n    handleChainError(error: Error, runId: string) {\n      const span = spanMap.get(runId);\n      if (span?.isRecording()) {\n        span.setStatus({ code: SPAN_STATUS_ERROR, message: 'chain_error' });\n        exitSpan(runId);\n      }\n\n      captureException(error, {\n        mechanism: {\n          handled: false,\n          type: `${LANGCHAIN_ORIGIN}.chain_error_handler`,\n        },\n      });\n    },\n\n    // Tool Start Handler\n    handleToolStart(tool: { name?: string }, input: string, runId: string, _parentRunId?: string) {\n      const toolName = tool.name || 'unknown_tool';\n      const attributes: Record<string, SpanAttributeValue> = {\n        [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: LANGCHAIN_ORIGIN,\n        'gen_ai.tool.name': toolName,\n      };\n\n      // Add input if recordInputs is enabled\n      if (recordInputs) {\n        attributes['gen_ai.tool.input'] = input;\n      }\n\n      startSpanManual(\n        {\n          name: `execute_tool ${toolName}`,\n          op: 'gen_ai.execute_tool',\n          attributes: {\n            ...attributes,\n            [SEMANTIC_ATTRIBUTE_SENTRY_OP]: 'gen_ai.execute_tool',\n          },\n        },\n        span => {\n          spanMap.set(runId, span);\n          return span;\n        },\n      );\n    },\n\n    // Tool End Handler\n    handleToolEnd(output: unknown, runId: string) {\n      const span = spanMap.get(runId);\n      if (span?.isRecording()) {\n        // Add output if recordOutputs is enabled\n        if (recordOutputs) {\n          span.setAttributes({\n            'gen_ai.tool.output': JSON.stringify(output),\n          });\n        }\n        exitSpan(runId);\n      }\n    },\n\n    // Tool Error Handler\n    handleToolError(error: Error, runId: string) {\n      const span = spanMap.get(runId);\n      if (span?.isRecording()) {\n        span.setStatus({ code: SPAN_STATUS_ERROR, message: 'tool_error' });\n        exitSpan(runId);\n      }\n\n      captureException(error, {\n        mechanism: {\n          handled: false,\n          type: `${LANGCHAIN_ORIGIN}.tool_error_handler`,\n        },\n      });\n    },\n\n    // LangChain BaseCallbackHandler required methods\n    copy() {\n      return handler;\n    },\n\n    toJSON() {\n      return {\n        lc: 1,\n        type: 'not_implemented',\n        id: handler.lc_id,\n      };\n    },\n\n    toJSONNotImplemented() {\n      return {\n        lc: 1,\n        type: 'not_implemented',\n        id: handler.lc_id,\n      };\n    },\n  };\n\n  return handler;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAqBA;;;;;CAKA,GACO,SAAS,8BAA8B,CAAC,OAAO,GAAqB,CAAA,CAAE,EAA4B;IACvG,MAAM,YAAA,GAAe,OAAO,CAAC,YAAA,IAAgB,KAAK;IAClD,MAAM,aAAA,GAAgB,OAAO,CAAC,aAAA,IAAiB,KAAK;IAEtD,oDAAA;IACE,MAAM,OAAA,GAAU,IAAI,GAAG,EAAgB;IAEzC;;GAEA,GACE,MAAM,QAAA,GAAW,CAAC,KAAK,KAAmB;QACxC,MAAM,OAAO,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC;QAC/B,IAAI,IAAI,EAAE,WAAW,EAAE,EAAE;YACvB,IAAI,CAAC,GAAG,EAAE;YACV,OAAO,CAAC,MAAM,CAAC,KAAK,CAAC;QACvB;IACF,CAAC;IAEH;;;GAGA,GACE,MAAM,OAAO,GAA6B;QAC5C,oDAAA;QACI,eAAe,EAAE,KAAK;QACtB,YAAY,EAAE;YAAC,gBAAgB;YAAE,WAAW;YAAE,QAAQ;SAAC;QACvD,UAAU,EAAE,SAAS;QACrB,aAAa,EAAE,SAAS;QACxB,UAAU,EAAE,SAAS;QACrB,oBAAoB,EAAE,SAAS;QAC/B,KAAK,EAAE;YAAC,gBAAgB;YAAE,WAAW;YAAE,QAAQ;SAAC;QAChD,SAAS,EAAE,CAAA,CAAE;QACb,IAAI,EAAE,uBAAuB;QAEjC,yCAAA;QACI,SAAS,EAAE,KAAK;QAChB,WAAW,EAAE,KAAK;QAClB,WAAW,EAAE,KAAK;QAClB,eAAe,EAAE,KAAK;QACtB,iBAAiB,EAAE,KAAK;QACxB,UAAU,EAAE,KAAK;QACjB,aAAa,EAAE,IAAI;QAEnB,cAAc,EACZ,GAAG,EACH,OAAO,EACP,KAAK,EACL,YAAY,EACZ,YAAY,EACZ,IAAI,EACJ,QAAQ,EACR,QAAQ;YAER,MAAM,gBAAA,OAAmB,4QAAmB,EAAC,IAAI,CAAC;YAClD,MAAM,UAAA,OAAa,oRAA2B,EAC5C,GAAA,EACA,OAAO,EACP,YAAY,EACZ,gBAAgB,EAChB,QAAQ;YAEV,MAAM,SAAA,GAAY,UAAU,CAAC,kSAA8B,CAAC;YAC5D,MAAM,aAAA,GAAgB,UAAU,CAAC,mSAA+B,CAAC;gBAEjE,2PAAe,EACb;gBACE,IAAI,EAAE,CAAC,EAAA,aAAA,CAAA,CAAA,EAAA,SAAA,CAAA,CAAA;gBACA,EAAA,EAAA,iBAAA;gBACA,UAAA,EAAA;oBACA,GAAA,UAAA;oBACA,CAAA,0QAAA,CAAA,EAAA,iBAAA;gBACA,CAAA;YACA,CAAA,GACA,IAAA,IAAA;gBACA,OAAA,CAAA,GAAA,CAAA,KAAA,EAAA,IAAA,CAAA;gBACA,OAAA,IAAA;YACA,CAAA;QAEA,CAAA;QAEA,2BAAA;QACA,oBAAA,EACA,GAAA,EACA,QAAA,EACA,KAAA,EACA,YAAA,EACA,YAAA,EACA,IAAA,EACA,QAAA,EACA,QAAA;YAEA,MAAA,gBAAA,OAAA,4QAAA,EAAA,IAAA,CAAA;YACA,MAAA,UAAA,OAAA,0RAAA,EACA,GAAA,EACA,QAAA,EACA,YAAA,EACA,gBAAA,EACA,QAAA;YAEA,MAAA,SAAA,GAAA,UAAA,CAAA,kSAAA,CAAA;YACA,MAAA,aAAA,GAAA,UAAA,CAAA,mSAAA,CAAA;gBAEA,2PAAA,EACA;gBACA,IAAA,EAAA,CAAA,EAAA,aAAA,CAAA,CAAA,EAAA,SAAA,CAAA,CAAA;gBACA,EAAA,EAAA,aAAA;gBACA,UAAA,EAAA;oBACA,GAAA,UAAA;oBACA,CAAA,0QAAA,CAAA,EAAA,aAAA;gBACA,CAAA;YACA,CAAA,GACA,IAAA,IAAA;gBACA,OAAA,CAAA,GAAA,CAAA,KAAA,EAAA,IAAA,CAAA;gBACA,OAAA,IAAA;YACA,CAAA;QAEA,CAAA;QAEA,6FAAA;QACA,YAAA,EACA,MAAA,EACA,KAAA,EACA,YAAA,EACA,KAAA,EACA,YAAA;YAEA,MAAA,IAAA,GAAA,OAAA,CAAA,GAAA,CAAA,KAAA,CAAA;YACA,IAAA,IAAA,EAAA,WAAA,EAAA,EAAA;gBACA,MAAA,UAAA,OAAA,qRAAA,EAAA,MAAA,EAAA,aAAA,CAAA;gBACA,IAAA,UAAA,EAAA;oBACA,IAAA,CAAA,aAAA,CAAA,UAAA,CAAA;gBACA;gBACA,QAAA,CAAA,KAAA,CAAA;YACA;QACA,CAAA;QAEA,4DAAA;QACA,cAAA,EAAA,KAAA,EAAA,KAAA,EAAA;YACA,MAAA,IAAA,GAAA,OAAA,CAAA,GAAA,CAAA,KAAA,CAAA;YACA,IAAA,IAAA,EAAA,WAAA,EAAA,EAAA;gBACA,IAAA,CAAA,SAAA,CAAA;oBAAA,IAAA,EAAA,kQAAA;oBAAA,OAAA,EAAA,WAAA;gBAAA,CAAA,CAAA;gBACA,QAAA,CAAA,KAAA,CAAA;YACA;gBAEA,mPAAA,EAAA,KAAA,EAAA;gBACA,SAAA,EAAA;oBACA,OAAA,EAAA,KAAA;oBACA,IAAA,EAAA,CAAA,EAAA,6QAAA,CAAA,kBAAA,CAAA;gBACA,CAAA;YACA,CAAA,CAAA;QACA,CAAA;QAEA,sBAAA;QACA,gBAAA,EAAA,KAAA,EAAA,MAAA,EAAA,KAAA,EAAA,YAAA,EAAA;YACA,MAAA,SAAA,GAAA,KAAA,CAAA,IAAA,IAAA,eAAA;YACA,MAAA,UAAA,GAAA;gBACA,CAAA,8QAAA,CAAA,EAAA,mBAAA;gBACA,sBAAA,EAAA,SAAA;YACA,CAAA;YAEA,wCAAA;YACA,IAAA,YAAA,EAAA;gBACA,UAAA,CAAA,wBAAA,CAAA,GAAA,IAAA,CAAA,SAAA,CAAA,MAAA,CAAA;YACA;gBAEA,2PAAA,EACA;gBACA,IAAA,EAAA,CAAA,MAAA,EAAA,SAAA,CAAA,CAAA;gBACA,EAAA,EAAA,qBAAA;gBACA,UAAA,EAAA;oBACA,GAAA,UAAA;oBACA,CAAA,0QAAA,CAAA,EAAA,qBAAA;gBACA,CAAA;YACA,CAAA,GACA,IAAA,IAAA;gBACA,OAAA,CAAA,GAAA,CAAA,KAAA,EAAA,IAAA,CAAA;gBACA,OAAA,IAAA;YACA,CAAA;QAEA,CAAA;QAEA,oBAAA;QACA,cAAA,EAAA,OAAA,EAAA,KAAA,EAAA;YACA,MAAA,IAAA,GAAA,OAAA,CAAA,GAAA,CAAA,KAAA,CAAA;YACA,IAAA,IAAA,EAAA,WAAA,EAAA,EAAA;gBACA,0CAAA;gBACA,IAAA,aAAA,EAAA;oBACA,IAAA,CAAA,aAAA,CAAA;wBACA,yBAAA,EAAA,IAAA,CAAA,SAAA,CAAA,OAAA,CAAA;oBACA,CAAA,CAAA;gBACA;gBACA,QAAA,CAAA,KAAA,CAAA;YACA;QACA,CAAA;QAEA,sBAAA;QACA,gBAAA,EAAA,KAAA,EAAA,KAAA,EAAA;YACA,MAAA,IAAA,GAAA,OAAA,CAAA,GAAA,CAAA,KAAA,CAAA;YACA,IAAA,IAAA,EAAA,WAAA,EAAA,EAAA;gBACA,IAAA,CAAA,SAAA,CAAA;oBAAA,IAAA,EAAA,kQAAA;oBAAA,OAAA,EAAA,aAAA;gBAAA,CAAA,CAAA;gBACA,QAAA,CAAA,KAAA,CAAA;YACA;gBAEA,mPAAA,EAAA,KAAA,EAAA;gBACA,SAAA,EAAA;oBACA,OAAA,EAAA,KAAA;oBACA,IAAA,EAAA,CAAA,EAAA,6QAAA,CAAA,oBAAA,CAAA;gBACA,CAAA;YACA,CAAA,CAAA;QACA,CAAA;QAEA,qBAAA;QACA,eAAA,EAAA,IAAA,EAAA,KAAA,EAAA,KAAA,EAAA,YAAA,EAAA;YACA,MAAA,QAAA,GAAA,IAAA,CAAA,IAAA,IAAA,cAAA;YACA,MAAA,UAAA,GAAA;gBACA,CAAA,8QAAA,CAAA,EAAA,6QAAA;gBACA,kBAAA,EAAA,QAAA;YACA,CAAA;YAEA,uCAAA;YACA,IAAA,YAAA,EAAA;gBACA,UAAA,CAAA,mBAAA,CAAA,GAAA,KAAA;YACA;gBAEA,2PAAA,EACA;gBACA,IAAA,EAAA,CAAA,aAAA,EAAA,QAAA,CAAA,CAAA;gBACA,EAAA,EAAA,qBAAA;gBACA,UAAA,EAAA;oBACA,GAAA,UAAA;oBACA,CAAA,0QAAA,CAAA,EAAA,qBAAA;gBACA,CAAA;YACA,CAAA,GACA,IAAA,IAAA;gBACA,OAAA,CAAA,GAAA,CAAA,KAAA,EAAA,IAAA,CAAA;gBACA,OAAA,IAAA;YACA,CAAA;QAEA,CAAA;QAEA,mBAAA;QACA,aAAA,EAAA,MAAA,EAAA,KAAA,EAAA;YACA,MAAA,IAAA,GAAA,OAAA,CAAA,GAAA,CAAA,KAAA,CAAA;YACA,IAAA,IAAA,EAAA,WAAA,EAAA,EAAA;gBACA,yCAAA;gBACA,IAAA,aAAA,EAAA;oBACA,IAAA,CAAA,aAAA,CAAA;wBACA,oBAAA,EAAA,IAAA,CAAA,SAAA,CAAA,MAAA,CAAA;oBACA,CAAA,CAAA;gBACA;gBACA,QAAA,CAAA,KAAA,CAAA;YACA;QACA,CAAA;QAEA,qBAAA;QACA,eAAA,EAAA,KAAA,EAAA,KAAA,EAAA;YACA,MAAA,IAAA,GAAA,OAAA,CAAA,GAAA,CAAA,KAAA,CAAA;YACA,IAAA,IAAA,EAAA,WAAA,EAAA,EAAA;gBACA,IAAA,CAAA,SAAA,CAAA;oBAAA,IAAA,EAAA,kQAAA;oBAAA,OAAA,EAAA,YAAA;gBAAA,CAAA,CAAA;gBACA,QAAA,CAAA,KAAA,CAAA;YACA;gBAEA,mPAAA,EAAA,KAAA,EAAA;gBACA,SAAA,EAAA;oBACA,OAAA,EAAA,KAAA;oBACA,IAAA,EAAA,CAAA,EAAA,6QAAA,CAAA,mBAAA,CAAA;gBACA,CAAA;YACA,CAAA,CAAA;QACA,CAAA;QAEA,iDAAA;QACA,IAAA,GAAA;YACA,OAAA,OAAA;QACA,CAAA;QAEA,MAAA,GAAA;YACA,OAAA;gBACA,EAAA,EAAA,CAAA;gBACA,IAAA,EAAA,iBAAA;gBACA,EAAA,EAAA,OAAA,CAAA,KAAA;YACA,CAAA;QACA,CAAA;QAEA,oBAAA,GAAA;YACA,OAAA;gBACA,EAAA,EAAA,CAAA;gBACA,IAAA,EAAA,iBAAA;gBACA,EAAA,EAAA,OAAA,CAAA,KAAA;YACA,CAAA;QACA,CAAA;IACA,CAAA;IAEA,OAAA,OAAA;AACA"}},
    {"offset": {"line": 4962, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/langgraph/constants.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/langgraph/constants.ts"],"sourcesContent":["export const LANGGRAPH_INTEGRATION_NAME = 'LangGraph';\nexport const LANGGRAPH_ORIGIN = 'auto.ai.langgraph';\n"],"names":[],"mappings":";;;;;;AAAO,MAAM,0BAAA,GAA6B;AACnC,MAAM,gBAAA,GAAmB"}},
    {"offset": {"line": 4976, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/langgraph/utils.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/langgraph/utils.ts"],"sourcesContent":["import type { Span } from '../../types-hoist/span';\nimport {\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport type { LangChainMessage } from '../langchain/types';\nimport { normalizeLangChainMessages } from '../langchain/utils';\nimport type { CompiledGraph, LangGraphTool } from './types';\n\n/**\n * Extract tool calls from messages\n */\nexport function extractToolCalls(messages: Array<Record<string, unknown>> | null): unknown[] | null {\n  if (!messages || messages.length === 0) {\n    return null;\n  }\n\n  const toolCalls: unknown[] = [];\n\n  for (const message of messages) {\n    if (message && typeof message === 'object') {\n      const msgToolCalls = message.tool_calls;\n      if (msgToolCalls && Array.isArray(msgToolCalls)) {\n        toolCalls.push(...msgToolCalls);\n      }\n    }\n  }\n\n  return toolCalls.length > 0 ? toolCalls : null;\n}\n\n/**\n * Extract token usage from a message's usage_metadata or response_metadata\n * Returns token counts without setting span attributes\n */\nexport function extractTokenUsageFromMessage(message: LangChainMessage): {\n  inputTokens: number;\n  outputTokens: number;\n  totalTokens: number;\n} {\n  const msg = message as Record<string, unknown>;\n  let inputTokens = 0;\n  let outputTokens = 0;\n  let totalTokens = 0;\n\n  // Extract from usage_metadata (newer format)\n  if (msg.usage_metadata && typeof msg.usage_metadata === 'object') {\n    const usage = msg.usage_metadata as Record<string, unknown>;\n    if (typeof usage.input_tokens === 'number') {\n      inputTokens = usage.input_tokens;\n    }\n    if (typeof usage.output_tokens === 'number') {\n      outputTokens = usage.output_tokens;\n    }\n    if (typeof usage.total_tokens === 'number') {\n      totalTokens = usage.total_tokens;\n    }\n    return { inputTokens, outputTokens, totalTokens };\n  }\n\n  // Fallback: Extract from response_metadata.tokenUsage\n  if (msg.response_metadata && typeof msg.response_metadata === 'object') {\n    const metadata = msg.response_metadata as Record<string, unknown>;\n    if (metadata.tokenUsage && typeof metadata.tokenUsage === 'object') {\n      const tokenUsage = metadata.tokenUsage as Record<string, unknown>;\n      if (typeof tokenUsage.promptTokens === 'number') {\n        inputTokens = tokenUsage.promptTokens;\n      }\n      if (typeof tokenUsage.completionTokens === 'number') {\n        outputTokens = tokenUsage.completionTokens;\n      }\n      if (typeof tokenUsage.totalTokens === 'number') {\n        totalTokens = tokenUsage.totalTokens;\n      }\n    }\n  }\n\n  return { inputTokens, outputTokens, totalTokens };\n}\n\n/**\n * Extract model and finish reason from a message's response_metadata\n */\nexport function extractModelMetadata(span: Span, message: LangChainMessage): void {\n  const msg = message as Record<string, unknown>;\n\n  if (msg.response_metadata && typeof msg.response_metadata === 'object') {\n    const metadata = msg.response_metadata as Record<string, unknown>;\n\n    if (metadata.model_name && typeof metadata.model_name === 'string') {\n      span.setAttribute(GEN_AI_RESPONSE_MODEL_ATTRIBUTE, metadata.model_name);\n    }\n\n    if (metadata.finish_reason && typeof metadata.finish_reason === 'string') {\n      span.setAttribute(GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE, [metadata.finish_reason]);\n    }\n  }\n}\n\n/**\n * Extract tools from compiled graph structure\n *\n * Tools are stored in: compiledGraph.builder.nodes.tools.runnable.tools\n */\nexport function extractToolsFromCompiledGraph(compiledGraph: CompiledGraph): unknown[] | null {\n  if (!compiledGraph.builder?.nodes?.tools?.runnable?.tools) {\n    return null;\n  }\n\n  const tools = compiledGraph.builder?.nodes?.tools?.runnable?.tools;\n\n  if (!tools || !Array.isArray(tools) || tools.length === 0) {\n    return null;\n  }\n\n  // Extract name, description, and schema from each tool's lc_kwargs\n  return tools.map((tool: LangGraphTool) => ({\n    name: tool.lc_kwargs?.name,\n    description: tool.lc_kwargs?.description,\n    schema: tool.lc_kwargs?.schema,\n  }));\n}\n\n/**\n * Set response attributes on the span\n */\nexport function setResponseAttributes(span: Span, inputMessages: LangChainMessage[] | null, result: unknown): void {\n  // Extract messages from result\n  const resultObj = result as { messages?: LangChainMessage[] } | undefined;\n  const outputMessages = resultObj?.messages;\n\n  if (!outputMessages || !Array.isArray(outputMessages)) {\n    return;\n  }\n\n  // Get new messages (delta between input and output)\n  const inputCount = inputMessages?.length ?? 0;\n  const newMessages = outputMessages.length > inputCount ? outputMessages.slice(inputCount) : [];\n\n  if (newMessages.length === 0) {\n    return;\n  }\n\n  // Extract and set tool calls from new messages BEFORE normalization\n  // (normalization strips tool_calls, so we need to extract them first)\n  const toolCalls = extractToolCalls(newMessages as Array<Record<string, unknown>>);\n  if (toolCalls) {\n    span.setAttribute(GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE, JSON.stringify(toolCalls));\n  }\n\n  // Normalize the new messages\n  const normalizedNewMessages = normalizeLangChainMessages(newMessages);\n  span.setAttribute(GEN_AI_RESPONSE_TEXT_ATTRIBUTE, JSON.stringify(normalizedNewMessages));\n\n  // Accumulate token usage across all messages\n  let totalInputTokens = 0;\n  let totalOutputTokens = 0;\n  let totalTokens = 0;\n\n  // Extract metadata from messages\n  for (const message of newMessages) {\n    // Accumulate token usage\n    const tokens = extractTokenUsageFromMessage(message);\n    totalInputTokens += tokens.inputTokens;\n    totalOutputTokens += tokens.outputTokens;\n    totalTokens += tokens.totalTokens;\n\n    // Extract model metadata (last message's metadata wins for model/finish_reason)\n    extractModelMetadata(span, message);\n  }\n\n  // Set accumulated token usage on span\n  if (totalInputTokens > 0) {\n    span.setAttribute(GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE, totalInputTokens);\n  }\n  if (totalOutputTokens > 0) {\n    span.setAttribute(GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE, totalOutputTokens);\n  }\n  if (totalTokens > 0) {\n    span.setAttribute(GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE, totalTokens);\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAcA;;CAEA,GACO,SAAS,gBAAgB,CAAC,QAAQ,EAA2D;IAClG,IAAI,CAAC,QAAA,IAAY,QAAQ,CAAC,MAAA,KAAW,CAAC,EAAE;QACtC,OAAO,IAAI;IACb;IAEA,MAAM,SAAS,GAAc,EAAE;IAE/B,KAAK,MAAM,OAAA,IAAW,QAAQ,CAAE;QAC9B,IAAI,OAAA,IAAW,OAAO,OAAA,KAAY,QAAQ,EAAE;YAC1C,MAAM,YAAA,GAAe,OAAO,CAAC,UAAU;YACvC,IAAI,YAAA,IAAgB,KAAK,CAAC,OAAO,CAAC,YAAY,CAAC,EAAE;gBAC/C,SAAS,CAAC,IAAI,CAAC,GAAG,YAAY,CAAC;YACjC;QACF;IACF;IAEA,OAAO,SAAS,CAAC,MAAA,GAAS,CAAA,GAAI,SAAA,GAAY,IAAI;AAChD;AAEA;;;CAGA,GACO,SAAS,4BAA4B,CAAC,OAAO;IAKlD,MAAM,GAAA,GAAM,OAAA;IACZ,IAAI,WAAA,GAAc,CAAC;IACnB,IAAI,YAAA,GAAe,CAAC;IACpB,IAAI,WAAA,GAAc,CAAC;IAErB,6CAAA;IACE,IAAI,GAAG,CAAC,cAAA,IAAkB,OAAO,GAAG,CAAC,cAAA,KAAmB,QAAQ,EAAE;QAChE,MAAM,KAAA,GAAQ,GAAG,CAAC,cAAA;QAClB,IAAI,OAAO,KAAK,CAAC,YAAA,KAAiB,QAAQ,EAAE;YAC1C,WAAA,GAAc,KAAK,CAAC,YAAY;QAClC;QACA,IAAI,OAAO,KAAK,CAAC,aAAA,KAAkB,QAAQ,EAAE;YAC3C,YAAA,GAAe,KAAK,CAAC,aAAa;QACpC;QACA,IAAI,OAAO,KAAK,CAAC,YAAA,KAAiB,QAAQ,EAAE;YAC1C,WAAA,GAAc,KAAK,CAAC,YAAY;QAClC;QACA,OAAO;YAAE,WAAW;YAAE,YAAY;YAAE;QAAA,CAAa;IACnD;IAEF,sDAAA;IACE,IAAI,GAAG,CAAC,iBAAA,IAAqB,OAAO,GAAG,CAAC,iBAAA,KAAsB,QAAQ,EAAE;QACtE,MAAM,QAAA,GAAW,GAAG,CAAC,iBAAA;QACrB,IAAI,QAAQ,CAAC,UAAA,IAAc,OAAO,QAAQ,CAAC,UAAA,KAAe,QAAQ,EAAE;YAClE,MAAM,UAAA,GAAa,QAAQ,CAAC,UAAA;YAC5B,IAAI,OAAO,UAAU,CAAC,YAAA,KAAiB,QAAQ,EAAE;gBAC/C,WAAA,GAAc,UAAU,CAAC,YAAY;YACvC;YACA,IAAI,OAAO,UAAU,CAAC,gBAAA,KAAqB,QAAQ,EAAE;gBACnD,YAAA,GAAe,UAAU,CAAC,gBAAgB;YAC5C;YACA,IAAI,OAAO,UAAU,CAAC,WAAA,KAAgB,QAAQ,EAAE;gBAC9C,WAAA,GAAc,UAAU,CAAC,WAAW;YACtC;QACF;IACF;IAEA,OAAO;QAAE,WAAW;QAAE,YAAY;QAAE;IAAA,CAAa;AACnD;AAEA;;CAEA,GACO,SAAS,oBAAoB,CAAC,IAAI,EAAQ,OAAO,EAA0B;IAChF,MAAM,GAAA,GAAM,OAAA;IAEZ,IAAI,GAAG,CAAC,iBAAA,IAAqB,OAAO,GAAG,CAAC,iBAAA,KAAsB,QAAQ,EAAE;QACtE,MAAM,QAAA,GAAW,GAAG,CAAC,iBAAA;QAErB,IAAI,QAAQ,CAAC,UAAA,IAAc,OAAO,QAAQ,CAAC,UAAA,KAAe,QAAQ,EAAE;YAClE,IAAI,CAAC,YAAY,CAAC,mSAA+B,EAAE,QAAQ,CAAC,UAAU,CAAC;QACzE;QAEA,IAAI,QAAQ,CAAC,aAAA,IAAiB,OAAO,QAAQ,CAAC,aAAA,KAAkB,QAAQ,EAAE;YACxE,IAAI,CAAC,YAAY,CAAC,4SAAwC,EAAE;gBAAC,QAAQ,CAAC,aAAa;aAAC,CAAC;QACvF;IACF;AACF;AAEA;;;;CAIA,GACO,SAAS,6BAA6B,CAAC,aAAa,EAAmC;IAC5F,IAAI,CAAC,aAAa,CAAC,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,QAAQ,EAAE,KAAK,EAAE;QACzD,OAAO,IAAI;IACb;IAEA,MAAM,KAAA,GAAQ,aAAa,CAAC,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,QAAQ,EAAE,KAAK;IAElE,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,OAAO,CAAC,KAAK,KAAK,KAAK,CAAC,MAAA,KAAW,CAAC,EAAE;QACzD,OAAO,IAAI;IACb;IAEF,mEAAA;IACE,OAAO,KAAK,CAAC,GAAG,CAAC,CAAC,IAAI,GAAA,CAAqB;YACzC,IAAI,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI;YAC1B,WAAW,EAAE,IAAI,CAAC,SAAS,EAAE,WAAW;YACxC,MAAM,EAAE,IAAI,CAAC,SAAS,EAAE,MAAM;QAClC,CAAG,CAAC,CAAC;AACL;AAEA;;CAEA,GACO,SAAS,qBAAqB,CAAC,IAAI,EAAQ,aAAa,EAA6B,MAAM,EAAiB;IACnH,+BAAA;IACE,MAAM,SAAA,GAAY,MAAA;IAClB,MAAM,cAAA,GAAiB,SAAS,EAAE,QAAQ;IAE1C,IAAI,CAAC,cAAA,IAAkB,CAAC,KAAK,CAAC,OAAO,CAAC,cAAc,CAAC,EAAE;QACrD;IACF;IAEF,oDAAA;IACE,MAAM,UAAA,GAAa,aAAa,EAAE,MAAA,IAAU,CAAC;IAC7C,MAAM,WAAA,GAAc,cAAc,CAAC,MAAA,GAAS,UAAA,GAAa,cAAc,CAAC,KAAK,CAAC,UAAU,CAAA,GAAI,EAAE;IAE9F,IAAI,WAAW,CAAC,MAAA,KAAW,CAAC,EAAE;QAC5B;IACF;IAEF,oEAAA;IACA,sEAAA;IACE,MAAM,SAAA,GAAY,gBAAgB,CAAC,aAA8C;IACjF,IAAI,SAAS,EAAE;QACb,IAAI,CAAC,YAAY,CAAC,wSAAoC,EAAE,IAAI,CAAC,SAAS,CAAC,SAAS,CAAC,CAAC;IACpF;IAEF,6BAAA;IACE,MAAM,qBAAA,OAAwB,mRAA0B,EAAC,WAAW,CAAC;IACrE,IAAI,CAAC,YAAY,CAAC,kSAA8B,EAAE,IAAI,CAAC,SAAS,CAAC,qBAAqB,CAAC,CAAC;IAE1F,6CAAA;IACE,IAAI,gBAAA,GAAmB,CAAC;IACxB,IAAI,iBAAA,GAAoB,CAAC;IACzB,IAAI,WAAA,GAAc,CAAC;IAErB,iCAAA;IACE,KAAK,MAAM,OAAA,IAAW,WAAW,CAAE;QACrC,yBAAA;QACI,MAAM,MAAA,GAAS,4BAA4B,CAAC,OAAO,CAAC;QACpD,gBAAA,IAAoB,MAAM,CAAC,WAAW;QACtC,iBAAA,IAAqB,MAAM,CAAC,YAAY;QACxC,WAAA,IAAe,MAAM,CAAC,WAAW;QAErC,gFAAA;QACI,oBAAoB,CAAC,IAAI,EAAE,OAAO,CAAC;IACrC;IAEF,sCAAA;IACE,IAAI,gBAAA,GAAmB,CAAC,EAAE;QACxB,IAAI,CAAC,YAAY,CAAC,uSAAmC,EAAE,gBAAgB,CAAC;IAC1E;IACA,IAAI,iBAAA,GAAoB,CAAC,EAAE;QACzB,IAAI,CAAC,YAAY,CAAC,wSAAoC,EAAE,iBAAiB,CAAC;IAC5E;IACA,IAAI,WAAA,GAAc,CAAC,EAAE;QACnB,IAAI,CAAC,YAAY,CAAC,uSAAmC,EAAE,WAAW,CAAC;IACrE;AACF"}},
    {"offset": {"line": 5147, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/langgraph/index.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/langgraph/index.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SEMANTIC_ATTRIBUTE_SENTRY_OP, SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN } from '../../semanticAttributes';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport {\n  GEN_AI_AGENT_NAME_ATTRIBUTE,\n  GEN_AI_INVOKE_AGENT_OPERATION_ATTRIBUTE,\n  GEN_AI_OPERATION_NAME_ATTRIBUTE,\n  GEN_AI_PIPELINE_NAME_ATTRIBUTE,\n  GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE,\n  GEN_AI_REQUEST_MESSAGES_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { truncateGenAiMessages } from '../ai/messageTruncation';\nimport type { LangChainMessage } from '../langchain/types';\nimport { normalizeLangChainMessages } from '../langchain/utils';\nimport { startSpan } from '../trace';\nimport { LANGGRAPH_ORIGIN } from './constants';\nimport type { CompiledGraph, LangGraphOptions } from './types';\nimport { extractToolsFromCompiledGraph, setResponseAttributes } from './utils';\n\n/**\n * Instruments StateGraph's compile method to create spans for agent creation and invocation\n *\n * Wraps the compile() method to:\n * - Create a `gen_ai.create_agent` span when compile() is called\n * - Automatically wrap the invoke() method on the returned compiled graph with a `gen_ai.invoke_agent` span\n *\n */\nexport function instrumentStateGraphCompile(\n  originalCompile: (...args: unknown[]) => CompiledGraph,\n  options: LangGraphOptions,\n): (...args: unknown[]) => CompiledGraph {\n  return new Proxy(originalCompile, {\n    apply(target, thisArg, args: unknown[]): CompiledGraph {\n      return startSpan(\n        {\n          op: 'gen_ai.create_agent',\n          name: 'create_agent',\n          attributes: {\n            [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: LANGGRAPH_ORIGIN,\n            [SEMANTIC_ATTRIBUTE_SENTRY_OP]: 'gen_ai.create_agent',\n            [GEN_AI_OPERATION_NAME_ATTRIBUTE]: 'create_agent',\n          },\n        },\n        span => {\n          try {\n            const compiledGraph = Reflect.apply(target, thisArg, args);\n            const compileOptions = args.length > 0 ? (args[0] as Record<string, unknown>) : {};\n\n            // Extract graph name\n            if (compileOptions?.name && typeof compileOptions.name === 'string') {\n              span.setAttribute(GEN_AI_AGENT_NAME_ATTRIBUTE, compileOptions.name);\n              span.updateName(`create_agent ${compileOptions.name}`);\n            }\n\n            // Instrument agent invoke method on the compiled graph\n            const originalInvoke = compiledGraph.invoke;\n            if (originalInvoke && typeof originalInvoke === 'function') {\n              compiledGraph.invoke = instrumentCompiledGraphInvoke(\n                originalInvoke.bind(compiledGraph) as (...args: unknown[]) => Promise<unknown>,\n                compiledGraph,\n                compileOptions,\n                options,\n              ) as typeof originalInvoke;\n            }\n\n            return compiledGraph;\n          } catch (error) {\n            span.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n            captureException(error, {\n              mechanism: {\n                handled: false,\n                type: 'auto.ai.langgraph.error',\n              },\n            });\n            throw error;\n          }\n        },\n      );\n    },\n  }) as (...args: unknown[]) => CompiledGraph;\n}\n\n/**\n * Instruments CompiledGraph's invoke method to create spans for agent invocation\n *\n * Creates a `gen_ai.invoke_agent` span when invoke() is called\n */\nfunction instrumentCompiledGraphInvoke(\n  originalInvoke: (...args: unknown[]) => Promise<unknown>,\n  graphInstance: CompiledGraph,\n  compileOptions: Record<string, unknown>,\n  options: LangGraphOptions,\n): (...args: unknown[]) => Promise<unknown> {\n  return new Proxy(originalInvoke, {\n    apply(target, thisArg, args: unknown[]): Promise<unknown> {\n      return startSpan(\n        {\n          op: 'gen_ai.invoke_agent',\n          name: 'invoke_agent',\n          attributes: {\n            [SEMANTIC_ATTRIBUTE_SENTRY_ORIGIN]: LANGGRAPH_ORIGIN,\n            [SEMANTIC_ATTRIBUTE_SENTRY_OP]: GEN_AI_INVOKE_AGENT_OPERATION_ATTRIBUTE,\n            [GEN_AI_OPERATION_NAME_ATTRIBUTE]: 'invoke_agent',\n          },\n        },\n        async span => {\n          try {\n            const graphName = compileOptions?.name;\n\n            if (graphName && typeof graphName === 'string') {\n              span.setAttribute(GEN_AI_PIPELINE_NAME_ATTRIBUTE, graphName);\n              span.setAttribute(GEN_AI_AGENT_NAME_ATTRIBUTE, graphName);\n              span.updateName(`invoke_agent ${graphName}`);\n            }\n\n            // Extract available tools from the graph instance\n            const tools = extractToolsFromCompiledGraph(graphInstance);\n            if (tools) {\n              span.setAttribute(GEN_AI_REQUEST_AVAILABLE_TOOLS_ATTRIBUTE, JSON.stringify(tools));\n            }\n\n            // Parse input messages\n            const recordInputs = options.recordInputs;\n            const recordOutputs = options.recordOutputs;\n            const inputMessages =\n              args.length > 0 ? ((args[0] as { messages?: LangChainMessage[] }).messages ?? []) : [];\n\n            if (inputMessages && recordInputs) {\n              const normalizedMessages = normalizeLangChainMessages(inputMessages);\n              const truncatedMessages = truncateGenAiMessages(normalizedMessages);\n              span.setAttribute(GEN_AI_REQUEST_MESSAGES_ATTRIBUTE, JSON.stringify(truncatedMessages));\n            }\n\n            // Call original invoke\n            const result = await Reflect.apply(target, thisArg, args);\n\n            // Set response attributes\n            if (recordOutputs) {\n              setResponseAttributes(span, inputMessages ?? null, result);\n            }\n\n            return result;\n          } catch (error) {\n            span.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n            captureException(error, {\n              mechanism: {\n                handled: false,\n                type: 'auto.ai.langgraph.error',\n              },\n            });\n            throw error;\n          }\n        },\n      );\n    },\n  }) as (...args: unknown[]) => Promise<unknown>;\n}\n\n/**\n * Directly instruments a StateGraph instance to add tracing spans\n *\n * This function can be used to manually instrument LangGraph StateGraph instances\n * in environments where automatic instrumentation is not available or desired.\n *\n * @param stateGraph - The StateGraph instance to instrument\n * @param options - Optional configuration for recording inputs/outputs\n *\n * @example\n * ```typescript\n * import { instrumentLangGraph } from '@sentry/cloudflare';\n * import { StateGraph } from '@langchain/langgraph';\n *\n * const graph = new StateGraph(MessagesAnnotation)\n *   .addNode('agent', mockLlm)\n *   .addEdge(START, 'agent')\n *   .addEdge('agent', END);\n *\n * instrumentLangGraph(graph, { recordInputs: true, recordOutputs: true });\n * const compiled = graph.compile({ name: 'my_agent' });\n * ```\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nexport function instrumentLangGraph<T extends { compile: (...args: any[]) => any }>(\n  stateGraph: T,\n  options?: LangGraphOptions,\n): T {\n  const _options: LangGraphOptions = options || {};\n\n  stateGraph.compile = instrumentStateGraphCompile(stateGraph.compile.bind(stateGraph), _options);\n\n  return stateGraph;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;AAmBA;;;;;;;CAOA,GACO,SAAS,2BAA2B,CACzC,eAAe,EACf,OAAO;IAEP,OAAO,IAAI,KAAK,CAAC,eAAe,EAAE;QAChC,KAAK,EAAC,MAAM,EAAE,OAAO,EAAE,IAAI,EAA4B;YACrD,WAAO,qPAAS,EACd;gBACE,EAAE,EAAE,qBAAqB;gBACzB,IAAI,EAAE,cAAc;gBACpB,UAAU,EAAE;oBACV,CAAC,8QAAgC,CAAA,EAAG,6QAAgB;oBACpD,CAAC,0QAA4B,CAAA,EAAG,qBAAqB;oBACrD,CAAC,mSAA+B,CAAA,EAAG,cAAc;gBAC7D,CAAW;YACX,CAAS,GACD,QAAQ;gBACN,IAAI;oBACF,MAAM,aAAA,GAAgB,OAAO,CAAC,KAAK,CAAC,MAAM,EAAE,OAAO,EAAE,IAAI,CAAC;oBAC1D,MAAM,cAAA,GAAiB,IAAI,CAAC,MAAA,GAAS,CAAA,GAAK,IAAI,CAAC,CAAC,CAAA,GAAgC,CAAA,CAAE;oBAE9F,qBAAA;oBACY,IAAI,cAAc,EAAE,IAAA,IAAQ,OAAO,cAAc,CAAC,IAAA,KAAS,QAAQ,EAAE;wBACnE,IAAI,CAAC,YAAY,CAAC,+RAA2B,EAAE,cAAc,CAAC,IAAI,CAAC;wBACnE,IAAI,CAAC,UAAU,CAAC,CAAC,aAAa,EAAE,cAAc,CAAC,IAAI,CAAC,CAAA,CAAA;oBACA;oBAEA,uDAAA;oBACA,MAAA,cAAA,GAAA,aAAA,CAAA,MAAA;oBACA,IAAA,cAAA,IAAA,OAAA,cAAA,KAAA,UAAA,EAAA;wBACA,aAAA,CAAA,MAAA,GAAA,6BAAA,CACA,cAAA,CAAA,IAAA,CAAA,aAAA,CAAA,EACA,aAAA,EACA,cAAA,EACA,OAAA;oBAEA;oBAEA,OAAA,aAAA;gBACA,CAAA,CAAA,OAAA,KAAA,EAAA;oBACA,IAAA,CAAA,SAAA,CAAA;wBAAA,IAAA,EAAA,kQAAA;wBAAA,OAAA,EAAA,gBAAA;oBAAA,CAAA,CAAA;wBACA,mPAAA,EAAA,KAAA,EAAA;wBACA,SAAA,EAAA;4BACA,OAAA,EAAA,KAAA;4BACA,IAAA,EAAA,yBAAA;wBACA,CAAA;oBACA,CAAA,CAAA;oBACA,MAAA,KAAA;gBACA;YACA,CAAA;QAEA,CAAA;IACA,CAAA,CAAA;AACA;AAEA;;;;CAIA,GACA,SAAA,6BAAA,CACA,cAAA,EACA,aAAA,EACA,cAAA,EACA,OAAA;IAEA,OAAA,IAAA,KAAA,CAAA,cAAA,EAAA;QACA,KAAA,EAAA,MAAA,EAAA,OAAA,EAAA,IAAA,EAAA;YACA,WAAA,qPAAA,EACA;gBACA,EAAA,EAAA,qBAAA;gBACA,IAAA,EAAA,cAAA;gBACA,UAAA,EAAA;oBACA,CAAA,8QAAA,CAAA,EAAA,6QAAA;oBACA,CAAA,0QAAA,CAAA,EAAA,2SAAA;oBACA,CAAA,mSAAA,CAAA,EAAA,cAAA;gBACA,CAAA;YACA,CAAA,EACA,OAAA,IAAA,IAAA;gBACA,IAAA;oBACA,MAAA,SAAA,GAAA,cAAA,EAAA,IAAA;oBAEA,IAAA,SAAA,IAAA,OAAA,SAAA,KAAA,QAAA,EAAA;wBACA,IAAA,CAAA,YAAA,CAAA,kSAAA,EAAA,SAAA,CAAA;wBACA,IAAA,CAAA,YAAA,CAAA,+RAAA,EAAA,SAAA,CAAA;wBACA,IAAA,CAAA,UAAA,CAAA,CAAA,aAAA,EAAA,SAAA,CAAA,CAAA,CAAA;oBACA;oBAEA,kDAAA;oBACA,MAAA,KAAA,OAAA,sRAAA,EAAA,aAAA,CAAA;oBACA,IAAA,KAAA,EAAA;wBACA,IAAA,CAAA,YAAA,CAAA,4SAAA,EAAA,IAAA,CAAA,SAAA,CAAA,KAAA,CAAA,CAAA;oBACA;oBAEA,uBAAA;oBACA,MAAA,YAAA,GAAA,OAAA,CAAA,YAAA;oBACA,MAAA,aAAA,GAAA,OAAA,CAAA,aAAA;oBACA,MAAA,aAAA,GACA,IAAA,CAAA,MAAA,GAAA,CAAA,GAAA,IAAA,CAAA,CAAA,CAAA,CAAA,QAAA,IAAA,EAAA,GAAA,EAAA;oBAEA,IAAA,aAAA,IAAA,YAAA,EAAA;wBACA,MAAA,kBAAA,OAAA,mRAAA,EAAA,aAAA,CAAA;wBACA,MAAA,iBAAA,OAAA,mRAAA,EAAA,kBAAA,CAAA;wBACA,IAAA,CAAA,YAAA,CAAA,qSAAA,EAAA,IAAA,CAAA,SAAA,CAAA,iBAAA,CAAA,CAAA;oBACA;oBAEA,uBAAA;oBACA,MAAA,MAAA,GAAA,MAAA,OAAA,CAAA,KAAA,CAAA,MAAA,EAAA,OAAA,EAAA,IAAA,CAAA;oBAEA,0BAAA;oBACA,IAAA,aAAA,EAAA;4BACA,8QAAA,EAAA,IAAA,EAAA,aAAA,IAAA,IAAA,EAAA,MAAA,CAAA;oBACA;oBAEA,OAAA,MAAA;gBACA,CAAA,CAAA,OAAA,KAAA,EAAA;oBACA,IAAA,CAAA,SAAA,CAAA;wBAAA,IAAA,EAAA,kQAAA;wBAAA,OAAA,EAAA,gBAAA;oBAAA,CAAA,CAAA;wBACA,mPAAA,EAAA,KAAA,EAAA;wBACA,SAAA,EAAA;4BACA,OAAA,EAAA,KAAA;4BACA,IAAA,EAAA,yBAAA;wBACA,CAAA;oBACA,CAAA,CAAA;oBACA,MAAA,KAAA;gBACA;YACA,CAAA;QAEA,CAAA;IACA,CAAA,CAAA;AACA;AAEA;;;;;;;;;;;;;;;;;;;;;;CAsBA,GACA,8DAAA;AACA,SAAA,mBAAA,CACA,UAAA,EACA,OAAA;IAEA,MAAA,QAAA,GAAA,OAAA,IAAA,CAAA,CAAA;IAEA,UAAA,CAAA,OAAA,GAAA,2BAAA,CAAA,UAAA,CAAA,OAAA,CAAA,IAAA,CAAA,UAAA,CAAA,EAAA,QAAA,CAAA;IAEA,OAAA,UAAA;AACA"}},
    {"offset": {"line": 5316, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/@sentry/core/build/esm/tracing/errors.js","sources":["file:///Users/crischimiadao/ETHGlobalBuenosAires/blockchain-status-plotter-new/node_modules/%40sentry/core/src/tracing/errors.ts"],"sourcesContent":["import { DEBUG_BUILD } from '../debug-build';\nimport { addGlobalErrorInstrumentationHandler } from '../instrument/globalError';\nimport { addGlobalUnhandledRejectionInstrumentationHandler } from '../instrument/globalUnhandledRejection';\nimport { debug } from '../utils/debug-logger';\nimport { getActiveSpan, getRootSpan } from '../utils/spanUtils';\nimport { SPAN_STATUS_ERROR } from './spanstatus';\n\nlet errorsInstrumented = false;\n\n/**  Only exposed for testing */\nexport function _resetErrorsInstrumented(): void {\n  errorsInstrumented = false;\n}\n\n/**\n * Ensure that global errors automatically set the active span status.\n */\nexport function registerSpanErrorInstrumentation(): void {\n  if (errorsInstrumented) {\n    return;\n  }\n\n  /**\n   * If an error or unhandled promise occurs, we mark the active root span as failed\n   */\n  function errorCallback(): void {\n    const activeSpan = getActiveSpan();\n    const rootSpan = activeSpan && getRootSpan(activeSpan);\n    if (rootSpan) {\n      const message = 'internal_error';\n      DEBUG_BUILD && debug.log(`[Tracing] Root span: ${message} -> Global error occurred`);\n      rootSpan.setStatus({ code: SPAN_STATUS_ERROR, message });\n    }\n  }\n\n  // The function name will be lost when bundling but we need to be able to identify this listener later to maintain the\n  // node.js default exit behaviour\n  errorCallback.tag = 'sentry_tracingErrorCallback';\n\n  errorsInstrumented = true;\n  addGlobalErrorInstrumentationHandler(errorCallback);\n  addGlobalUnhandledRejectionInstrumentationHandler(errorCallback);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAOA,IAAI,kBAAA,GAAqB,KAAK;AAO9B;;CAEA,GACO,SAAS,gCAAgC,GAAS;IACvD,IAAI,kBAAkB,EAAE;QACtB;IACF;IAEF;;GAEA,GACE,SAAS,aAAa,GAAS;QAC7B,MAAM,UAAA,OAAa,2PAAa,EAAE;QAClC,MAAM,WAAW,UAAA,QAAc,yPAAW,EAAC,UAAU,CAAC;QACtD,IAAI,QAAQ,EAAE;YACZ,MAAM,OAAA,GAAU,gBAAgB;YAChC,qPAAA,IAAe,yPAAK,CAAC,GAAG,CAAC,CAAC,qBAAqB,EAAE,OAAO,CAAC,yBAAyB,CAAC,CAAC;YACpF,QAAQ,CAAC,SAAS,CAAC;gBAAE,IAAI,EAAE,kQAAiB;gBAAE,OAAA;YAAA,CAAS,CAAC;QAC1D;IACF;IAEF,sHAAA;IACA,iCAAA;IACE,aAAa,CAAC,GAAA,GAAM,6BAA6B;IAEjD,kBAAA,GAAqB,IAAI;QACzB,yRAAoC,EAAC,aAAa,CAAC;QACnD,mTAAiD,EAAC,aAAa,CAAC;AAClE"}}]
}